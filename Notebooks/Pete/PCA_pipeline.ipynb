{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b22b4c43-dd87-4058-b98d-c9b68351e897",
   "metadata": {},
   "source": [
    "# Feature Extraction using Unsupervised Methods\n",
    "\n",
    "This notebook augments the X_train and X_test dataframes with additional features from PCA extraction, MDS, and K-Means clustering techniques.\n",
    "\n",
    "Additionally, it preserves all objects as python 'pickle' files so that results can be replicated in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eeb35af-c354-495b-951f-b2a45f204632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#123456789012345678901234567890123456789012345678901234567890123456789012345678"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeee13b2-2b92-47b4-82eb-a284bc05ee83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "PATH_TO_MODULES = '../..'\n",
    "sys.path.insert(0, PATH_TO_MODULES)\n",
    "\n",
    "from helpers import *\n",
    "from unsupervised_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25cda203-6975-45f8-8ffb-e6fc08be0753",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_features(input_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Extract features from a training dataset using PCA.\n",
    "\n",
    "    Use this function only on the TRAINING set.\n",
    "    This function extracts features using PCA and assigns cluster labels\n",
    "    using K-Means.  It also saves an augmented dataframe as a CSV file, and \n",
    "    preserves the objects used to transform the data as 'pickle' files.\n",
    "    \"\"\"\n",
    "    dataset = input_df.copy()\n",
    "    if 'Unnamed: 0' in dataset.columns:\n",
    "        dataset.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    # Process for PCA\n",
    "    pca_df = process_for_PCA(dataset)\n",
    "    # We found that the top 50 PCs explain 85% of the variance\n",
    "    pca = PCA(50)\n",
    "    X_PCA = pca.fit_transform(pca_df)\n",
    "    # Pickle the pca object\n",
    "    with open(path + 'pca_all.pickle', 'wb') as f:\n",
    "        pickle.dump(pca, f)\n",
    "    # Make a dataframe of the top 50 PCs\n",
    "    PCA_cols = ['PCA_all_PC' + str(i + 1) for i in range(X_PCA.shape[1])]\n",
    "    top50_PC_all_df = pd.DataFrame(X_PCA, columns=PCA_cols)\n",
    "    # Use K-Means to assign cluster labels\n",
    "    kmeans = KMeans(n_clusters=7, init='random', n_init=100, copy_x=False)\n",
    "    cluster_label = kmeans.fit_predict(X_PCA)\n",
    "    # Pickle the K-Means object\n",
    "    with open(path + 'kmeans.pickle', 'wb') as f:\n",
    "        pickle.dump(kmeans, f)\n",
    "    # Perform PCA using only the KPI subset\n",
    "    subset_df = get_KPI(dataset)\n",
    "    subset_pca_df = process_for_PCA(subset_df)\n",
    "    pca_KPI = PCA(10)\n",
    "    X_PCA_KPI = pca_KPI.fit_transform(pca_df)\n",
    "    # pickle the pca_KPI object\n",
    "    with open(path + 'pca_KPI.pickle', 'wb') as f:\n",
    "        pickle.dump(pca_KPI, f)\n",
    "    # Make a dataframe of the top 10 PCs from the KPI subset\n",
    "    PCA_KPI_cols = ['PCA_KPI_PC' + str(i + 1) for i in range(X_PCA_KPI.shape[1])]\n",
    "    top10_PC_KPI_df = pd.DataFrame(X_PCA_KPI, columns=PCA_KPI_cols)\n",
    "    # Create augmented DataFrame\n",
    "    augmented_df = pd.concat(\n",
    "        (\n",
    "            dataset,\n",
    "            top50_PC_all_df,\n",
    "            top10_PC_KPI_df,\n",
    "            pd.Series(cluster_label, name='Cluster')\n",
    "        ), axis = 1\n",
    "    )\n",
    "    return augmented_df\n",
    "\n",
    "    \n",
    "def transform_features(input_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Augment a dataframe with extracted features.\n",
    "\n",
    "    Use this function on the test set.\n",
    "    This function uses pickled objects that were used during feature extraction\n",
    "    on the test set to augment the test set with additional features.\n",
    "    \"\"\"\n",
    "    dataset = input_df.copy()\n",
    "    if 'Unnamed: 0' in dataset.columns:\n",
    "        dataset.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    # Need to finish this....\n",
    "    return dataset\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec7cf42-1120-4006-acec-85b6e95d2a97",
   "metadata": {},
   "source": [
    "\n",
    "## Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f954f57f-631b-4652-8f21-8331496bb31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1905 rows and 284 columns in the dataset.\n"
     ]
    }
   ],
   "source": [
    "# Import merged dataset\n",
    "path = PATH_TO_MODULES + '/datasets/'\n",
    "input_filename = 'X_train_filled_KPIs_QoQ.csv'\n",
    "dataset = pd.read_csv(path + input_filename)\n",
    "print(f'There are {dataset.shape[0]} rows and {dataset.shape[1]} columns in the dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "969f109e-2c61-436f-8f5c-b7e5f44bb793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping non-numeric columns.\n",
      "Remaining dtypes: [dtype('float64') dtype('int64')]\n",
      "There are 1905 rows and 278 columns in the dataset.\n",
      "Dropping non-numeric columns.\n",
      "Remaining dtypes: [dtype('float64')]\n",
      "There are 1905 rows and 47 columns in the dataset.\n"
     ]
    }
   ],
   "source": [
    "augmented_df = extract_features(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197a3fda-99d2-4bc4-8abb-a67ae312e346",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
