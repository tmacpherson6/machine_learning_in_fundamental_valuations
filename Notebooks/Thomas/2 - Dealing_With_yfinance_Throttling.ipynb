{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "luiGzJXvIKLa"
   },
   "source": [
    "# yFinance Throttling Issues\n",
    "We are dealing with a strange issues where we are missing pretty much all data from the 900+ ticker. Then it will come back much later and we have data from 2000+. To me, because we are getting data and then not, I think it is an issue with yfinance throttling us for too many requests. Going to build in a longer delay using the notebook and then transfer that to the pipeline when I have a resolved answer.\n",
    "\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 7827,
     "status": "ok",
     "timestamp": 1758488245420,
     "user": {
      "displayName": "Thomas Macpherson",
      "userId": "08726222529195553341"
     },
     "user_tz": 360
    },
    "id": "YMgbsiItuvyj"
   },
   "outputs": [],
   "source": [
    "# File system libraries\n",
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "# Data Manipulation Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Stat Libraries\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Machine Learning Libraries\n",
    "#import pycaret #Not working with this version of python\n",
    "import sklearn\n",
    "\n",
    "# Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import altair as alt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WswT0tPYIhpQ"
   },
   "source": [
    "# Load Data\n",
    "Let's start by loading the base data that we want to add to because that is typically done for us in the pipeline but here we will have to do it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 413,
     "status": "ok",
     "timestamp": 1758488245831,
     "user": {
      "displayName": "Thomas Macpherson",
      "userId": "08726222529195553341"
     },
     "user_tz": 360
    },
    "id": "dJc4X5nAu47Y",
    "outputId": "e9869bf9-bca2-4726-e461-bf43483763eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Russell_3000.csv',\n",
       " 'Russell_3000_With_Fundamentals.csv',\n",
       " 'Makefile',\n",
       " 'data_acquisition_macro.py',\n",
       " 'data_acquisition.py',\n",
       " 'Russel_3000_With_Macro.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mount the google drive\n",
    "drive.mount('/content/drive')\n",
    "# Navigate to the folder and set the file name\n",
    "path = '/content/drive/MyDrive/Colab Notebooks/696 - Milestone II/696 - Milestone II - Shared/Pipeline Files'\n",
    "\n",
    "os.chdir(path)\n",
    "os.getcwd()\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 133,
     "status": "ok",
     "timestamp": 1758488245964,
     "user": {
      "displayName": "Thomas Macpherson",
      "userId": "08726222529195553341"
     },
     "user_tz": 360
    },
    "id": "dEae7e7au9wC",
    "outputId": "5ab284e8-116a-42a3-f886-efe4f27f6597"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ticker                        Name                  Sector Asset Class  \\\n",
      "0   NVDA                 NVIDIA CORP  Information Technology      Equity   \n",
      "1   MSFT              MICROSOFT CORP  Information Technology      Equity   \n",
      "2   AAPL                   APPLE INC  Information Technology      Equity   \n",
      "3   AMZN              AMAZON COM INC  Consumer Discretionary      Equity   \n",
      "4   META  META PLATFORMS INC CLASS A           Communication      Equity   \n",
      "\n",
      "       Market Value  Weight (%)    Notional Value      Quantity   Price  \\\n",
      "0  1,066,994,615.04        6.39  1,066,994,615.04  6,215,744.00  171.66   \n",
      "1  1,000,536,825.69        5.99  1,000,536,825.69  1,969,677.00  507.97   \n",
      "2    938,729,828.14        5.62    938,729,828.14  3,914,963.00  239.78   \n",
      "3    600,426,381.12        3.60    600,426,381.12  2,547,634.00  235.68   \n",
      "4    434,118,178.20        2.60    434,118,178.20    579,868.00  748.65   \n",
      "\n",
      "        Location Exchange Currency  \n",
      "0  United States   NASDAQ      USD  \n",
      "1  United States   NASDAQ      USD  \n",
      "2  United States   NASDAQ      USD  \n",
      "3  United States   NASDAQ      USD  \n",
      "4  United States   NASDAQ      USD  \n"
     ]
    }
   ],
   "source": [
    "filename = 'Russell_3000.csv'\n",
    "df = pd.read_csv(filename)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ND2_fGliIqKe"
   },
   "source": [
    "Now, let's pull in our complete pipeline code. We will  have to block the argparse section and bypass the loading of the data from a different path location as we have already loaded the base data into a dataframe titled 'df'. Let's also skip the saving session so we can investigate the data before saving to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 459312,
     "status": "ok",
     "timestamp": 1758488705277,
     "user": {
      "displayName": "Thomas Macpherson",
      "userId": "08726222529195553341"
     },
     "user_tz": 360
    },
    "id": "-LqBpdeDvEax",
    "outputId": "6d61017d-41dc-4f76-d834-86aec7232fd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 2596 unique tickers to process from your original CSV file.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching last 5 completed-quarter metrics: 100%|██████████| 2596/2596 [07:37<00:00,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched financial metrics for 2596 tickers.\n",
      "\n",
      "Merged data contains 2600 rows and 109 columns.\n",
      "\n",
      "Target quarters (most recent first): ['2025Q2', '2025Q1', '2024Q4', '2024Q3', '2024Q2']\n",
      "  Ticker                        Name                  Sector OriginalTicker  \\\n",
      "0   NVDA                 NVIDIA CORP  Information Technology           NVDA   \n",
      "1   MSFT              MICROSOFT CORP  Information Technology           MSFT   \n",
      "2   AAPL                   APPLE INC  Information Technology           AAPL   \n",
      "3   AMZN              AMAZON COM INC  Consumer Discretionary           AMZN   \n",
      "4   META  META PLATFORMS INC CLASS A           Communication           META   \n",
      "\n",
      "  YahooSymbol  Weight (%) Asset Class  CapitalExpenditure_2024Q2  \\\n",
      "0        NVDA        6.39      Equity                        NaN   \n",
      "1        MSFT        5.99      Equity              -1.387300e+10   \n",
      "2        AAPL        5.62      Equity              -2.151000e+09   \n",
      "3        AMZN        3.60      Equity              -1.762000e+10   \n",
      "4        META        2.60      Equity              -8.173000e+09   \n",
      "\n",
      "   CapitalExpenditure_2024Q3  CapitalExpenditure_2024Q4  ...  \\\n",
      "0              -9.770000e+08              -8.130000e+08  ...   \n",
      "1              -1.492300e+10              -1.580400e+10  ...   \n",
      "2              -2.908000e+09              -2.940000e+09  ...   \n",
      "3              -2.262000e+10              -2.783400e+10  ...   \n",
      "4              -8.258000e+09              -1.442500e+10  ...   \n",
      "\n",
      "   TotalEquity_2024Q2  TotalEquity_2024Q3  TotalEquity_2024Q4  \\\n",
      "0                 NaN        5.815700e+10        6.589900e+10   \n",
      "1        2.684770e+11        2.877230e+11        3.026950e+11   \n",
      "2        6.670800e+10        5.695000e+10        6.675800e+10   \n",
      "3        2.364470e+11        2.591510e+11        2.859700e+11   \n",
      "4        1.567630e+11        1.645290e+11        1.826370e+11   \n",
      "\n",
      "   TotalEquity_2025Q1  TotalEquity_2025Q2  TotalLiabilities_2024Q2  \\\n",
      "0        7.932700e+10        8.384300e+10                      NaN   \n",
      "1        3.218910e+11        3.434790e+11             2.436860e+11   \n",
      "2        6.679600e+10        6.583000e+10             2.649040e+11   \n",
      "3        3.058670e+11        3.337750e+11             3.183710e+11   \n",
      "4        1.850290e+11        1.950700e+11             7.347500e+10   \n",
      "\n",
      "   TotalLiabilities_2024Q3  TotalLiabilities_2024Q4  TotalLiabilities_2025Q1  \\\n",
      "0             2.707000e+10             3.011400e+10             3.227400e+10   \n",
      "1             2.352900e+11             2.312030e+11             2.407330e+11   \n",
      "2             3.080300e+11             2.773270e+11             2.644370e+11   \n",
      "3             3.254750e+11             3.389240e+11             3.373890e+11   \n",
      "4             9.187900e+10             9.341700e+10             9.518400e+10   \n",
      "\n",
      "   TotalLiabilities_2025Q2  \n",
      "0             4.141100e+10  \n",
      "1             2.755240e+11  \n",
      "2             2.656650e+11  \n",
      "3             3.483950e+11  \n",
      "4             9.967400e+10  \n",
      "\n",
      "[5 rows x 109 columns]\n",
      "Data downloaded and saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import time\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "\n",
    "def upload_file(input_file: str) -> None:\n",
    "    \"\"\"\n",
    "    Downloads the Base Stock CSV data from the Repoository. In this project\n",
    "    we use the Russell 3000 ETF as our base stock data. The data\n",
    "    is downloaded from:\n",
    "    https://www.ishares.com/us/products/239714/ishares-russell-3000-etf\n",
    "\n",
    "    The base data should contain:\n",
    "    - Ticker\n",
    "    - Company Name\n",
    "    - Sector\n",
    "    - Asset Class\n",
    "    - Market Value (Market Cap, quantitative)\n",
    "    - Weight (%) in the ETF\n",
    "    - Notional Value (Equal to Market Value)\n",
    "    - Quantity (Number of Outstanding Shares)\n",
    "    - Price (Current Price per Share at time of download)\n",
    "    - Location (Headquarters)\n",
    "    - Exchange (Primary Exchange)\n",
    "    - Currency (Trading Currency)\n",
    "\n",
    "    Parameters:\n",
    "    input_file (str): The original Stock CSV file path.\n",
    "    \"\"\"\n",
    "    # Load the Base Stock data from the provided CSV file\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    return df\n",
    "\n",
    "def build_ticker_mapping(df):\n",
    "    \"\"\"\n",
    "    Build a mapping from OriginalTicker list from our original CSV to YahooSymbol\n",
    "    \"\"\"\n",
    "    if \"Ticker\" not in df.columns:\n",
    "        raise KeyError(\"Your DataFrame must have a 'Ticker' column.\")\n",
    "    orig_tickers = (\n",
    "        df[\"Ticker\"]\n",
    "        .dropna()\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .unique()\n",
    "        .tolist()\n",
    "    )\n",
    "\n",
    "    return orig_tickers\n",
    "\n",
    "def fetch_metrcis(orig_tickers, max_workers=8):\n",
    "    \"\"\"\n",
    "    Fetch financial metrics for a list of original tickers using multithreading.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "        futures = {ex.submit(fetch_last_completed_quarters, tk): tk for tk in orig_tickers}\n",
    "        for fut in tqdm(as_completed(futures), total=len(futures), desc=\"Fetching last 5 completed-quarter metrics\"):\n",
    "            rows.append(fut.result())\n",
    "\n",
    "    metrics = pd.DataFrame(rows)\n",
    "    return metrics\n",
    "\n",
    "def _label_quarter(ts):\n",
    "    \"\"\"\n",
    "    Convert a timestamp to a 'YYYYQ#' quarter label.\n",
    "    \"\"\"\n",
    "    ts = pd.Timestamp(ts)\n",
    "    q = (ts.month - 1)//3 + 1\n",
    "    return f\"{ts.year}Q{q}\"\n",
    "\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    \"\"\"Lowercase, remove non-alnum; robust to spaces/punctuation/casing.\"\"\"\n",
    "    _norm_re = re.compile(r\"[^a-z0-9]+\")\n",
    "    return _norm_re.sub(\"\", str(s).lower())\n",
    "\n",
    "def _last_completed_quarter(as_of=None):\n",
    "    \"\"\"\n",
    "    Return (year, quarter) for the most recently COMPLETED quarter relative to as_of.\n",
    "    \"\"\"\n",
    "    if as_of is None:\n",
    "        as_of = pd.Timestamp.today()\n",
    "    y = as_of.year\n",
    "    q = (as_of.month - 1)//3 + 1\n",
    "    # current quarter is in-progress -> use previous quarter\n",
    "    if q > 1:\n",
    "        return y, q - 1\n",
    "    else:\n",
    "        return y - 1, 4\n",
    "\n",
    "def _last_n_completed_quarters(n=5, as_of=None):\n",
    "    \"\"\"\n",
    "    Return list of 'YYYYQ#' labels for the last n COMPLETED quarters (most recent first).\n",
    "    most recent -> oldedr\n",
    "    \"\"\"\n",
    "    y, q = _last_completed_quarter(as_of)\n",
    "    labels = []\n",
    "    for _ in range(n):\n",
    "        labels.append(f\"{y}Q{q}\")\n",
    "        if q > 1:\n",
    "            q -= 1\n",
    "        else:\n",
    "            q = 4\n",
    "            y -= 1\n",
    "    return labels\n",
    "\n",
    "def _get_series(df, candidates, max_quarters=8):\n",
    "    \"\"\"\n",
    "    Return a Series for the first matching row in `candidates`, indexed by period end,\n",
    "    sorted ascending by date (we'll filter by ALLOWED_QUARTERS later).\n",
    "    Works for income_stmt, cashflow, and balance_sheet frames.\n",
    "    \"\"\"\n",
    "    if df is None or not hasattr(df, \"index\") or df.empty:\n",
    "        return pd.Series(dtype=float)\n",
    "    row = next((r for r in candidates if r in df.index), None)\n",
    "    if row is None:\n",
    "        return pd.Series(dtype=float)\n",
    "    s = df.loc[row].dropna()\n",
    "    try:\n",
    "        s.index = pd.to_datetime(s.index)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return s.sort_index().tail(max_quarters)\n",
    "\n",
    "def _get_series_caseflex(df, candidates, keywords=None, max_quarters=8):\n",
    "    \"\"\"\n",
    "    Robust row resolver:\n",
    "      1) exact match\n",
    "      2) case/space/punct-insensitive match\n",
    "      3) fuzzy 'contains' search using keywords (if provided)\n",
    "    Returns Series indexed by period-end (datetime), sorted asc.\n",
    "    \"\"\"\n",
    "    if df is None or not hasattr(df, \"index\") or df.empty:\n",
    "        return pd.Series(dtype=float)\n",
    "\n",
    "    # 1) exact\n",
    "    for r in candidates:\n",
    "        if r in df.index:\n",
    "            s = df.loc[r].dropna()\n",
    "            try: s.index = pd.to_datetime(s.index)\n",
    "            except: pass\n",
    "            return s.sort_index().tail(max_quarters)\n",
    "\n",
    "    # 2) normalized exact\n",
    "    norm_to_real = { _norm(idx): idx for idx in df.index }\n",
    "    for r in candidates:\n",
    "        nr = _norm(r)\n",
    "        if nr in norm_to_real:\n",
    "            s = df.loc[norm_to_real[nr]].dropna()\n",
    "            try: s.index = pd.to_datetime(s.index)\n",
    "            except: pass\n",
    "            return s.sort_index().tail(max_quarters)\n",
    "\n",
    "    # 3) fuzzy contains by keywords\n",
    "    if keywords:\n",
    "        hits = []\n",
    "        lower_idx = [(idx, idx.lower()) for idx in df.index]\n",
    "        for idx, low in lower_idx:\n",
    "            if any(k.lower() in low for k in keywords):\n",
    "                hits.append(idx)\n",
    "        if hits:\n",
    "            # prefer the first stable-looking hit (shortest name as a heuristic)\n",
    "            hits.sort(key=lambda x: len(x))\n",
    "            s = df.loc[hits[0]].dropna()\n",
    "            try: s.index = pd.to_datetime(s.index)\n",
    "            except: pass\n",
    "            return s.sort_index().tail(max_quarters)\n",
    "\n",
    "    return pd.Series(dtype=float)\n",
    "\n",
    "def _filter_and_add(row, series, metric):\n",
    "    if series is None or series.empty:\n",
    "        return\n",
    "    for dt, val in series.items():\n",
    "        q = _label_quarter(dt)\n",
    "        if q in ALLOWED_QUARTERS:\n",
    "            try:\n",
    "                row[f\"{metric}_{q}\"] = float(val)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "def fetch_last_completed_quarters(orig_ticker, retries=6, pause=1.0):\n",
    "    \"\"\"\n",
    "    Pull metrics only for the last 5 COMPLETED quarters (exclude the current quarter).\n",
    "    Includes Income/CF metrics and Balance Sheet metrics.\n",
    "    \"\"\"\n",
    "    ytk = yahoo_map.get(orig_ticker, orig_ticker)\n",
    "    for _ in range(retries + 1):\n",
    "        try:\n",
    "            t = yf.Ticker(ytk)\n",
    "            inc = getattr(t, \"quarterly_income_stmt\", None)\n",
    "            cf  = getattr(t, \"quarterly_cashflow\", None)\n",
    "            bal = getattr(t, \"quarterly_balance_sheet\", None)\n",
    "\n",
    "            # Income & CF series\n",
    "            rev = _get_series(inc, REV)\n",
    "            opi = _get_series(inc, OPI)\n",
    "            net = _get_series(inc, NET)\n",
    "            eps = _get_series(inc, EPS)  # may be empty; OK\n",
    "            cfo = _get_series(cf,  CFO)\n",
    "\n",
    "            # Balance sheet series (NEW)\n",
    "            cash   = _get_series(bal, CASH)\n",
    "            assets = _get_series(bal, ASSETS)\n",
    "            liab   = _get_series(bal, LIAB)\n",
    "            stdebt = _get_series(bal, ST_DEBT)\n",
    "            ltdebt = _get_series(bal, LT_DEBT)\n",
    "            equity = _get_series(bal, EQUITY)\n",
    "            curr_li = _get_series(bal, CURRENT_LIAB)\n",
    "            curr_as = _get_series(bal, CURRENT_ASSETS)\n",
    "            tot_debt = _get_series(bal, TOTAL_DEBT)\n",
    "\n",
    "            # Primary pulls (robust)\n",
    "            cor      = _get_series_caseflex(inc, COR,       keywords=[\"cost\",\"revenue\",\"sales\",\"cogs\"])\n",
    "            int_exp  = _get_series_caseflex(inc, INT_EXP,   keywords=[\"interest\",\"debt\"])\n",
    "            tax_exp  = _get_series_caseflex(inc, TAX_EXP,   keywords=[\"tax\",\"provision\"])\n",
    "            opex_oth = _get_series_caseflex(inc, OPEX_OTHER,keywords=[\"operating\",\"expense\"])\n",
    "            capex    = _get_series_caseflex(cf,  CAPEX,     keywords=[\"capital\",\"property\",\"equipment\",\"purchases\",\"ppe\"])\n",
    "\n",
    "            # Fallbacks:\n",
    "            # - Interest expense: sometimes found in cashflow descriptions\n",
    "            if (int_exp is None) or int_exp.empty:\n",
    "                int_exp = _get_series_caseflex(cf, INT_EXP, keywords=[\"interest\"])\n",
    "\n",
    "            # - CapEx: try broader keywords if still empty\n",
    "            if (capex is None) or capex.empty:\n",
    "                capex = _get_series_caseflex(cf, CAPEX, keywords=[\"capital\",\"purchases\",\"property\",\"plant\",\"equipment\"])\n",
    "\n",
    "            # - TAX derived fallback: Pretax - NetIncome (approx. provision for income taxes)\n",
    "            if (tax_exp is None) or tax_exp.empty:\n",
    "                pretax = _get_series_caseflex(inc, PRETAX, keywords=[\"before tax\",\"pretax\",\"earnings before tax\"])\n",
    "                net    = _get_series_caseflex(inc, NET_INCOME, keywords=[\"net income\"])\n",
    "                if pretax is not None and not pretax.empty and net is not None and not net.empty:\n",
    "                    # Align and derive\n",
    "                    df_tax = (pretax - net).dropna()\n",
    "                    try: df_tax.index = pd.to_datetime(df_tax.index)\n",
    "                    except: pass\n",
    "                    df_tax = df_tax.sort_index()\n",
    "                    tax_exp = df_tax.tail(8)\n",
    "\n",
    "            row = {\"OriginalTicker\": orig_ticker, \"YahooSymbol\": ytk}\n",
    "\n",
    "            for series, metric in [\n",
    "                (rev,   \"Revenue\"),\n",
    "                (opi,   \"OperatingIncome\"),\n",
    "                (net,   \"NetIncome\"),\n",
    "                (cfo,   \"CashFromOps\"),\n",
    "                (eps,   \"EPS\"),\n",
    "                (cash,  \"CashAndSTInvestments\"),\n",
    "                (assets,\"TotalAssets\"),\n",
    "                (liab,  \"TotalLiabilities\"),\n",
    "                (stdebt,\"ShortTermDebtOrCurrentLiab\"),\n",
    "                (ltdebt,\"LongTermDebt\"),\n",
    "                (equity,\"TotalEquity\"),\n",
    "                (curr_li, \"CurrentLiabilities\"),\n",
    "                (curr_as, \"CurrentAssets\"),\n",
    "                (tot_debt, \"TotalDebt\"),\n",
    "            ]:\n",
    "                if series is None or series.empty:\n",
    "                    continue\n",
    "                for dt, val in series.items():\n",
    "                    q = _label_quarter(dt)\n",
    "                    if q in ALLOWED_QUARTERS:\n",
    "                        # EPS might already be float; others may be numpy types\n",
    "                        try:\n",
    "                            row[f\"{metric}_{q}\"] = float(val)\n",
    "                        except Exception:\n",
    "                            # if conversion fails, skip this value gracefully\n",
    "                            continue\n",
    "\n",
    "            _filter_and_add(row, cor,      \"CostOfRevenue\")\n",
    "            _filter_and_add(row, int_exp,  \"InterestExpense\")\n",
    "            _filter_and_add(row, tax_exp,  \"IncomeTaxExpense\")   # may be derived\n",
    "            _filter_and_add(row, opex_oth, \"OtherOperatingExpense\")\n",
    "            _filter_and_add(row, capex,    \"CapitalExpenditure\")\n",
    "\n",
    "            return row\n",
    "        except Exception:\n",
    "            time.sleep(pause)\n",
    "\n",
    "    return {\"OriginalTicker\": orig_ticker, \"YahooSymbol\": ytk}\n",
    "\n",
    "def save_to_csv(df, output_file):\n",
    "    \"\"\"\n",
    "    Save the DataFrame to a CSV file.\n",
    "    \"\"\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #parser = argparse.ArgumentParser()\n",
    "    #parser.add_argument('input_file', help = 'Title of input file: Russell_3000.csv')\n",
    "    #parser.add_argument('output_file', help = 'Title of output file. ')\n",
    "    #args = parser.parse_args()\n",
    "\n",
    "    # Set the output file name and export the data\n",
    "    #input_file = args.input_file\n",
    "    #df = upload_file(args.input_file)\n",
    "\n",
    "    # Optional: symbol mapping if your tickers differ from Yahoo (leave empty if not needed)\n",
    "    yahoo_map = {}  # e.g., {'BRK.B': 'BRK-B'}\n",
    "\n",
    "    # Candidate labels (Yahoo varies naming sometimes)\n",
    "    # Income / CF (existing)\n",
    "    REV = [\"Total Revenue\",\"TotalRevenue\",\"Revenue\",\"Operating Revenue\",\"OperatingRevenue\"]\n",
    "    OPI = [\"Operating Income\",\"OperatingIncome\",\"Operating Income (Loss)\",\"OperatingIncomeLoss\"]\n",
    "    NET = [\"Net Income\",\"NetIncome\",\"Net Income Common Stockholders\",\"NetIncomeCommonStockholders\",\n",
    "        \"Net Income Applicable To Common Shares\",\"NetIncomeApplicableToCommonShares\"]\n",
    "    CFO = [\"Operating Cash Flow\",\"OperatingCashFlow\",\"Total Cash From Operating Activities\",\n",
    "        \"Net Cash Provided by Operating Activities\",\"NetCashProvidedByUsedInOperatingActivities\"]\n",
    "    EPS = [\"Diluted EPS\",\"DilutedEPS\",\"Basic EPS\",\"BasicEPS\",\"EPS (Diluted)\",\"EarningsPerShare\"]\n",
    "\n",
    "    # Balance Sheet (NEW)\n",
    "    CASH   = [\"Cash And Cash Equivalents\", \"CashCashEquivalentsAndShortTermInvestments\", \"Cash And Short Term Investments\"]\n",
    "    ASSETS = [\"Total Assets\",\"TotalAssets\"]\n",
    "    LIAB   = [\"Total Liabilities Net Minority Interest\",\"TotalLiabilitiesNetMinorityInterest\",\"Total Liabilities\"]\n",
    "    ST_DEBT = [\"Current Debt\",\"CurrentDebt\",\"Short Term Debt\",\"ShortTermDebt\",\n",
    "            \"Total Current Liabilities\",\"Current Portion Of Long Term Debt\"]\n",
    "    LT_DEBT = [\"Long Term Debt\",\"LongTermDebt\",\"Non Current Debt\",\"NonCurrentDebt\",\n",
    "            \"Long Term Debt And Capital Lease Obligation\"]\n",
    "    EQUITY = [\"Total Stockholder Equity\",\"TotalStockholderEquity\",\"StockholdersEquity\",\n",
    "            \"Total Equity Gross Minority Interest\",\"TotalEquityGrossMinorityInterest\"]\n",
    "        # Cost of revenue / cost of sales\n",
    "    COR = [\n",
    "        \"Cost Of Revenue\",\"CostOfRevenue\",\"Cost of Goods Sold\",\"CostOfGoodsSold\",\n",
    "        \"Cost Of Goods And Services Sold\",\"CostOfGoodsAndServicesSold\",\n",
    "        \"Cost Of Sales\",\"CostOfSales\",\"Cost of Sales\",\"Cost of Revenue\"\n",
    "    ]\n",
    "\n",
    "    # Total interest expense\n",
    "    INT_EXP = [\n",
    "        \"Interest Expense\",\"InterestExpense\",\"Interest Expense Non Operating\",\"InterestExpenseNonOperating\",\n",
    "        \"Total Interest Expense\",\"TotalInterestExpense\",\n",
    "        # extra variants seen in the wild\n",
    "        \"Interest And Debt Expense\",\"InterestAndDebtExpense\",\n",
    "        \"Interest And Debt Expense Non Operating\",\"InterestAndDebtExpenseNonOperating\",\n",
    "        \"Interest Expense Net\",\"InterestExpenseNet\"\n",
    "    ]\n",
    "\n",
    "    # Income tax expense / provision (expanded)\n",
    "    TAX_EXP = [\n",
    "        \"Income Tax Expense\",\"IncomeTaxExpense\",\"Provision For Income Taxes\",\"ProvisionForIncomeTaxes\",\n",
    "        \"Provision for income taxes\",\"Income Taxes\",\"IncomeTaxes\",\n",
    "        \"Income Tax (Benefit) Expense\",\"IncomeTaxExpenseBenefit\",\n",
    "        \"Income Tax Provision\",\"IncomeTaxProvision\",\"Provision For Income Tax\",\"ProvisionForIncomeTax\",\n",
    "        \"Provision For Income Tax (Benefit)\",\"ProvisionForIncomeTaxBenefit\"\n",
    "    ]\n",
    "\n",
    "    # Other / total operating expenses (Yahoo sometimes uses these for the roll-up)\n",
    "    OPEX_OTHER = [\n",
    "        \"Operating Expense\",\"OperatingExpense\",\"Operating Expenses\",\"OperatingExpenses\",\n",
    "        \"Other Operating Expenses\",\"OtherOperatingExpenses\",\n",
    "        # some tickers expose \"Total Operating Expenses\"\n",
    "        \"Total Operating Expenses\",\"TotalOperatingExpenses\"\n",
    "    ]\n",
    "\n",
    "    # Capital expenditures (typically reported in cash flow and often negative)\n",
    "    CAPEX = [\n",
    "        \"Capital Expenditure\",\"CapitalExpenditure\",\"Capital Expenditures\",\"CapitalExpenditures\",\n",
    "        # common cash-flow variants\n",
    "        \"Purchase Of Property And Equipment\",\"PurchaseOfPropertyAndEquipment\",\n",
    "        \"Investments In Property Plant And Equipment\",\"InvestmentsInPropertyPlantAndEquipment\",\n",
    "        \"Purchase Of Fixed Assets\",\"PurchaseOfFixedAssets\",\n",
    "        \"Additions To Property Plant And Equipment\",\"AdditionsToPropertyPlantAndEquipment\"\n",
    "    ]\n",
    "\n",
    "    # ---- For derived tax (fallback): we won't output these, only use them if needed ----\n",
    "    PRETAX = [\n",
    "        \"Pretax Income\",\"PretaxIncome\",\"Income Before Tax\",\"IncomeBeforeTax\",\n",
    "        \"Earnings Before Tax\",\"EarningsBeforeTax\",\"Income Loss Before Income Taxes\",\"IncomeLossBeforeIncomeTaxes\"\n",
    "    ]\n",
    "    NET_INCOME = [\n",
    "        \"Net Income\",\"NetIncome\",\"Net Income Common Stockholders\",\"NetIncomeCommonStockholders\",\n",
    "        \"Net Income Applicable To Common Shares\",\"NetIncomeApplicableToCommonShares\"\n",
    "    ]\n",
    "\n",
    "    # ---------------- Candidate labels (Balance Sheet only) ----------------\n",
    "    CURRENT_LIAB = [\n",
    "        \"Total Current Liabilities\",\"TotalCurrentLiabilities\",\n",
    "        \"Current Liabilities\",\"CurrentLiabilities\", \"current liabilities\",\"Current liabilities\",\"Current debt\",\"Current Debt\",\"Deposits\"\n",
    "    ]\n",
    "\n",
    "\n",
    "    CURRENT_ASSETS = [\n",
    "        \"Total Current Assets\",\"TotalCurrentAssets\",\n",
    "        \"Current Assets\",\"CurrentAssets\", \"current assets\",\"Current assets\",\"Trading Securities\",\"Trading Assets\",\"Trading securities\",\"Trading assets\"\n",
    "    ]\n",
    "\n",
    "    CURRENT_LIAB = [\n",
    "    \"Total Current Liabilities\",\"TotalCurrentLiabilities\",\n",
    "    \"Current Liabilities\",\"CurrentLiabilities\",\"current liabilities\",\n",
    "    \"Current liabilities\",\"Current debt\",\"Current Debt\",\"Deposits\"\n",
    "]\n",
    "\n",
    "    CURRENT_ASSETS = [\n",
    "        \"Total Current Assets\",\"TotalCurrentAssets\",\n",
    "        \"Current Assets\",\"CurrentAssets\",\"current assets\",\n",
    "        \"Current assets\",\"Trading Securities\",\"Trading Assets\",\n",
    "        \"Trading securities\",\"Trading assets\"\n",
    "    ]\n",
    "\n",
    "    TOTAL_DEBT = [\n",
    "        \"Total Debt\",\"TotalDebt\",\n",
    "        \"Short Long Term Debt\",\"Short Long Term Debt Total\",\"Short/Long Term Debt\",\n",
    "        \"Long Term Debt\",\"LongTermDebt\",\"Long-term debt\",\"Long Term Debt Noncurrent\",\n",
    "    ]\n",
    "\n",
    "    # Build allowed quarter labels (exclude current quarter)\n",
    "    ORDERED_QUARTERS = _last_n_completed_quarters(n=5)  # e.g., ['2025Q2','2025Q1','2024Q4','2024Q3','2024Q2']\n",
    "    ALLOWED_QUARTERS = set(ORDERED_QUARTERS)\n",
    "\n",
    "    orig_tickers = build_ticker_mapping(df)\n",
    "    print(f\"\\nFound {len(orig_tickers)} unique tickers to process from your original CSV file.\\n\")\n",
    "\n",
    "    metrics = fetch_metrcis(orig_tickers, max_workers=8)\n",
    "    print(f\"Fetched financial metrics for {len(metrics)} tickers.\\n\")\n",
    "\n",
    "    # Merge the dataframes on 'Ticker' and 'OriginalTicker'\n",
    "    merged_df = pd.merge(df, metrics, left_on='Ticker', right_on='OriginalTicker', how='left')\n",
    "    print(f\"Merged data contains {merged_df.shape[0]} rows and {merged_df.shape[1]} columns.\\n\")\n",
    "\n",
    "    # Optional: move identification columns to the front\n",
    "    id_cols = [c for c in [\"Ticker\",\"Name\",\"Sector\",\"OriginalTicker\",\"YahooSymbol\", \"Weight (%)\"] if c in merged_df.columns]\n",
    "    metric_cols = [c for c in merged_df.columns if c not in id_cols]\n",
    "    merged_df = merged_df[id_cols + sorted(metric_cols)]\n",
    "\n",
    "    print(\"Target quarters (most recent first):\", ORDERED_QUARTERS)\n",
    "    print(merged_df.head())\n",
    "\n",
    "    #save_to_csv(merged_df, 'Russell_3000_With_Macro.csv')\n",
    "    print(f\"Data downloaded and saved\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqWACd7FI7di"
   },
   "source": [
    "Alright, so it iterated through and took nearly twice the amount of time but let's check and see if we still have an excessive amount of missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1758488705299,
     "user": {
      "displayName": "Thomas Macpherson",
      "userId": "08726222529195553341"
     },
     "user_tz": 360
    },
    "id": "dWOUjRmOyYQi",
    "outputId": "3094cbb2-803b-42b2-faf5-65d4d2fc8b1e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sector</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OriginalTicker</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YahooSymbol</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalLiabilities_2024Q2</th>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalLiabilities_2024Q3</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalLiabilities_2024Q4</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalLiabilities_2025Q1</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalLiabilities_2025Q2</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 1 columns</p>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "Ticker                       0\n",
       "Name                         0\n",
       "Sector                       0\n",
       "OriginalTicker               0\n",
       "YahooSymbol                  0\n",
       "                          ... \n",
       "TotalLiabilities_2024Q2    180\n",
       "TotalLiabilities_2024Q3     41\n",
       "TotalLiabilities_2024Q4     37\n",
       "TotalLiabilities_2025Q1     36\n",
       "TotalLiabilities_2025Q2     32\n",
       "Length: 109, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cm7jef7OJCCA"
   },
   "source": [
    "Okay, this looks like we took care of the throttling issue so let's save to a CSV and update the pipeline file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 518,
     "status": "ok",
     "timestamp": 1758488823990,
     "user": {
      "displayName": "Thomas Macpherson",
      "userId": "08726222529195553341"
     },
     "user_tz": 360
    },
    "id": "fBvdoOuKGPlU",
    "outputId": "7dd124dc-02a2-4108-a6d0-aa0d1c33c7db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded and saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#save_to_csv(merged_df, 'Russell_3000_With_Fundamentals.csv')\n",
    "#print(f\"Data downloaded and saved\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZreBAZcJH7B"
   },
   "source": [
    "Pipeline file has been updated and pushed to the GitHub Repository."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNLxNgLq7Jt8kXwq6Q11G+F",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
