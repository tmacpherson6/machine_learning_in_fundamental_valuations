{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f2d2185",
   "metadata": {},
   "source": [
    "# Supervised Learning Models  \n",
    "The goal of this notebook is to create a machine learning pipeline that test multiple base forms (no hyper parameter tuning) of supervised machine learning techniques. This will allow us to determine the best baseline model to then tune in order to maximize performance. We want to set this up in a form that allows us to apply it to many different subsets of our feature space to see what works best and reduce model complexity while maintaining forecasting of out-of-sample data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018f1012",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "There are going to be a lot of different baseline models that we need to import here. The goal will be to produce a pipeline that runs the dataset through all of these models and outputs a box-whisker plot showing the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4282acdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Sci-Kit Learn Processing and Evaluating\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, QuantileTransformer\n",
    "\n",
    "\n",
    "# Supervised Learning Models  \n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso  \n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor  \n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "from sklearn.svm import SVR  \n",
    "from sklearn.ensemble import RandomForestRegressor  \n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import altair as alt\n",
    "\n",
    "# Let's set our Random State here as well\n",
    "random_state = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a12134b",
   "metadata": {},
   "source": [
    "## Load Data Files\n",
    "Now we need to load both the X_data files and the y_data files for comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f28340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2292, 345) (1968, 19)\n",
      "      Unnamed: 0 Ticker Name Sector  CapitalExpenditure_2024Q2  \\\n",
      "2287        1875    NaN  NaN    NaN                        NaN   \n",
      "2288        1881    NaN  NaN    NaN                        NaN   \n",
      "2289        1892    NaN  NaN    NaN                        NaN   \n",
      "2290        1894    NaN  NaN    NaN                        NaN   \n",
      "2291        1904    NaN  NaN    NaN                        NaN   \n",
      "\n",
      "      CapitalExpenditure_2024Q3  CapitalExpenditure_2024Q4  \\\n",
      "2287                        NaN                        NaN   \n",
      "2288                        NaN                        NaN   \n",
      "2289                        NaN                        NaN   \n",
      "2290                        NaN                        NaN   \n",
      "2291                        NaN                        NaN   \n",
      "\n",
      "      CapitalExpenditure_2025Q1  CashAndSTInvestments_2024Q2  \\\n",
      "2287                        NaN                          NaN   \n",
      "2288                        NaN                          NaN   \n",
      "2289                        NaN                          NaN   \n",
      "2290                        NaN                          NaN   \n",
      "2291                        NaN                          NaN   \n",
      "\n",
      "      CashAndSTInvestments_2024Q3  ...  PCA_KPI_PC2  PCA_KPI_PC3  PCA_KPI_PC4  \\\n",
      "2287                          NaN  ...    -2.573841    -1.119056     4.865908   \n",
      "2288                          NaN  ...     3.321506    -0.721611    -3.860126   \n",
      "2289                          NaN  ...     3.431848    -7.379038    -1.150408   \n",
      "2290                          NaN  ...     3.547160    -4.568328    -1.022957   \n",
      "2291                          NaN  ...     1.447105    -6.112911     1.942216   \n",
      "\n",
      "      PCA_KPI_PC5  PCA_KPI_PC6  PCA_KPI_PC7  PCA_KPI_PC8  PCA_KPI_PC9  \\\n",
      "2287    -5.179741    -3.941715    -6.136925     1.185725     2.809218   \n",
      "2288    -1.733341     0.411055    -2.967956    -1.342109     1.315784   \n",
      "2289    -2.174023    -4.777348     4.256810     2.131698     2.538607   \n",
      "2290    -0.922503    -0.591134     2.708538    -1.406071    -1.355282   \n",
      "2291     0.499962    -1.496423    -3.473335    -0.926276    -3.076073   \n",
      "\n",
      "      PCA_KPI_PC10  Cluster  \n",
      "2287     -3.276745      4.0  \n",
      "2288     -0.360877      2.0  \n",
      "2289      0.649989      2.0  \n",
      "2290     -0.231660      2.0  \n",
      "2291      3.657480      6.0  \n",
      "\n",
      "[5 rows x 345 columns]       Unnamed: 0  CapitalExpenditure_2025Q2  CashAndSTInvestments_2025Q2  \\\n",
      "1963        1644                 -2489000.0                  689734000.0   \n",
      "1964        1704                  -569000.0                  188648000.0   \n",
      "1965         674               -845000000.0                  412000000.0   \n",
      "1966        1599                 -2900000.0                   90200000.0   \n",
      "1967         856                -31462000.0                   95319000.0   \n",
      "\n",
      "      CashFromOps_2025Q2  CostOfRevenue_2025Q2  CurrentAssets_2025Q2  \\\n",
      "1963           9381000.0            94577000.0                   NaN   \n",
      "1964           5408000.0           377992000.0          3.629390e+08   \n",
      "1965         477000000.0           532000000.0          1.025000e+09   \n",
      "1966          61600000.0            85200000.0          2.248000e+08   \n",
      "1967          73850000.0           306846000.0          9.087440e+08   \n",
      "\n",
      "      CurrentLiabilities_2025Q2  EPS_2025Q2  IncomeTaxExpense_2025Q2  \\\n",
      "1963                        NaN       -0.22               -2015000.0   \n",
      "1964               2.019480e+08       -0.02              -10578000.0   \n",
      "1965               2.870000e+09       -0.49              -16000000.0   \n",
      "1966               5.540000e+07        0.28                4500000.0   \n",
      "1967               3.586540e+08        1.74               17880000.0   \n",
      "\n",
      "      InterestExpense_2025Q2  LongTermDebt_2025Q2  NetIncome_2025Q2  \\\n",
      "1963             121637000.0         1.400150e+08       -27881000.0   \n",
      "1964                     NaN                  NaN       -10578000.0   \n",
      "1965             197000000.0         1.186000e+10      -123000000.0   \n",
      "1966               5300000.0         2.745000e+08        10100000.0   \n",
      "1967                343000.0         5.203000e+08        53408000.0   \n",
      "\n",
      "      OperatingIncome_2025Q2  OtherOperatingExpense_2025Q2  Revenue_2025Q2  \\\n",
      "1963                     NaN                   121637000.0    9.457700e+07   \n",
      "1964             -10559000.0                   110187000.0    4.776200e+08   \n",
      "1965              60000000.0                   930000000.0    1.522000e+09   \n",
      "1966              16200000.0                    26000000.0    1.274000e+08   \n",
      "1967              70720000.0                   126501000.0    5.040670e+08   \n",
      "\n",
      "      TotalAssets_2025Q2  TotalDebt_2025Q2  TotalEquity_2025Q2  \\\n",
      "1963        1.854702e+10      2.009000e+08        2.224117e+09   \n",
      "1964        5.749870e+08               NaN        3.441790e+08   \n",
      "1965        2.126500e+10      1.187000e+10        4.761000e+09   \n",
      "1966        6.723000e+08      3.583000e+08        8.690000e+07   \n",
      "1967        2.093826e+09      5.971480e+08        1.171406e+09   \n",
      "\n",
      "      TotalLiabilities_2025Q2  \n",
      "1963             1.632290e+10  \n",
      "1964             2.308080e+08  \n",
      "1965             1.650400e+10  \n",
      "1966             5.854000e+08  \n",
      "1967             9.224200e+08  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tmacp\\AppData\\Local\\Temp\\ipykernel_52004\\3714269502.py:4: DtypeWarning: Columns (1,2,3,32,109) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  X = pd.read_csv(root_path+X_train_file)\n"
     ]
    }
   ],
   "source": [
    "root_path = '../../datasets/'\n",
    "X_train_file = 'X_train_filled_KPIs_QoQ.csv'\n",
    "y_train_file = 'y_train.csv'\n",
    "X = pd.read_csv(root_path+X_train_file)\n",
    "y = pd.read_csv(root_path+y_train_file)\n",
    "print(X.shape, y.shape)\n",
    "print(X.tail(),y.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aea7a58",
   "metadata": {},
   "source": [
    "Alright, the first thing that I notice is that we have different sizes of files. That means we dropped rows in our X split but didn't drop them in our y. So let's address this first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "08d21ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2292\n",
      "(1908, 19)\n",
      "      Unnamed: 0 Ticker Name Sector  CapitalExpenditure_2024Q2  \\\n",
      "2287        1875    NaN  NaN    NaN                        NaN   \n",
      "2288        1881    NaN  NaN    NaN                        NaN   \n",
      "2289        1892    NaN  NaN    NaN                        NaN   \n",
      "2290        1894    NaN  NaN    NaN                        NaN   \n",
      "2291        1904    NaN  NaN    NaN                        NaN   \n",
      "\n",
      "      CapitalExpenditure_2024Q3  CapitalExpenditure_2024Q4  \\\n",
      "2287                        NaN                        NaN   \n",
      "2288                        NaN                        NaN   \n",
      "2289                        NaN                        NaN   \n",
      "2290                        NaN                        NaN   \n",
      "2291                        NaN                        NaN   \n",
      "\n",
      "      CapitalExpenditure_2025Q1  CashAndSTInvestments_2024Q2  \\\n",
      "2287                        NaN                          NaN   \n",
      "2288                        NaN                          NaN   \n",
      "2289                        NaN                          NaN   \n",
      "2290                        NaN                          NaN   \n",
      "2291                        NaN                          NaN   \n",
      "\n",
      "      CashAndSTInvestments_2024Q3  ...  PCA_KPI_PC2  PCA_KPI_PC3  PCA_KPI_PC4  \\\n",
      "2287                          NaN  ...    -2.573841    -1.119056     4.865908   \n",
      "2288                          NaN  ...     3.321506    -0.721611    -3.860126   \n",
      "2289                          NaN  ...     3.431848    -7.379038    -1.150408   \n",
      "2290                          NaN  ...     3.547160    -4.568328    -1.022957   \n",
      "2291                          NaN  ...     1.447105    -6.112911     1.942216   \n",
      "\n",
      "      PCA_KPI_PC5  PCA_KPI_PC6  PCA_KPI_PC7  PCA_KPI_PC8  PCA_KPI_PC9  \\\n",
      "2287    -5.179741    -3.941715    -6.136925     1.185725     2.809218   \n",
      "2288    -1.733341     0.411055    -2.967956    -1.342109     1.315784   \n",
      "2289    -2.174023    -4.777348     4.256810     2.131698     2.538607   \n",
      "2290    -0.922503    -0.591134     2.708538    -1.406071    -1.355282   \n",
      "2291     0.499962    -1.496423    -3.473335    -0.926276    -3.076073   \n",
      "\n",
      "      PCA_KPI_PC10  Cluster  \n",
      "2287     -3.276745      4.0  \n",
      "2288     -0.360877      2.0  \n",
      "2289      0.649989      2.0  \n",
      "2290     -0.231660      2.0  \n",
      "2291      3.657480      6.0  \n",
      "\n",
      "[5 rows x 345 columns]       Unnamed: 0  CapitalExpenditure_2025Q2  CashAndSTInvestments_2025Q2  \\\n",
      "1903        1644                 -2489000.0                  689734000.0   \n",
      "1904        1704                  -569000.0                  188648000.0   \n",
      "1905         674               -845000000.0                  412000000.0   \n",
      "1906        1599                 -2900000.0                   90200000.0   \n",
      "1907         856                -31462000.0                   95319000.0   \n",
      "\n",
      "      CashFromOps_2025Q2  CostOfRevenue_2025Q2  CurrentAssets_2025Q2  \\\n",
      "1903           9381000.0            94577000.0                   NaN   \n",
      "1904           5408000.0           377992000.0          3.629390e+08   \n",
      "1905         477000000.0           532000000.0          1.025000e+09   \n",
      "1906          61600000.0            85200000.0          2.248000e+08   \n",
      "1907          73850000.0           306846000.0          9.087440e+08   \n",
      "\n",
      "      CurrentLiabilities_2025Q2  EPS_2025Q2  IncomeTaxExpense_2025Q2  \\\n",
      "1903                        NaN       -0.22               -2015000.0   \n",
      "1904               2.019480e+08       -0.02              -10578000.0   \n",
      "1905               2.870000e+09       -0.49              -16000000.0   \n",
      "1906               5.540000e+07        0.28                4500000.0   \n",
      "1907               3.586540e+08        1.74               17880000.0   \n",
      "\n",
      "      InterestExpense_2025Q2  LongTermDebt_2025Q2  NetIncome_2025Q2  \\\n",
      "1903             121637000.0         1.400150e+08       -27881000.0   \n",
      "1904                     NaN                  NaN       -10578000.0   \n",
      "1905             197000000.0         1.186000e+10      -123000000.0   \n",
      "1906               5300000.0         2.745000e+08        10100000.0   \n",
      "1907                343000.0         5.203000e+08        53408000.0   \n",
      "\n",
      "      OperatingIncome_2025Q2  OtherOperatingExpense_2025Q2  Revenue_2025Q2  \\\n",
      "1903                     NaN                   121637000.0    9.457700e+07   \n",
      "1904             -10559000.0                   110187000.0    4.776200e+08   \n",
      "1905              60000000.0                   930000000.0    1.522000e+09   \n",
      "1906              16200000.0                    26000000.0    1.274000e+08   \n",
      "1907              70720000.0                   126501000.0    5.040670e+08   \n",
      "\n",
      "      TotalAssets_2025Q2  TotalDebt_2025Q2  TotalEquity_2025Q2  \\\n",
      "1903        1.854702e+10      2.009000e+08        2.224117e+09   \n",
      "1904        5.749870e+08               NaN        3.441790e+08   \n",
      "1905        2.126500e+10      1.187000e+10        4.761000e+09   \n",
      "1906        6.723000e+08      3.583000e+08        8.690000e+07   \n",
      "1907        2.093826e+09      5.971480e+08        1.171406e+09   \n",
      "\n",
      "      TotalLiabilities_2025Q2  \n",
      "1903             1.632290e+10  \n",
      "1904             2.308080e+08  \n",
      "1905             1.650400e+10  \n",
      "1906             5.854000e+08  \n",
      "1907             9.224200e+08  \n"
     ]
    }
   ],
   "source": [
    "in_train = set(X['Unnamed: 0'])\n",
    "y = y[y['Unnamed: 0'].isin(in_train)].copy()\n",
    "X.reset_index(drop=True,inplace=True)\n",
    "y.reset_index(drop=True,inplace=True)\n",
    "print(len(in_train))\n",
    "print(y.shape)\n",
    "print(X.tail(),y.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246251c0",
   "metadata": {},
   "source": [
    "### Set up our dependent variables (y1 and y2)\n",
    "Now, Let's get our two different y variables that we want to compare to. y1 will be total Revenue, y2 will be net income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f430f0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1908,) (1908,)\n",
      "457\n",
      "457\n"
     ]
    }
   ],
   "source": [
    "# Let's pull out the data we want to predict\n",
    "y1_rev = y['Revenue_2025Q2']\n",
    "y2_ear = y['NetIncome_2025Q2']\n",
    "print(y1_rev.shape,y2_ear.shape)\n",
    "print(y1_rev.isna().sum())\n",
    "print(y2_ear.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d2a575",
   "metadata": {},
   "source": [
    "So, it turns out that we have a lot of missing values that we are trying to predict here. So we obviously need to remove them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a1f18c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1908, 3)\n",
      "(1451, 3)\n",
      "(1451, 345)\n"
     ]
    }
   ],
   "source": [
    "y = y[['Unnamed: 0','Revenue_2025Q2','NetIncome_2025Q2']]\n",
    "print(y.shape)\n",
    "y.dropna(inplace=True)\n",
    "print(y.shape)\n",
    "in_dependent = set(y['Unnamed: 0'])\n",
    "X = X[X['Unnamed: 0'].isin(in_dependent)].copy()\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257b5f00",
   "metadata": {},
   "source": [
    "Now, we can reassing the y1_rev and the y2_ear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5bab48fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1451,) (1451,)\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "y1_rev = y['Revenue_2025Q2']\n",
    "y2_ear = y['NetIncome_2025Q2']\n",
    "print(y1_rev.shape,y2_ear.shape)\n",
    "print(y1_rev.isna().sum())\n",
    "print(y2_ear.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2951ae",
   "metadata": {},
   "source": [
    "Great, now similar to our unsupervised notebook. We need to do a little data cleaning and manipulation on our X here so that we have useable X and y data. Let's start by dropping the unique columns that will not help us in identifying trends (Ticker, Name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82883dd3",
   "metadata": {},
   "source": [
    "## Dataset Separation\n",
    "Alright, I think one of the first things we should do is identify three different datasets that we want to work with.  \n",
    "1. Full Dataset (minus columns like Ticker)  \n",
    "2. Raw Data Dataset (What would it look like if we just used the raw financial data) \n",
    "4. KPIs and PCA Dataset (Engineered data and data reduction dataset; this may end up being 2) \n",
    "3. Engineered Dataset (Do we get better structure when we look at just the engineered features)\n",
    "\n",
    "We can easily just split these into subdatasets if we pull out the relevant columns. So let's look at all of the columns first so that we can start creating the proper datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "df8e189b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CapitalExpenditure_2024Q2\n",
      "CapitalExpenditure_2024Q3\n",
      "CapitalExpenditure_2024Q4\n",
      "CapitalExpenditure_2025Q1\n",
      "CapitalExpenditure_QoQ_24Q2_24Q3\n",
      "CapitalExpenditure_QoQ_24Q3_24Q4\n",
      "CapitalExpenditure_QoQ_24Q4_25Q1\n",
      "CapitalExpenditure_QoQ_Rate\n",
      "CapitalExpenditure_Rate\n",
      "CashAndSTInvestments_2024Q2\n",
      "CashAndSTInvestments_2024Q3\n",
      "CashAndSTInvestments_2024Q4\n",
      "CashAndSTInvestments_2025Q1\n",
      "CashAndSTInvestments_QoQ_24Q2_24Q3\n",
      "CashAndSTInvestments_QoQ_24Q3_24Q4\n",
      "CashAndSTInvestments_QoQ_24Q4_25Q1\n",
      "CashAndSTInvestments_QoQ_Rate\n",
      "CashAndSTInvestments_Rate\n",
      "CashFromOps_2024Q2\n",
      "CashFromOps_2024Q3\n",
      "CashFromOps_2024Q4\n",
      "CashFromOps_2025Q1\n",
      "CashFromOps_QoQ_24Q2_24Q3\n",
      "CashFromOps_QoQ_24Q3_24Q4\n",
      "CashFromOps_QoQ_24Q4_25Q1\n",
      "CashFromOps_QoQ_Rate\n",
      "CashFromOps_Rate\n",
      "Cluster\n",
      "CostOfRevenue_2024Q2\n",
      "CostOfRevenue_2024Q3\n",
      "CostOfRevenue_2024Q4\n",
      "CostOfRevenue_2025Q1\n",
      "CostOfRevenue_QoQ_24Q2_24Q3\n",
      "CostOfRevenue_QoQ_24Q3_24Q4\n",
      "CostOfRevenue_QoQ_24Q4_25Q1\n",
      "CostOfRevenue_QoQ_Rate\n",
      "CostOfRevenue_Rate\n",
      "CurrentAssets_2024Q2\n",
      "CurrentAssets_2024Q3\n",
      "CurrentAssets_2024Q4\n",
      "CurrentAssets_2025Q1\n",
      "CurrentAssets_QoQ_24Q2_24Q3\n",
      "CurrentAssets_QoQ_24Q3_24Q4\n",
      "CurrentAssets_QoQ_24Q4_25Q1\n",
      "CurrentAssets_QoQ_Rate\n",
      "CurrentAssets_Rate\n",
      "CurrentLiabilities_2024Q2\n",
      "CurrentLiabilities_2024Q3\n",
      "CurrentLiabilities_2024Q4\n",
      "CurrentLiabilities_2025Q1\n",
      "CurrentLiabilities_QoQ_24Q2_24Q3\n",
      "CurrentLiabilities_QoQ_24Q3_24Q4\n",
      "CurrentLiabilities_QoQ_24Q4_25Q1\n",
      "CurrentLiabilities_QoQ_Rate\n",
      "CurrentLiabilities_Rate\n",
      "EPS_2024Q2\n",
      "EPS_2024Q3\n",
      "EPS_2024Q4\n",
      "EPS_2025Q1\n",
      "EPS_QoQ_24Q2_24Q3\n",
      "EPS_QoQ_24Q3_24Q4\n",
      "EPS_QoQ_24Q4_25Q1\n",
      "EPS_QoQ_Rate\n",
      "EPS_Rate\n",
      "Exchange\n",
      "GDPReal_2024Q1\n",
      "GDPReal_2024Q2\n",
      "GDPReal_2024Q3\n",
      "GDPReal_2024Q4\n",
      "GDPReal_2025Q1\n",
      "GDP_2024Q1\n",
      "GDP_2024Q2\n",
      "GDP_2024Q3\n",
      "GDP_2024Q4\n",
      "GDP_2025Q1\n",
      "IncomeTaxExpense_2024Q2\n",
      "IncomeTaxExpense_2024Q3\n",
      "IncomeTaxExpense_2024Q4\n",
      "IncomeTaxExpense_2025Q1\n",
      "IncomeTaxExpense_QoQ_24Q2_24Q3\n",
      "IncomeTaxExpense_QoQ_24Q3_24Q4\n",
      "IncomeTaxExpense_QoQ_24Q4_25Q1\n",
      "IncomeTaxExpense_QoQ_Rate\n",
      "IncomeTaxExpense_Rate\n",
      "IndustrialProd_2024Q1\n",
      "IndustrialProd_2024Q2\n",
      "IndustrialProd_2024Q3\n",
      "IndustrialProd_2024Q4\n",
      "IndustrialProd_2025Q1\n",
      "Inflation_2024Q1\n",
      "Inflation_2024Q2\n",
      "Inflation_2024Q3\n",
      "Inflation_2024Q4\n",
      "Inflation_2025Q1\n",
      "InterestExpense_2024Q2\n",
      "InterestExpense_2024Q3\n",
      "InterestExpense_2024Q4\n",
      "InterestExpense_2025Q1\n",
      "InterestExpense_QoQ_24Q2_24Q3\n",
      "InterestExpense_QoQ_24Q3_24Q4\n",
      "InterestExpense_QoQ_24Q4_25Q1\n",
      "InterestExpense_QoQ_Rate\n",
      "InterestExpense_Rate\n",
      "InterestRate_2024Q1\n",
      "InterestRate_2024Q2\n",
      "InterestRate_2024Q3\n",
      "InterestRate_2024Q4\n",
      "InterestRate_2025Q1\n",
      "KPI_CashFlow_2024Q2\n",
      "KPI_CashFlow_2024Q3\n",
      "KPI_CashFlow_2024Q4\n",
      "KPI_CashFlow_2025Q1\n",
      "KPI_CashFlow_QoQ_24Q2_24Q3\n",
      "KPI_CashFlow_QoQ_24Q3_24Q4\n",
      "KPI_CashFlow_QoQ_24Q4_25Q1\n",
      "KPI_CashFlow_QoQ_Rate\n",
      "KPI_CashFlow_Rate\n",
      "KPI_CurrentRatio_2024Q2\n",
      "KPI_CurrentRatio_2024Q3\n",
      "KPI_CurrentRatio_2024Q4\n",
      "KPI_CurrentRatio_2025Q1\n",
      "KPI_CurrentRatio_QoQ_24Q2_24Q3\n",
      "KPI_CurrentRatio_QoQ_24Q3_24Q4\n",
      "KPI_CurrentRatio_QoQ_24Q4_25Q1\n",
      "KPI_CurrentRatio_QoQ_Rate\n",
      "KPI_CurrentRatio_Rate\n",
      "KPI_DebtToEquityRatio_2024Q2\n",
      "KPI_DebtToEquityRatio_2024Q3\n",
      "KPI_DebtToEquityRatio_2024Q4\n",
      "KPI_DebtToEquityRatio_2025Q1\n",
      "KPI_DebtToEquityRatio_QoQ_24Q2_24Q3\n",
      "KPI_DebtToEquityRatio_QoQ_24Q3_24Q4\n",
      "KPI_DebtToEquityRatio_QoQ_24Q4_25Q1\n",
      "KPI_DebtToEquityRatio_QoQ_Rate\n",
      "KPI_DebtToEquityRatio_Rate\n",
      "KPI_GrossProfitMargin_2024Q2\n",
      "KPI_GrossProfitMargin_2024Q3\n",
      "KPI_GrossProfitMargin_2024Q4\n",
      "KPI_GrossProfitMargin_2025Q1\n",
      "KPI_GrossProfitMargin_QoQ_24Q2_24Q3\n",
      "KPI_GrossProfitMargin_QoQ_24Q3_24Q4\n",
      "KPI_GrossProfitMargin_QoQ_24Q4_25Q1\n",
      "KPI_GrossProfitMargin_QoQ_Rate\n",
      "KPI_GrossProfitMargin_Rate\n",
      "KPI_Leverage_2024Q2\n",
      "KPI_Leverage_2024Q3\n",
      "KPI_Leverage_2024Q4\n",
      "KPI_Leverage_2025Q1\n",
      "KPI_Leverage_QoQ_24Q2_24Q3\n",
      "KPI_Leverage_QoQ_24Q3_24Q4\n",
      "KPI_Leverage_QoQ_24Q4_25Q1\n",
      "KPI_Leverage_QoQ_Rate\n",
      "KPI_Leverage_Rate\n",
      "KPI_NetProfitMargin_2024Q2\n",
      "KPI_NetProfitMargin_2024Q3\n",
      "KPI_NetProfitMargin_2024Q4\n",
      "KPI_NetProfitMargin_2025Q1\n",
      "KPI_NetProfitMargin_QoQ_24Q2_24Q3\n",
      "KPI_NetProfitMargin_QoQ_24Q3_24Q4\n",
      "KPI_NetProfitMargin_QoQ_24Q4_25Q1\n",
      "KPI_NetProfitMargin_QoQ_Rate\n",
      "KPI_NetProfitMargin_Rate\n",
      "KPI_ReturnOnAssets_2024Q3\n",
      "KPI_ReturnOnAssets_2024Q4\n",
      "KPI_ReturnOnAssets_2025Q1\n",
      "KPI_ReturnOnAssets_QoQ_24Q3_24Q4\n",
      "KPI_ReturnOnAssets_QoQ_24Q4_25Q1\n",
      "KPI_ReturnOnAssets_QoQ_Rate\n",
      "KPI_ReturnOnAssets_Rate\n",
      "KPI_ReturnOnEquity_2024Q3\n",
      "KPI_ReturnOnEquity_2024Q4\n",
      "KPI_ReturnOnEquity_2025Q1\n",
      "KPI_ReturnOnEquity_QoQ_24Q3_24Q4\n",
      "KPI_ReturnOnEquity_QoQ_24Q4_25Q1\n",
      "KPI_ReturnOnEquity_QoQ_Rate\n",
      "KPI_ReturnOnEquity_Rate\n",
      "KPI_TotalAssetTurnover_2024Q3\n",
      "KPI_TotalAssetTurnover_2024Q4\n",
      "KPI_TotalAssetTurnover_2025Q1\n",
      "KPI_TotalAssetTurnover_QoQ_24Q3_24Q4\n",
      "KPI_TotalAssetTurnover_QoQ_24Q4_25Q1\n",
      "KPI_TotalAssetTurnover_QoQ_Rate\n",
      "KPI_TotalAssetTurnover_Rate\n",
      "KPI_WorkingCapital_2024Q2\n",
      "KPI_WorkingCapital_2024Q3\n",
      "KPI_WorkingCapital_2024Q4\n",
      "KPI_WorkingCapital_2025Q1\n",
      "KPI_WorkingCapital_QoQ_24Q2_24Q3\n",
      "KPI_WorkingCapital_QoQ_24Q3_24Q4\n",
      "KPI_WorkingCapital_QoQ_24Q4_25Q1\n",
      "KPI_WorkingCapital_QoQ_Rate\n",
      "KPI_WorkingCapital_Rate\n",
      "Location\n",
      "LongTermDebt_2024Q2\n",
      "LongTermDebt_2024Q3\n",
      "LongTermDebt_2024Q4\n",
      "LongTermDebt_2025Q1\n",
      "LongTermDebt_QoQ_24Q2_24Q3\n",
      "LongTermDebt_QoQ_24Q3_24Q4\n",
      "LongTermDebt_QoQ_24Q4_25Q1\n",
      "LongTermDebt_QoQ_Rate\n",
      "LongTermDebt_Rate\n",
      "Market Cap\n",
      "Market Value\n",
      "Name\n",
      "NetIncome_2024Q2\n",
      "NetIncome_2024Q3\n",
      "NetIncome_2024Q4\n",
      "NetIncome_2025Q1\n",
      "NetIncome_QoQ_24Q2_24Q3\n",
      "NetIncome_QoQ_24Q3_24Q4\n",
      "NetIncome_QoQ_24Q4_25Q1\n",
      "NetIncome_QoQ_Rate\n",
      "NetIncome_Rate\n",
      "OperatingIncome_2024Q2\n",
      "OperatingIncome_2024Q3\n",
      "OperatingIncome_2024Q4\n",
      "OperatingIncome_2025Q1\n",
      "OperatingIncome_QoQ_24Q2_24Q3\n",
      "OperatingIncome_QoQ_24Q3_24Q4\n",
      "OperatingIncome_QoQ_24Q4_25Q1\n",
      "OperatingIncome_QoQ_Rate\n",
      "OperatingIncome_Rate\n",
      "OtherOperatingExpense_2024Q2\n",
      "OtherOperatingExpense_2024Q3\n",
      "OtherOperatingExpense_2024Q4\n",
      "OtherOperatingExpense_2025Q1\n",
      "OtherOperatingExpense_QoQ_24Q2_24Q3\n",
      "OtherOperatingExpense_QoQ_24Q3_24Q4\n",
      "OtherOperatingExpense_QoQ_24Q4_25Q1\n",
      "OtherOperatingExpense_QoQ_Rate\n",
      "OtherOperatingExpense_Rate\n",
      "PCA_KPI_PC1\n",
      "PCA_KPI_PC10\n",
      "PCA_KPI_PC2\n",
      "PCA_KPI_PC3\n",
      "PCA_KPI_PC4\n",
      "PCA_KPI_PC5\n",
      "PCA_KPI_PC6\n",
      "PCA_KPI_PC7\n",
      "PCA_KPI_PC8\n",
      "PCA_KPI_PC9\n",
      "PCA_all_PC1\n",
      "PCA_all_PC10\n",
      "PCA_all_PC11\n",
      "PCA_all_PC12\n",
      "PCA_all_PC13\n",
      "PCA_all_PC14\n",
      "PCA_all_PC15\n",
      "PCA_all_PC16\n",
      "PCA_all_PC17\n",
      "PCA_all_PC18\n",
      "PCA_all_PC19\n",
      "PCA_all_PC2\n",
      "PCA_all_PC20\n",
      "PCA_all_PC21\n",
      "PCA_all_PC22\n",
      "PCA_all_PC23\n",
      "PCA_all_PC24\n",
      "PCA_all_PC25\n",
      "PCA_all_PC26\n",
      "PCA_all_PC27\n",
      "PCA_all_PC28\n",
      "PCA_all_PC29\n",
      "PCA_all_PC3\n",
      "PCA_all_PC30\n",
      "PCA_all_PC31\n",
      "PCA_all_PC32\n",
      "PCA_all_PC33\n",
      "PCA_all_PC34\n",
      "PCA_all_PC35\n",
      "PCA_all_PC36\n",
      "PCA_all_PC37\n",
      "PCA_all_PC38\n",
      "PCA_all_PC39\n",
      "PCA_all_PC4\n",
      "PCA_all_PC40\n",
      "PCA_all_PC41\n",
      "PCA_all_PC42\n",
      "PCA_all_PC43\n",
      "PCA_all_PC44\n",
      "PCA_all_PC45\n",
      "PCA_all_PC46\n",
      "PCA_all_PC47\n",
      "PCA_all_PC48\n",
      "PCA_all_PC49\n",
      "PCA_all_PC5\n",
      "PCA_all_PC50\n",
      "PCA_all_PC6\n",
      "PCA_all_PC7\n",
      "PCA_all_PC8\n",
      "PCA_all_PC9\n",
      "Revenue_2024Q2\n",
      "Revenue_2024Q3\n",
      "Revenue_2024Q4\n",
      "Revenue_2025Q1\n",
      "Revenue_QoQ_24Q2_24Q3\n",
      "Revenue_QoQ_24Q3_24Q4\n",
      "Revenue_QoQ_24Q4_25Q1\n",
      "Revenue_QoQ_Rate\n",
      "Revenue_Rate\n",
      "Sector\n",
      "Ticker\n",
      "TotalAssets_2024Q2\n",
      "TotalAssets_2024Q3\n",
      "TotalAssets_2024Q4\n",
      "TotalAssets_2025Q1\n",
      "TotalAssets_QoQ_24Q2_24Q3\n",
      "TotalAssets_QoQ_24Q3_24Q4\n",
      "TotalAssets_QoQ_24Q4_25Q1\n",
      "TotalAssets_QoQ_Rate\n",
      "TotalAssets_Rate\n",
      "TotalDebt_2024Q2\n",
      "TotalDebt_2024Q3\n",
      "TotalDebt_2024Q4\n",
      "TotalDebt_2025Q1\n",
      "TotalDebt_QoQ_24Q2_24Q3\n",
      "TotalDebt_QoQ_24Q3_24Q4\n",
      "TotalDebt_QoQ_24Q4_25Q1\n",
      "TotalDebt_QoQ_Rate\n",
      "TotalDebt_Rate\n",
      "TotalEquity_2024Q2\n",
      "TotalEquity_2024Q3\n",
      "TotalEquity_2024Q4\n",
      "TotalEquity_2025Q1\n",
      "TotalEquity_QoQ_24Q2_24Q3\n",
      "TotalEquity_QoQ_24Q3_24Q4\n",
      "TotalEquity_QoQ_24Q4_25Q1\n",
      "TotalEquity_QoQ_Rate\n",
      "TotalEquity_Rate\n",
      "TotalLiabilities_2024Q2\n",
      "TotalLiabilities_2024Q3\n",
      "TotalLiabilities_2024Q4\n",
      "TotalLiabilities_2025Q1\n",
      "TotalLiabilities_QoQ_24Q2_24Q3\n",
      "TotalLiabilities_QoQ_24Q3_24Q4\n",
      "TotalLiabilities_QoQ_24Q4_25Q1\n",
      "TotalLiabilities_QoQ_Rate\n",
      "TotalLiabilities_Rate\n",
      "Unemployment_2024Q1\n",
      "Unemployment_2024Q2\n",
      "Unemployment_2024Q3\n",
      "Unemployment_2024Q4\n",
      "Unemployment_2025Q1\n",
      "Unnamed: 0\n"
     ]
    }
   ],
   "source": [
    "complete_dataset = X.copy()\n",
    "columns = complete_dataset.columns.tolist()\n",
    "for column in sorted(columns):\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fc654c",
   "metadata": {},
   "source": [
    "Alright, let's start by identifying which columns to drop because they are unnecessary for the unsupervised learning part. This should be relatively few columns.\n",
    "- Ticker\n",
    "- Name  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c8288eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1451, 342)\n"
     ]
    }
   ],
   "source": [
    "complete_dataset = complete_dataset.drop(columns=['Unnamed: 0','Ticker','Name'])\n",
    "print(complete_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c33ce7d",
   "metadata": {},
   "source": [
    "Great, now, we can loop through all of the columns and we will pull out all of the feature engineered data if it contains 'KPI', 'QoQ', or 'Rate' in the title. We can then investigate these columns to make sure they make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "951429f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Columns: 102\n",
      "Engineered Columns: 240\n",
      "PCA Columns 61\n"
     ]
    }
   ],
   "source": [
    "raw_columns = []\n",
    "engineered_columns = []\n",
    "pca_columns = []\n",
    "for column in complete_dataset.columns:\n",
    "    if ('KPI' not in column) and ('QoQ' not in column) and ('Rate' not in column) and ('PCA' not in column) and ('Cluster' not in column):\n",
    "        raw_columns.append(column)\n",
    "    else:\n",
    "        engineered_columns.append(column)\n",
    "for column in complete_dataset.columns:\n",
    "    if ('PCA' not in column) and ('Cluster' not in column):\n",
    "        continue\n",
    "    else:\n",
    "        pca_columns.append(column)\n",
    "print(f'Raw Columns: {len(raw_columns)}')\n",
    "print(f'Engineered Columns: {len(engineered_columns)}')\n",
    "print(f'PCA Columns {len(pca_columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e580b7f2",
   "metadata": {},
   "source": [
    "Now, there are going to be some of the raw columns that we want to add back to the engineered columns as they can be very important components to the company, so let's list these here.\n",
    "- Sector  \n",
    "- Exchange\n",
    "- Location  \n",
    "- Market Cap\n",
    "- Market Value\n",
    "\n",
    "So let's append those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "30639f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered Columns after adding back important raw columns: 245\n"
     ]
    }
   ],
   "source": [
    "add_back = ['Sector','Exchange','Location','Market Value','Market Cap']\n",
    "engineered_columns = engineered_columns + add_back\n",
    "print(f'Engineered Columns after adding back important raw columns: {len(engineered_columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c098971",
   "metadata": {},
   "source": [
    "Alright, now we can build out all of our feature dataframes to test them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "89a507d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Dataset Shape: (1451, 342)\n",
      "Raw Data Shape: (1451, 102)\n",
      "Engineered Data Shape: (1451, 245)\n",
      "PCA reduced Data Shape: (1451, 61)\n"
     ]
    }
   ],
   "source": [
    "raw_data = complete_dataset[raw_columns]\n",
    "eng_data = complete_dataset[engineered_columns]\n",
    "tot_data = complete_dataset.copy()\n",
    "#kpi_data = place holder for the KPI data\n",
    "pca_data = complete_dataset[pca_columns]\n",
    "\n",
    "print(f'Full Dataset Shape: {tot_data.shape}')\n",
    "print(f'Raw Data Shape: {raw_data.shape}')\n",
    "print(f'Engineered Data Shape: {eng_data.shape}')\n",
    "#print(f'KPI Data shape: {kpi_data.shape}')\n",
    "print(f'PCA reduced Data Shape: {pca_data.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78784126",
   "metadata": {},
   "source": [
    "## Fundamental Data\n",
    "Now that we have all of our data setup, we need to work on the preprocessing steps in order to have machine readable information being fed into our supervised model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd416dde",
   "metadata": {},
   "source": [
    "### Scaler Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d2b2e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set our scaler here\n",
    "scaler = QuantileTransformer()\n",
    "#scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "87746896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "4 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 618, in fit\n",
      "    X, y = validate_data(\n",
      "           ~~~~~~~~~~~~~^\n",
      "        self,\n",
      "        ^^^^^\n",
      "    ...<5 lines>...\n",
      "        force_writeable=True,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n",
      "    X = check_array(\n",
      "        X,\n",
      "    ...<12 lines>...\n",
      "        input_name=\"X\",\n",
      "    )\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1105, in check_array\n",
      "    _assert_all_finite(\n",
      "    ~~~~~~~~~~~~~~~~~~^\n",
      "        array,\n",
      "        ^^^^^^\n",
      "    ...<2 lines>...\n",
      "        allow_nan=ensure_all_finite == \"allow-nan\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 120, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        X,\n",
      "        ^^\n",
      "    ...<4 lines>...\n",
      "        input_name=input_name,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "LinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "4 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1238, in fit\n",
      "    X, y = validate_data(\n",
      "           ~~~~~~~~~~~~~^\n",
      "        self,\n",
      "        ^^^^^\n",
      "    ...<6 lines>...\n",
      "        y_numeric=True,\n",
      "        ^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n",
      "    X = check_array(\n",
      "        X,\n",
      "    ...<12 lines>...\n",
      "        input_name=\"X\",\n",
      "    )\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1105, in check_array\n",
      "    _assert_all_finite(\n",
      "    ~~~~~~~~~~~~~~~~~~^\n",
      "        array,\n",
      "        ^^^^^^\n",
      "    ...<2 lines>...\n",
      "        allow_nan=ensure_all_finite == \"allow-nan\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 120, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        X,\n",
      "        ^^\n",
      "    ...<4 lines>...\n",
      "        input_name=input_name,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "Ridge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "4 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 986, in fit\n",
      "    X, y = validate_data(\n",
      "           ~~~~~~~~~~~~~^\n",
      "        self,\n",
      "        ^^^^^\n",
      "    ...<9 lines>...\n",
      "        y_numeric=True,\n",
      "        ^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n",
      "    X = check_array(\n",
      "        X,\n",
      "    ...<12 lines>...\n",
      "        input_name=\"X\",\n",
      "    )\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1105, in check_array\n",
      "    _assert_all_finite(\n",
      "    ~~~~~~~~~~~~~~~~~~^\n",
      "        array,\n",
      "        ^^^^^^\n",
      "    ...<2 lines>...\n",
      "        allow_nan=ensure_all_finite == \"allow-nan\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 120, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        X,\n",
      "        ^^\n",
      "    ...<4 lines>...\n",
      "        input_name=input_name,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "Lasso does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "4 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 986, in fit\n",
      "    X, y = validate_data(\n",
      "           ~~~~~~~~~~~~~^\n",
      "        self,\n",
      "        ^^^^^\n",
      "    ...<9 lines>...\n",
      "        y_numeric=True,\n",
      "        ^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n",
      "    X = check_array(\n",
      "        X,\n",
      "    ...<12 lines>...\n",
      "        input_name=\"X\",\n",
      "    )\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1105, in check_array\n",
      "    _assert_all_finite(\n",
      "    ~~~~~~~~~~~~~~~~~~^\n",
      "        array,\n",
      "        ^^^^^^\n",
      "    ...<2 lines>...\n",
      "        allow_nan=ensure_all_finite == \"allow-nan\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 120, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        X,\n",
      "        ^^\n",
      "    ...<4 lines>...\n",
      "        input_name=input_name,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "4 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\neighbors\\_regression.py\", line 222, in fit\n",
      "    return self._fit(X, y)\n",
      "           ~~~~~~~~~^^^^^^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 478, in _fit\n",
      "    X, y = validate_data(\n",
      "           ~~~~~~~~~~~~~^\n",
      "        self,\n",
      "        ^^^^^\n",
      "    ...<5 lines>...\n",
      "        ensure_all_finite=ensure_all_finite,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n",
      "    X = check_array(\n",
      "        X,\n",
      "    ...<12 lines>...\n",
      "        input_name=\"X\",\n",
      "    )\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1105, in check_array\n",
      "    _assert_all_finite(\n",
      "    ~~~~~~~~~~~~~~~~~~^\n",
      "        array,\n",
      "        ^^^^^^\n",
      "    ...<2 lines>...\n",
      "        allow_nan=ensure_all_finite == \"allow-nan\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 120, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        X,\n",
      "        ^^\n",
      "    ...<4 lines>...\n",
      "        input_name=input_name,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "KNeighborsRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "4 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 197, in fit\n",
      "    X, y = validate_data(\n",
      "           ~~~~~~~~~~~~~^\n",
      "        self,\n",
      "        ^^^^^\n",
      "    ...<5 lines>...\n",
      "        accept_large_sparse=False,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n",
      "    X = check_array(\n",
      "        X,\n",
      "    ...<12 lines>...\n",
      "        input_name=\"X\",\n",
      "    )\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1105, in check_array\n",
      "    _assert_all_finite(\n",
      "    ~~~~~~~~~~~~~~~~~~^\n",
      "        array,\n",
      "        ^^^^^^\n",
      "    ...<2 lines>...\n",
      "        allow_nan=ensure_all_finite == \"allow-nan\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 120, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        X,\n",
      "        ^^\n",
      "    ...<4 lines>...\n",
      "        input_name=input_name,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "SVR does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "4 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 130, in fit\n",
      "    X, y = validate_data(\n",
      "           ~~~~~~~~~~~~~^\n",
      "        self,\n",
      "        ^^^^^\n",
      "    ...<6 lines>...\n",
      "        y_numeric=is_regressor(self),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n",
      "    X = check_array(\n",
      "        X,\n",
      "    ...<12 lines>...\n",
      "        input_name=\"X\",\n",
      "    )\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1105, in check_array\n",
      "    _assert_all_finite(\n",
      "    ~~~~~~~~~~~~~~~~~~^\n",
      "        array,\n",
      "        ^^^^^^\n",
      "    ...<2 lines>...\n",
      "        allow_nan=ensure_all_finite == \"allow-nan\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 120, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        X,\n",
      "        ^^\n",
      "    ...<4 lines>...\n",
      "        input_name=input_name,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "AdaBoostRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "4 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 658, in fit\n",
      "    X, y = validate_data(\n",
      "           ~~~~~~~~~~~~~^\n",
      "        self,\n",
      "        ^^^^^\n",
      "    ...<4 lines>...\n",
      "        multi_output=True,\n",
      "        ^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n",
      "    X = check_array(\n",
      "        X,\n",
      "    ...<12 lines>...\n",
      "        input_name=\"X\",\n",
      "    )\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1105, in check_array\n",
      "    _assert_all_finite(\n",
      "    ~~~~~~~~~~~~~~~~~~^\n",
      "        array,\n",
      "        ^^^^^^\n",
      "    ...<2 lines>...\n",
      "        allow_nan=ensure_all_finite == \"allow-nan\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 120, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        X,\n",
      "        ^^\n",
      "    ...<4 lines>...\n",
      "        input_name=input_name,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "GradientBoostingRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rev_rmse_mean</th>\n",
       "      <th>rev_rmse_std</th>\n",
       "      <th>ear_rmse_mean</th>\n",
       "      <th>ear_rmse_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RFR</td>\n",
       "      <td>2.650966e+09</td>\n",
       "      <td>1.759992e+09</td>\n",
       "      <td>7.074485e+08</td>\n",
       "      <td>5.427865e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ETR</td>\n",
       "      <td>3.305744e+09</td>\n",
       "      <td>1.898559e+09</td>\n",
       "      <td>6.759261e+08</td>\n",
       "      <td>3.403187e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DT</td>\n",
       "      <td>3.737771e+09</td>\n",
       "      <td>6.687072e+08</td>\n",
       "      <td>1.068367e+09</td>\n",
       "      <td>8.552103e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DUMMY</td>\n",
       "      <td>9.588735e+09</td>\n",
       "      <td>3.093268e+09</td>\n",
       "      <td>1.276041e+09</td>\n",
       "      <td>8.244618e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RIDGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LASSO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ABR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GBR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model  rev_rmse_mean  rev_rmse_std  ear_rmse_mean  ear_rmse_std\n",
       "8     RFR   2.650966e+09  1.759992e+09   7.074485e+08  5.427865e+08\n",
       "9     ETR   3.305744e+09  1.898559e+09   6.759261e+08  3.403187e+08\n",
       "6      DT   3.737771e+09  6.687072e+08   1.068367e+09  8.552103e+08\n",
       "0   DUMMY   9.588735e+09  3.093268e+09   1.276041e+09  8.244618e+08\n",
       "1      LR            NaN           NaN            NaN           NaN\n",
       "2   RIDGE            NaN           NaN            NaN           NaN\n",
       "3   LASSO            NaN           NaN            NaN           NaN\n",
       "4      EN            NaN           NaN            NaN           NaN\n",
       "5     KNN            NaN           NaN            NaN           NaN\n",
       "7     SVR            NaN           NaN            NaN           NaN\n",
       "10    ABR            NaN           NaN            NaN           NaN\n",
       "11    GBR            NaN           NaN            NaN           NaN"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets attempt this first with the raw data\n",
    "X_raw = raw_data.copy()\n",
    "# columns\n",
    "cat_cols = ['Sector', 'Exchange', 'Market Cap'] \n",
    "num_cols = [c for c in X_raw.columns if c not in cat_cols]\n",
    "\n",
    "# models (set seeds where applicable)\n",
    "models = [\n",
    "    ('DUMMY', DummyRegressor(strategy='mean')),\n",
    "    ('LR', LinearRegression()),\n",
    "    ('RIDGE', Ridge()),\n",
    "    ('LASSO', Lasso()),\n",
    "    ('EN', ElasticNet()),\n",
    "    ('KNN', KNeighborsRegressor()),\n",
    "    ('DT', DecisionTreeRegressor(random_state=random_state)),\n",
    "    ('SVR', SVR()),\n",
    "    ('RFR', RandomForestRegressor(random_state=random_state)),\n",
    "    ('ETR', ExtraTreesRegressor(random_state=random_state)),\n",
    "    ('ABR', AdaBoostRegressor(random_state=random_state)),\n",
    "    ('GBR', GradientBoostingRegressor(random_state=random_state)),\n",
    "]\n",
    "\n",
    "# preprocessing\n",
    "preproc = ColumnTransformer([\n",
    "    ('num', Pipeline([\n",
    "        ('scale', scaler)\n",
    "    ]), num_cols),\n",
    "    ('cat', Pipeline([\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]), cat_cols),\n",
    "])\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle = True, random_state=random_state)\n",
    "scorer = 'neg_root_mean_squared_error'  # RMSE as negative; flip sign after\n",
    "\n",
    "names, kfold_results_rev, kfold_results_ear = [], [], []\n",
    "\n",
    "for name, model in models:\n",
    "    pipe = Pipeline([('prep', preproc), ('model', model)])\n",
    "    rmse_rev = -cross_val_score(pipe, X_raw, y1_rev, cv=cv, scoring=scorer, n_jobs=-1)\n",
    "    rmse_ear = -cross_val_score(pipe, X_raw, y2_ear, cv=cv, scoring=scorer, n_jobs=-1)\n",
    "    names.append(name)\n",
    "    kfold_results_rev.append(rmse_rev)\n",
    "    kfold_results_ear.append(rmse_ear)\n",
    "\n",
    "# optional: summary\n",
    "summary = pd.DataFrame({\n",
    "    'model': names,\n",
    "    'rev_rmse_mean': [r.mean() for r in kfold_results_rev],\n",
    "    'rev_rmse_std':  [r.std()  for r in kfold_results_rev],\n",
    "    'ear_rmse_mean': [r.mean() for r in kfold_results_ear],\n",
    "    'ear_rmse_std':  [r.std()  for r in kfold_results_ear],\n",
    "}).sort_values('rev_rmse_mean')\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19903c6",
   "metadata": {},
   "source": [
    "Alright, that should hopefully run through all of our models and give us an output that we can plot the box and whisker plots. Let's just use a simple plot first to see if it worked then we can build a nicer one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e243fe41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison Predicting Revenue using Raw Financial Data: \\n5-fold Cross Validation')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(kfold_results_rev)\n",
    "ax.set_xticklabels(names)\n",
    "fig.set_size_inches(15,8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b00d1f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a better looking chart in altair\n",
    "df_rev = pd.DataFrame({\n",
    "    \"model\": np.concatenate([[n]*len(v) for n, v in zip(names, kfold_results_rev)]),\n",
    "    \"rmse\":  np.concatenate(kfold_results_rev)\n",
    "})\n",
    "\n",
    "df_rev['rmse'] = df_rev['rmse']/1_000_000\n",
    "\n",
    "rev_chart = alt.Chart(df_rev).mark_boxplot(size=33, opacity=0.5, median={'color': 'black', 'strokeWidth': 3}).encode(\n",
    "    x=alt.X('model:N', sort=names, title='Regression Model', axis = alt.Axis(labelAngle = 0, grid = False)),\n",
    "    y=alt.Y('rmse:Q', title='RMSE (millions of $)', axis = alt.Axis(grid = False)),\n",
    "    color = alt.Color('model:N', legend=None)\n",
    ").properties(\n",
    "    width=40*len(names), height=300,\n",
    "    title='Revenue'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7c32e06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a better looking chart in altair\n",
    "df_ear = pd.DataFrame({\n",
    "    \"model\": np.concatenate([[n]*len(v) for n, v in zip(names, kfold_results_ear)]),\n",
    "    \"rmse\":  np.concatenate(kfold_results_ear)\n",
    "})\n",
    "\n",
    "df_ear['rmse'] = df_ear['rmse']/1_000_000\n",
    "\n",
    "ear_chart = alt.Chart(df_ear).mark_boxplot(size=33, opacity=0.5, median={'color': 'black', 'strokeWidth': 3}).encode(\n",
    "    x=alt.X('model:N', sort=names, title='Regression Model', axis = alt.Axis(labelAngle = 0, grid = False)),\n",
    "    y=alt.Y('rmse:Q', title='RMSE (millions of $)', axis = alt.Axis(grid = False)),\n",
    "    color = alt.Color('model:N', legend=None)\n",
    ").properties(\n",
    "    width=40*len(names), height=300,\n",
    "    title='Net Income'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5211391a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-9387d222b8cd4427b11be00adf781d0f.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-9387d222b8cd4427b11be00adf781d0f.vega-embed details,\n",
       "  #altair-viz-9387d222b8cd4427b11be00adf781d0f.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-9387d222b8cd4427b11be00adf781d0f\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-9387d222b8cd4427b11be00adf781d0f\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-9387d222b8cd4427b11be00adf781d0f\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300, \"stroke\": null}}, \"hconcat\": [{\"data\": {\"name\": \"data-1af83db8b1cacb878ee6b14206a85c07\"}, \"mark\": {\"type\": \"boxplot\", \"median\": {\"color\": \"black\", \"strokeWidth\": 3}, \"opacity\": 0.5, \"size\": 33}, \"encoding\": {\"color\": {\"field\": \"model\", \"legend\": null, \"type\": \"nominal\"}, \"x\": {\"axis\": {\"grid\": false, \"labelAngle\": 0}, \"field\": \"model\", \"sort\": [\"DUMMY\", \"LR\", \"RIDGE\", \"LASSO\", \"EN\", \"KNN\", \"DT\", \"SVR\", \"RFR\", \"ETR\", \"ABR\", \"GBR\"], \"title\": \"Regression Model\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false}, \"field\": \"rmse\", \"title\": \"RMSE (millions of $)\", \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Revenue\", \"width\": 480}, {\"data\": {\"name\": \"data-74d6db877d800d6096ab8473bb952276\"}, \"mark\": {\"type\": \"boxplot\", \"median\": {\"color\": \"black\", \"strokeWidth\": 3}, \"opacity\": 0.5, \"size\": 33}, \"encoding\": {\"color\": {\"field\": \"model\", \"legend\": null, \"type\": \"nominal\"}, \"x\": {\"axis\": {\"grid\": false, \"labelAngle\": 0}, \"field\": \"model\", \"sort\": [\"DUMMY\", \"LR\", \"RIDGE\", \"LASSO\", \"EN\", \"KNN\", \"DT\", \"SVR\", \"RFR\", \"ETR\", \"ABR\", \"GBR\"], \"title\": \"Regression Model\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false}, \"field\": \"rmse\", \"title\": \"RMSE (millions of $)\", \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Net Income\", \"width\": 480}], \"title\": {\"text\": \"Raw Fundamental Feature Space\", \"anchor\": \"middle\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-1af83db8b1cacb878ee6b14206a85c07\": [{\"model\": \"DUMMY\", \"rmse\": 12601.616489160135}, {\"model\": \"DUMMY\", \"rmse\": 5191.7006146522845}, {\"model\": \"DUMMY\", \"rmse\": 9136.731986758925}, {\"model\": \"DUMMY\", \"rmse\": 13468.243334278626}, {\"model\": \"DUMMY\", \"rmse\": 7545.385036034495}, {\"model\": \"LR\", \"rmse\": null}, {\"model\": \"LR\", \"rmse\": null}, {\"model\": \"LR\", \"rmse\": null}, {\"model\": \"LR\", \"rmse\": null}, {\"model\": \"LR\", \"rmse\": null}, {\"model\": \"RIDGE\", \"rmse\": null}, {\"model\": \"RIDGE\", \"rmse\": null}, {\"model\": \"RIDGE\", \"rmse\": null}, {\"model\": \"RIDGE\", \"rmse\": null}, {\"model\": \"RIDGE\", \"rmse\": null}, {\"model\": \"LASSO\", \"rmse\": null}, {\"model\": \"LASSO\", \"rmse\": null}, {\"model\": \"LASSO\", \"rmse\": null}, {\"model\": \"LASSO\", \"rmse\": null}, {\"model\": \"LASSO\", \"rmse\": null}, {\"model\": \"EN\", \"rmse\": null}, {\"model\": \"EN\", \"rmse\": null}, {\"model\": \"EN\", \"rmse\": null}, {\"model\": \"EN\", \"rmse\": null}, {\"model\": \"EN\", \"rmse\": null}, {\"model\": \"KNN\", \"rmse\": null}, {\"model\": \"KNN\", \"rmse\": null}, {\"model\": \"KNN\", \"rmse\": null}, {\"model\": \"KNN\", \"rmse\": null}, {\"model\": \"KNN\", \"rmse\": null}, {\"model\": \"DT\", \"rmse\": 3591.935719256363}, {\"model\": \"DT\", \"rmse\": 3031.022079268611}, {\"model\": \"DT\", \"rmse\": 3931.8732300155293}, {\"model\": \"DT\", \"rmse\": 4921.589979650537}, {\"model\": \"DT\", \"rmse\": 3212.43173922095}, {\"model\": \"SVR\", \"rmse\": null}, {\"model\": \"SVR\", \"rmse\": null}, {\"model\": \"SVR\", \"rmse\": null}, {\"model\": \"SVR\", \"rmse\": null}, {\"model\": \"SVR\", \"rmse\": null}, {\"model\": \"RFR\", \"rmse\": 4606.24343189673}, {\"model\": \"RFR\", \"rmse\": 1229.5124196810725}, {\"model\": \"RFR\", \"rmse\": 1113.016024780606}, {\"model\": \"RFR\", \"rmse\": 4993.516907706534}, {\"model\": \"RFR\", \"rmse\": 1312.5401863951788}, {\"model\": \"ETR\", \"rmse\": 5813.798475970901}, {\"model\": \"ETR\", \"rmse\": 2376.0771932447137}, {\"model\": \"ETR\", \"rmse\": 1293.101165909567}, {\"model\": \"ETR\", \"rmse\": 5356.308708299046}, {\"model\": \"ETR\", \"rmse\": 1689.433188218471}, {\"model\": \"ABR\", \"rmse\": null}, {\"model\": \"ABR\", \"rmse\": null}, {\"model\": \"ABR\", \"rmse\": null}, {\"model\": \"ABR\", \"rmse\": null}, {\"model\": \"ABR\", \"rmse\": null}, {\"model\": \"GBR\", \"rmse\": null}, {\"model\": \"GBR\", \"rmse\": null}, {\"model\": \"GBR\", \"rmse\": null}, {\"model\": \"GBR\", \"rmse\": null}, {\"model\": \"GBR\", \"rmse\": null}], \"data-74d6db877d800d6096ab8473bb952276\": [{\"model\": \"DUMMY\", \"rmse\": 1105.5200394089509}, {\"model\": \"DUMMY\", \"rmse\": 500.1867453190943}, {\"model\": \"DUMMY\", \"rmse\": 1517.2549269174797}, {\"model\": \"DUMMY\", \"rmse\": 2737.8659041303927}, {\"model\": \"DUMMY\", \"rmse\": 519.375468004107}, {\"model\": \"LR\", \"rmse\": null}, {\"model\": \"LR\", \"rmse\": null}, {\"model\": \"LR\", \"rmse\": null}, {\"model\": \"LR\", \"rmse\": null}, {\"model\": \"LR\", \"rmse\": null}, {\"model\": \"RIDGE\", \"rmse\": null}, {\"model\": \"RIDGE\", \"rmse\": null}, {\"model\": \"RIDGE\", \"rmse\": null}, {\"model\": \"RIDGE\", \"rmse\": null}, {\"model\": \"RIDGE\", \"rmse\": null}, {\"model\": \"LASSO\", \"rmse\": null}, {\"model\": \"LASSO\", \"rmse\": null}, {\"model\": \"LASSO\", \"rmse\": null}, {\"model\": \"LASSO\", \"rmse\": null}, {\"model\": \"LASSO\", \"rmse\": null}, {\"model\": \"EN\", \"rmse\": null}, {\"model\": \"EN\", \"rmse\": null}, {\"model\": \"EN\", \"rmse\": null}, {\"model\": \"EN\", \"rmse\": null}, {\"model\": \"EN\", \"rmse\": null}, {\"model\": \"KNN\", \"rmse\": null}, {\"model\": \"KNN\", \"rmse\": null}, {\"model\": \"KNN\", \"rmse\": null}, {\"model\": \"KNN\", \"rmse\": null}, {\"model\": \"KNN\", \"rmse\": null}, {\"model\": \"DT\", \"rmse\": 620.1639143032862}, {\"model\": \"DT\", \"rmse\": 296.29984872958016}, {\"model\": \"DT\", \"rmse\": 880.5726945346624}, {\"model\": \"DT\", \"rmse\": 2729.833009532818}, {\"model\": \"DT\", \"rmse\": 814.9631896166187}, {\"model\": \"SVR\", \"rmse\": null}, {\"model\": \"SVR\", \"rmse\": null}, {\"model\": \"SVR\", \"rmse\": null}, {\"model\": \"SVR\", \"rmse\": null}, {\"model\": \"SVR\", \"rmse\": null}, {\"model\": \"RFR\", \"rmse\": 519.8258544914382}, {\"model\": \"RFR\", \"rmse\": 224.05928033621333}, {\"model\": \"RFR\", \"rmse\": 519.1261064172141}, {\"model\": \"RFR\", \"rmse\": 1769.3836156348955}, {\"model\": \"RFR\", \"rmse\": 504.847853092955}, {\"model\": \"ETR\", \"rmse\": 585.7421235101303}, {\"model\": \"ETR\", \"rmse\": 316.63197579600114}, {\"model\": \"ETR\", \"rmse\": 531.334616183238}, {\"model\": \"ETR\", \"rmse\": 1322.5982220537526}, {\"model\": \"ETR\", \"rmse\": 623.3236737984525}, {\"model\": \"ABR\", \"rmse\": null}, {\"model\": \"ABR\", \"rmse\": null}, {\"model\": \"ABR\", \"rmse\": null}, {\"model\": \"ABR\", \"rmse\": null}, {\"model\": \"ABR\", \"rmse\": null}, {\"model\": \"GBR\", \"rmse\": null}, {\"model\": \"GBR\", \"rmse\": null}, {\"model\": \"GBR\", \"rmse\": null}, {\"model\": \"GBR\", \"rmse\": null}, {\"model\": \"GBR\", \"rmse\": null}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chart = (rev_chart | ear_chart).properties(\n",
    "    title=alt.TitleParams('Raw Fundamental Feature Space', anchor='middle'))\n",
    "full_chart.configure_view(stroke=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90727086",
   "metadata": {},
   "source": [
    "## Engineered Only Data\n",
    "Now that we have seen the performance of the fundamentals. Let's look at the engineered data by itself. I have a feeling this will struggle to predict the absolute revenue value because it's not included in the orginal but I may be wrong. Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a6ebe972",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 618, in fit\n    X, y = validate_data(\n           ~~~~~~~~~~~~~^\n        self,\n        ^^^^^\n    ...<5 lines>...\n        force_writeable=True,\n        ^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n    X = check_array(\n        X,\n    ...<12 lines>...\n        input_name=\"X\",\n    )\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1105, in check_array\n    _assert_all_finite(\n    ~~~~~~~~~~~~~~~~~~^\n        array,\n        ^^^^^^\n    ...<2 lines>...\n        allow_nan=ensure_all_finite == \"allow-nan\",\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 120, in _assert_all_finite\n    _assert_all_finite_element_wise(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        X,\n        ^^\n    ...<4 lines>...\n        input_name=input_name,\n        ^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 169, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[32m     39\u001b[39m     pipe = Pipeline([(\u001b[33m'\u001b[39m\u001b[33mprep\u001b[39m\u001b[33m'\u001b[39m, preproc), (\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m, model)])\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     rmse_rev = -\u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_eng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my1_rev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     rmse_ear = -cross_val_score(pipe, X_eng, y2_ear, cv=cv, scoring=scorer, n_jobs=-\u001b[32m1\u001b[39m)\n\u001b[32m     42\u001b[39m     names.append(name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:677\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    674\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    675\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:419\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    398\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m    399\u001b[39m results = parallel(\n\u001b[32m    400\u001b[39m     delayed(_fit_and_score)(\n\u001b[32m    401\u001b[39m         clone(estimator),\n\u001b[32m   (...)\u001b[39m\u001b[32m    416\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[32m    417\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    423\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[32m    424\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:505\u001b[39m, in \u001b[36m_warn_or_raise_about_fit_failures\u001b[39m\u001b[34m(results, error_score)\u001b[39m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits == num_fits:\n\u001b[32m    499\u001b[39m     all_fits_failed_message = (\n\u001b[32m    500\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    501\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    502\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou can try to debug the error by setting error_score=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    503\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    508\u001b[39m     some_fits_failed_message = (\n\u001b[32m    509\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    510\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe score on these train-test partitions for these parameters\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    514\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 618, in fit\n    X, y = validate_data(\n           ~~~~~~~~~~~~~^\n        self,\n        ^^^^^\n    ...<5 lines>...\n        force_writeable=True,\n        ^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n    X = check_array(\n        X,\n    ...<12 lines>...\n        input_name=\"X\",\n    )\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1105, in check_array\n    _assert_all_finite(\n    ~~~~~~~~~~~~~~~~~~^\n        array,\n        ^^^^^^\n    ...<2 lines>...\n        allow_nan=ensure_all_finite == \"allow-nan\",\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 120, in _assert_all_finite\n    _assert_all_finite_element_wise(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        X,\n        ^^\n    ...<4 lines>...\n        input_name=input_name,\n        ^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 169, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    }
   ],
   "source": [
    "# Lets attempt this first with the raw data\n",
    "X_eng = eng_data.copy()\n",
    "# columns\n",
    "cat_cols = ['Sector', 'Exchange', 'Market Cap'] \n",
    "num_cols = [c for c in X_eng.columns if c not in cat_cols]\n",
    "\n",
    "# models (set seeds where applicable)\n",
    "models = [\n",
    "    ('DUMMY', DummyRegressor(strategy='mean')),\n",
    "    ('LR', LinearRegression()),\n",
    "    ('RIDGE', Ridge()),\n",
    "    ('LASSO', Lasso()),\n",
    "    ('EN', ElasticNet()),\n",
    "    ('KNN', KNeighborsRegressor()),\n",
    "    ('DT', DecisionTreeRegressor(random_state=random_state)),\n",
    "    ('SVR', SVR()),\n",
    "    ('RFR', RandomForestRegressor(random_state=random_state)),\n",
    "    ('ETR', ExtraTreesRegressor(random_state=random_state)),\n",
    "    ('ABR', AdaBoostRegressor(random_state=random_state)),\n",
    "    ('GBR', GradientBoostingRegressor(random_state=random_state)),\n",
    "]\n",
    "\n",
    "# preprocessing\n",
    "preproc = ColumnTransformer([\n",
    "    ('num', Pipeline([\n",
    "        ('scale', scaler)\n",
    "    ]), num_cols),\n",
    "    ('cat', Pipeline([\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]), cat_cols),\n",
    "])\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle = True, random_state=random_state)\n",
    "scorer = 'neg_root_mean_squared_error'  # RMSE as negative; flip sign after\n",
    "\n",
    "names, kfold_results_rev, kfold_results_ear = [], [], []\n",
    "\n",
    "for name, model in models:\n",
    "    pipe = Pipeline([('prep', preproc), ('model', model)])\n",
    "    rmse_rev = -cross_val_score(pipe, X_eng, y1_rev, cv=cv, scoring=scorer, n_jobs=-1)\n",
    "    rmse_ear = -cross_val_score(pipe, X_eng, y2_ear, cv=cv, scoring=scorer, n_jobs=-1)\n",
    "    names.append(name)\n",
    "    kfold_results_rev.append(rmse_rev)\n",
    "    kfold_results_ear.append(rmse_ear)\n",
    "\n",
    "# optional: summary\n",
    "summary = pd.DataFrame({\n",
    "    'model': names,\n",
    "    'rev_rmse_mean': [r.mean() for r in kfold_results_rev],\n",
    "    'rev_rmse_std':  [r.std()  for r in kfold_results_rev],\n",
    "    'ear_rmse_mean': [r.mean() for r in kfold_results_ear],\n",
    "    'ear_rmse_std':  [r.std()  for r in kfold_results_ear],\n",
    "}).sort_values('rev_rmse_mean')\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7137bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a better looking chart in altair\n",
    "df_rev = pd.DataFrame({\n",
    "    \"model\": np.concatenate([[n]*len(v) for n, v in zip(names, kfold_results_rev)]),\n",
    "    \"rmse\":  np.concatenate(kfold_results_rev)\n",
    "})\n",
    "\n",
    "df_rev['rmse'] = df_rev['rmse']/1_000_000\n",
    "\n",
    "rev_chart2 = alt.Chart(df_rev).mark_boxplot(size=33, opacity=0.5, median={'color': 'black', 'strokeWidth': 3}).encode(\n",
    "    x=alt.X('model:N', sort=names, title='Regression Model', axis = alt.Axis(labelAngle = 0, grid = False)),\n",
    "    y=alt.Y('rmse:Q', title='RMSE (millions of $)', axis = alt.Axis(grid = False)),\n",
    "    color = alt.Color('model:N', legend=None)\n",
    ").properties(\n",
    "    width=40*len(names), height=300,\n",
    "    title='Revenue'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3520be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a better looking chart in altair\n",
    "df_ear = pd.DataFrame({\n",
    "    \"model\": np.concatenate([[n]*len(v) for n, v in zip(names, kfold_results_ear)]),\n",
    "    \"rmse\":  np.concatenate(kfold_results_ear)\n",
    "})\n",
    "\n",
    "df_ear['rmse'] = df_ear['rmse']/1_000_000\n",
    "\n",
    "ear_chart2 = alt.Chart(df_ear).mark_boxplot(size=33, opacity=0.5, median={'color': 'black', 'strokeWidth': 3}).encode(\n",
    "    x=alt.X('model:N', sort=names, title='Regression Model', axis = alt.Axis(labelAngle = 0, grid = False)),\n",
    "    y=alt.Y('rmse:Q', title='RMSE (millions of $)', axis = alt.Axis(grid = False)),\n",
    "    color = alt.Color('model:N', legend=None)\n",
    ").properties(\n",
    "    width=40*len(names), height=300,\n",
    "    title='Net Income'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869fb916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-63e3d9f6f61d4ab3bac39b19a3ec1c5b.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-63e3d9f6f61d4ab3bac39b19a3ec1c5b.vega-embed details,\n",
       "  #altair-viz-63e3d9f6f61d4ab3bac39b19a3ec1c5b.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-63e3d9f6f61d4ab3bac39b19a3ec1c5b\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-63e3d9f6f61d4ab3bac39b19a3ec1c5b\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-63e3d9f6f61d4ab3bac39b19a3ec1c5b\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300, \"stroke\": null}}, \"hconcat\": [{\"data\": {\"name\": \"data-49bd409fa04e18edd5766f5b3d0bb945\"}, \"mark\": {\"type\": \"boxplot\", \"median\": {\"color\": \"black\", \"strokeWidth\": 3}, \"opacity\": 0.5, \"size\": 33}, \"encoding\": {\"color\": {\"field\": \"model\", \"legend\": null, \"type\": \"nominal\"}, \"x\": {\"axis\": {\"grid\": false, \"labelAngle\": 0}, \"field\": \"model\", \"sort\": [\"DUMMY\", \"LR\", \"RIDGE\", \"LASSO\", \"EN\", \"KNN\", \"DT\", \"SVR\", \"RFR\", \"ETR\", \"ABR\", \"GBR\"], \"title\": \"Regression Model\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false}, \"field\": \"rmse\", \"title\": \"RMSE (millions of $)\", \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Revenue\", \"width\": 480}, {\"data\": {\"name\": \"data-4aeb8efa1eb8e28597b63c2697cbfa21\"}, \"mark\": {\"type\": \"boxplot\", \"median\": {\"color\": \"black\", \"strokeWidth\": 3}, \"opacity\": 0.5, \"size\": 33}, \"encoding\": {\"color\": {\"field\": \"model\", \"legend\": null, \"type\": \"nominal\"}, \"x\": {\"axis\": {\"grid\": false, \"labelAngle\": 0}, \"field\": \"model\", \"sort\": [\"DUMMY\", \"LR\", \"RIDGE\", \"LASSO\", \"EN\", \"KNN\", \"DT\", \"SVR\", \"RFR\", \"ETR\", \"ABR\", \"GBR\"], \"title\": \"Regression Model\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false}, \"field\": \"rmse\", \"title\": \"RMSE (millions of $)\", \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Net Income\", \"width\": 480}], \"title\": {\"text\": \"Engineered Feature Space\", \"anchor\": \"middle\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-49bd409fa04e18edd5766f5b3d0bb945\": [{\"model\": \"DUMMY\", \"rmse\": 12787.60384183147}, {\"model\": \"DUMMY\", \"rmse\": 6077.478958107764}, {\"model\": \"DUMMY\", \"rmse\": 7852.07307076927}, {\"model\": \"DUMMY\", \"rmse\": 12706.694262667083}, {\"model\": \"DUMMY\", \"rmse\": 8770.744163137864}, {\"model\": \"LR\", \"rmse\": 10821.891380559671}, {\"model\": \"LR\", \"rmse\": 6427.184889094979}, {\"model\": \"LR\", \"rmse\": 6046.859739325045}, {\"model\": \"LR\", \"rmse\": 8812.492501213797}, {\"model\": \"LR\", \"rmse\": 8917.227889193897}, {\"model\": \"RIDGE\", \"rmse\": 10820.955413729984}, {\"model\": \"RIDGE\", \"rmse\": 5936.887561742372}, {\"model\": \"RIDGE\", \"rmse\": 5785.344723687073}, {\"model\": \"RIDGE\", \"rmse\": 9256.2043542556}, {\"model\": \"RIDGE\", \"rmse\": 8505.789743541158}, {\"model\": \"LASSO\", \"rmse\": 10821.65681942802}, {\"model\": \"LASSO\", \"rmse\": 6427.186397231974}, {\"model\": \"LASSO\", \"rmse\": 6046.726455227086}, {\"model\": \"LASSO\", \"rmse\": 8812.508451571439}, {\"model\": \"LASSO\", \"rmse\": 8916.413894495263}, {\"model\": \"EN\", \"rmse\": 11989.728150365947}, {\"model\": \"EN\", \"rmse\": 5165.325650915977}, {\"model\": \"EN\", \"rmse\": 7101.304523144149}, {\"model\": \"EN\", \"rmse\": 11989.36222314085}, {\"model\": \"EN\", \"rmse\": 8010.502772093782}, {\"model\": \"KNN\", \"rmse\": 12036.691598811534}, {\"model\": \"KNN\", \"rmse\": 5031.590520746698}, {\"model\": \"KNN\", \"rmse\": 7199.425704946406}, {\"model\": \"KNN\", \"rmse\": 11905.477074839888}, {\"model\": \"KNN\", \"rmse\": 8580.738187163706}, {\"model\": \"DT\", \"rmse\": 6415.996329186189}, {\"model\": \"DT\", \"rmse\": 9297.738212332197}, {\"model\": \"DT\", \"rmse\": 5421.7622488290845}, {\"model\": \"DT\", \"rmse\": 5579.190814179891}, {\"model\": \"DT\", \"rmse\": 5329.52359019969}, {\"model\": \"SVR\", \"rmse\": 13064.982004694677}, {\"model\": \"SVR\", \"rmse\": 6350.3766936187285}, {\"model\": \"SVR\", \"rmse\": 8203.201594301494}, {\"model\": \"SVR\", \"rmse\": 12987.834713710039}, {\"model\": \"SVR\", \"rmse\": 8877.241333903963}, {\"model\": \"RFR\", \"rmse\": 7541.237000043439}, {\"model\": \"RFR\", \"rmse\": 7234.706233008463}, {\"model\": \"RFR\", \"rmse\": 4420.903935099489}, {\"model\": \"RFR\", \"rmse\": 7326.15477388617}, {\"model\": \"RFR\", \"rmse\": 5027.118553227127}, {\"model\": \"ETR\", \"rmse\": 8054.652508797339}, {\"model\": \"ETR\", \"rmse\": 4029.5397136890138}, {\"model\": \"ETR\", \"rmse\": 3100.5778241193266}, {\"model\": \"ETR\", \"rmse\": 7120.315184880896}, {\"model\": \"ETR\", \"rmse\": 6211.995423287581}, {\"model\": \"ABR\", \"rmse\": 9404.777681797255}, {\"model\": \"ABR\", \"rmse\": 9332.454744318451}, {\"model\": \"ABR\", \"rmse\": 5865.407508944504}, {\"model\": \"ABR\", \"rmse\": 10491.24174251723}, {\"model\": \"ABR\", \"rmse\": 8171.270953458604}, {\"model\": \"GBR\", \"rmse\": 5599.495318039817}, {\"model\": \"GBR\", \"rmse\": 6834.119780516619}, {\"model\": \"GBR\", \"rmse\": 4116.763136159413}, {\"model\": \"GBR\", \"rmse\": 7143.510341321735}, {\"model\": \"GBR\", \"rmse\": 3709.297196494301}], \"data-4aeb8efa1eb8e28597b63c2697cbfa21\": [{\"model\": \"DUMMY\", \"rmse\": 916.4380151999005}, {\"model\": \"DUMMY\", \"rmse\": 1297.4962393795124}, {\"model\": \"DUMMY\", \"rmse\": 1863.7191067462393}, {\"model\": \"DUMMY\", \"rmse\": 2074.94830401245}, {\"model\": \"DUMMY\", \"rmse\": 673.9992753708216}, {\"model\": \"LR\", \"rmse\": 817.4849373142287}, {\"model\": \"LR\", \"rmse\": 682.959700120298}, {\"model\": \"LR\", \"rmse\": 978.5491712302647}, {\"model\": \"LR\", \"rmse\": 1302.6223267539153}, {\"model\": \"LR\", \"rmse\": 921.136941267385}, {\"model\": \"RIDGE\", \"rmse\": 786.4594157357989}, {\"model\": \"RIDGE\", \"rmse\": 697.2312986611292}, {\"model\": \"RIDGE\", \"rmse\": 1094.270405634486}, {\"model\": \"RIDGE\", \"rmse\": 1323.19436526431}, {\"model\": \"RIDGE\", \"rmse\": 817.7290011681536}, {\"model\": \"LASSO\", \"rmse\": 817.4578656658457}, {\"model\": \"LASSO\", \"rmse\": 682.9693529550854}, {\"model\": \"LASSO\", \"rmse\": 978.5189195043238}, {\"model\": \"LASSO\", \"rmse\": 1302.6166438788928}, {\"model\": \"LASSO\", \"rmse\": 921.0741900266224}, {\"model\": \"EN\", \"rmse\": 798.5217175821591}, {\"model\": \"EN\", \"rmse\": 1187.5932961328192}, {\"model\": \"EN\", \"rmse\": 1786.9790329210903}, {\"model\": \"EN\", \"rmse\": 1986.754055785419}, {\"model\": \"EN\", \"rmse\": 595.2096141092587}, {\"model\": \"KNN\", \"rmse\": 799.3160766437555}, {\"model\": \"KNN\", \"rmse\": 778.601419211135}, {\"model\": \"KNN\", \"rmse\": 1763.4395102049252}, {\"model\": \"KNN\", \"rmse\": 1771.9853656057553}, {\"model\": \"KNN\", \"rmse\": 571.3361450528296}, {\"model\": \"DT\", \"rmse\": 656.0800395618402}, {\"model\": \"DT\", \"rmse\": 787.7058480408089}, {\"model\": \"DT\", \"rmse\": 940.7303016900796}, {\"model\": \"DT\", \"rmse\": 1389.3593522827368}, {\"model\": \"DT\", \"rmse\": 887.599962612554}, {\"model\": \"SVR\", \"rmse\": 942.9786937381182}, {\"model\": \"SVR\", \"rmse\": 1324.080295578571}, {\"model\": \"SVR\", \"rmse\": 1892.9308275842213}, {\"model\": \"SVR\", \"rmse\": 2094.1627315185833}, {\"model\": \"SVR\", \"rmse\": 677.6543053115021}, {\"model\": \"RFR\", \"rmse\": 619.1305492222881}, {\"model\": \"RFR\", \"rmse\": 307.44498681399824}, {\"model\": \"RFR\", \"rmse\": 739.0028198733388}, {\"model\": \"RFR\", \"rmse\": 1144.759007386523}, {\"model\": \"RFR\", \"rmse\": 445.1219449326818}, {\"model\": \"ETR\", \"rmse\": 553.3610304253714}, {\"model\": \"ETR\", \"rmse\": 387.79813781129667}, {\"model\": \"ETR\", \"rmse\": 699.2560595831644}, {\"model\": \"ETR\", \"rmse\": 1194.9300926963115}, {\"model\": \"ETR\", \"rmse\": 741.7047453195752}, {\"model\": \"ABR\", \"rmse\": 698.9025777189274}, {\"model\": \"ABR\", \"rmse\": 558.7300163984949}, {\"model\": \"ABR\", \"rmse\": 875.0030095923129}, {\"model\": \"ABR\", \"rmse\": 912.213888881783}, {\"model\": \"ABR\", \"rmse\": 333.31568610264213}, {\"model\": \"GBR\", \"rmse\": 666.5138825313824}, {\"model\": \"GBR\", \"rmse\": 377.11631592411214}, {\"model\": \"GBR\", \"rmse\": 798.8438295103458}, {\"model\": \"GBR\", \"rmse\": 1235.6668580287078}, {\"model\": \"GBR\", \"rmse\": 475.68252500143495}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chart2 = (rev_chart2 | ear_chart2).properties(\n",
    "    title=alt.TitleParams('Engineered Feature Space', anchor='middle'))\n",
    "full_chart2.configure_view(stroke=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e568df9",
   "metadata": {},
   "source": [
    "## Full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f7b848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rev_rmse_mean</th>\n",
       "      <th>rev_rmse_std</th>\n",
       "      <th>ear_rmse_mean</th>\n",
       "      <th>ear_rmse_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GBR</td>\n",
       "      <td>2.213514e+09</td>\n",
       "      <td>1.351061e+09</td>\n",
       "      <td>6.894875e+08</td>\n",
       "      <td>2.433559e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ABR</td>\n",
       "      <td>2.585076e+09</td>\n",
       "      <td>1.231032e+09</td>\n",
       "      <td>6.255660e+08</td>\n",
       "      <td>1.683944e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ETR</td>\n",
       "      <td>2.678715e+09</td>\n",
       "      <td>1.470072e+09</td>\n",
       "      <td>6.470136e+08</td>\n",
       "      <td>2.543649e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RFR</td>\n",
       "      <td>2.685895e+09</td>\n",
       "      <td>1.757646e+09</td>\n",
       "      <td>6.262135e+08</td>\n",
       "      <td>2.556276e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DT</td>\n",
       "      <td>2.821250e+09</td>\n",
       "      <td>1.128797e+09</td>\n",
       "      <td>7.904396e+08</td>\n",
       "      <td>2.048527e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RIDGE</td>\n",
       "      <td>7.674605e+09</td>\n",
       "      <td>1.852961e+09</td>\n",
       "      <td>9.487690e+08</td>\n",
       "      <td>2.243704e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN</td>\n",
       "      <td>7.891828e+09</td>\n",
       "      <td>2.925327e+09</td>\n",
       "      <td>1.021972e+09</td>\n",
       "      <td>4.652107e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LASSO</td>\n",
       "      <td>7.997365e+09</td>\n",
       "      <td>1.640274e+09</td>\n",
       "      <td>9.662212e+08</td>\n",
       "      <td>1.947566e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>8.059928e+09</td>\n",
       "      <td>1.636350e+09</td>\n",
       "      <td>9.658852e+08</td>\n",
       "      <td>1.957586e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EN</td>\n",
       "      <td>8.472970e+09</td>\n",
       "      <td>2.667800e+09</td>\n",
       "      <td>1.239450e+09</td>\n",
       "      <td>5.309227e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DUMMY</td>\n",
       "      <td>9.638919e+09</td>\n",
       "      <td>2.681636e+09</td>\n",
       "      <td>1.365320e+09</td>\n",
       "      <td>5.359092e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVR</td>\n",
       "      <td>9.896727e+09</td>\n",
       "      <td>2.686141e+09</td>\n",
       "      <td>1.386361e+09</td>\n",
       "      <td>5.404310e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model  rev_rmse_mean  rev_rmse_std  ear_rmse_mean  ear_rmse_std\n",
       "11    GBR   2.213514e+09  1.351061e+09   6.894875e+08  2.433559e+08\n",
       "10    ABR   2.585076e+09  1.231032e+09   6.255660e+08  1.683944e+08\n",
       "9     ETR   2.678715e+09  1.470072e+09   6.470136e+08  2.543649e+08\n",
       "8     RFR   2.685895e+09  1.757646e+09   6.262135e+08  2.556276e+08\n",
       "6      DT   2.821250e+09  1.128797e+09   7.904396e+08  2.048527e+08\n",
       "2   RIDGE   7.674605e+09  1.852961e+09   9.487690e+08  2.243704e+08\n",
       "5     KNN   7.891828e+09  2.925327e+09   1.021972e+09  4.652107e+08\n",
       "3   LASSO   7.997365e+09  1.640274e+09   9.662212e+08  1.947566e+08\n",
       "1      LR   8.059928e+09  1.636350e+09   9.658852e+08  1.957586e+08\n",
       "4      EN   8.472970e+09  2.667800e+09   1.239450e+09  5.309227e+08\n",
       "0   DUMMY   9.638919e+09  2.681636e+09   1.365320e+09  5.359092e+08\n",
       "7     SVR   9.896727e+09  2.686141e+09   1.386361e+09  5.404310e+08"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets attempt this first with the raw data\n",
    "X_tot = tot_data.copy()\n",
    "# columns\n",
    "cat_cols = ['Sector', 'Exchange', 'Market Cap'] \n",
    "num_cols = [c for c in X_tot.columns if c not in cat_cols]\n",
    "\n",
    "# models (set seeds where applicable)\n",
    "models = [\n",
    "    ('DUMMY', DummyRegressor(strategy='mean')),\n",
    "    ('LR', LinearRegression()),\n",
    "    ('RIDGE', Ridge()),\n",
    "    ('LASSO', Lasso()),\n",
    "    ('EN', ElasticNet()),\n",
    "    ('KNN', KNeighborsRegressor()),\n",
    "    ('DT', DecisionTreeRegressor(random_state=random_state)),\n",
    "    ('SVR', SVR()),\n",
    "    ('RFR', RandomForestRegressor(random_state=random_state)),\n",
    "    ('ETR', ExtraTreesRegressor(random_state=random_state)),\n",
    "    ('ABR', AdaBoostRegressor(random_state=random_state)),\n",
    "    ('GBR', GradientBoostingRegressor(random_state=random_state)),\n",
    "]\n",
    "\n",
    "# preprocessing\n",
    "preproc = ColumnTransformer([\n",
    "    ('num', Pipeline([\n",
    "        ('scale', scaler)\n",
    "    ]), num_cols),\n",
    "    ('cat', Pipeline([\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]), cat_cols),\n",
    "])\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle = True, random_state=random_state)\n",
    "scorer = 'neg_root_mean_squared_error'  # RMSE as negative; flip sign after\n",
    "\n",
    "names, kfold_results_rev, kfold_results_ear = [], [], []\n",
    "\n",
    "for name, model in models:\n",
    "    pipe = Pipeline([('prep', preproc), ('model', model)])\n",
    "    rmse_rev = -cross_val_score(pipe, X_tot, y1_rev, cv=cv, scoring=scorer, n_jobs=-1)\n",
    "    rmse_ear = -cross_val_score(pipe, X_tot, y2_ear, cv=cv, scoring=scorer, n_jobs=-1)\n",
    "    names.append(name)\n",
    "    kfold_results_rev.append(rmse_rev)\n",
    "    kfold_results_ear.append(rmse_ear)\n",
    "\n",
    "# optional: summary\n",
    "summary = pd.DataFrame({\n",
    "    'model': names,\n",
    "    'rev_rmse_mean': [r.mean() for r in kfold_results_rev],\n",
    "    'rev_rmse_std':  [r.std()  for r in kfold_results_rev],\n",
    "    'ear_rmse_mean': [r.mean() for r in kfold_results_ear],\n",
    "    'ear_rmse_std':  [r.std()  for r in kfold_results_ear],\n",
    "}).sort_values('rev_rmse_mean')\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d91bac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a better looking chart in altair\n",
    "df_rev = pd.DataFrame({\n",
    "    \"model\": np.concatenate([[n]*len(v) for n, v in zip(names, kfold_results_rev)]),\n",
    "    \"rmse\":  np.concatenate(kfold_results_rev)\n",
    "})\n",
    "\n",
    "df_rev['rmse'] = df_rev['rmse']/1_000_000\n",
    "\n",
    "rev_chart3 = alt.Chart(df_rev).mark_boxplot(size=33, opacity=0.5, median={'color': 'black', 'strokeWidth': 3}).encode(\n",
    "    x=alt.X('model:N', sort=names, title='Regression Model', axis = alt.Axis(labelAngle = 0, grid = False)),\n",
    "    y=alt.Y('rmse:Q', title='RMSE (millions of $)', axis = alt.Axis(grid = False)),\n",
    "    color = alt.Color('model:N', legend=None)\n",
    ").properties(\n",
    "    width=40*len(names), height=300,\n",
    "    title='Revenue'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb429220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a better looking chart in altair\n",
    "df_ear = pd.DataFrame({\n",
    "    \"model\": np.concatenate([[n]*len(v) for n, v in zip(names, kfold_results_ear)]),\n",
    "    \"rmse\":  np.concatenate(kfold_results_ear)\n",
    "})\n",
    "\n",
    "df_ear['rmse'] = df_ear['rmse']/1_000_000\n",
    "\n",
    "ear_chart3 = alt.Chart(df_ear).mark_boxplot(size=33, opacity=0.5, median={'color': 'black', 'strokeWidth': 3}).encode(\n",
    "    x=alt.X('model:N', sort=names, title='Regression Model', axis = alt.Axis(labelAngle = 0, grid = False)),\n",
    "    y=alt.Y('rmse:Q', title='RMSE (millions of $)', axis = alt.Axis(grid = False)),\n",
    "    color = alt.Color('model:N', legend=None)\n",
    ").properties(\n",
    "    width=40*len(names), height=300,\n",
    "    title='Net Income'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ee982a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-ef6f698a9db649d8aede97eb6b94e3e4.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-ef6f698a9db649d8aede97eb6b94e3e4.vega-embed details,\n",
       "  #altair-viz-ef6f698a9db649d8aede97eb6b94e3e4.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-ef6f698a9db649d8aede97eb6b94e3e4\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-ef6f698a9db649d8aede97eb6b94e3e4\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-ef6f698a9db649d8aede97eb6b94e3e4\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300, \"stroke\": null}}, \"hconcat\": [{\"data\": {\"name\": \"data-220082242f2738b52bacfbc9e2374d61\"}, \"mark\": {\"type\": \"boxplot\", \"median\": {\"color\": \"black\", \"strokeWidth\": 3}, \"opacity\": 0.5, \"size\": 33}, \"encoding\": {\"color\": {\"field\": \"model\", \"legend\": null, \"type\": \"nominal\"}, \"x\": {\"axis\": {\"grid\": false, \"labelAngle\": 0}, \"field\": \"model\", \"sort\": [\"DUMMY\", \"LR\", \"RIDGE\", \"LASSO\", \"EN\", \"KNN\", \"DT\", \"SVR\", \"RFR\", \"ETR\", \"ABR\", \"GBR\"], \"title\": \"Regression Model\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false}, \"field\": \"rmse\", \"title\": \"RMSE (millions of $)\", \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Revenue\", \"width\": 480}, {\"data\": {\"name\": \"data-57e2c4bf959c6419fa1d70aa24739c88\"}, \"mark\": {\"type\": \"boxplot\", \"median\": {\"color\": \"black\", \"strokeWidth\": 3}, \"opacity\": 0.5, \"size\": 33}, \"encoding\": {\"color\": {\"field\": \"model\", \"legend\": null, \"type\": \"nominal\"}, \"x\": {\"axis\": {\"grid\": false, \"labelAngle\": 0}, \"field\": \"model\", \"sort\": [\"DUMMY\", \"LR\", \"RIDGE\", \"LASSO\", \"EN\", \"KNN\", \"DT\", \"SVR\", \"RFR\", \"ETR\", \"ABR\", \"GBR\"], \"title\": \"Regression Model\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false}, \"field\": \"rmse\", \"title\": \"RMSE (millions of $)\", \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Net Income\", \"width\": 480}], \"title\": {\"text\": \"Full Feature Space\", \"anchor\": \"middle\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-220082242f2738b52bacfbc9e2374d61\": [{\"model\": \"DUMMY\", \"rmse\": 12787.60384183147}, {\"model\": \"DUMMY\", \"rmse\": 6077.478958107764}, {\"model\": \"DUMMY\", \"rmse\": 7852.07307076927}, {\"model\": \"DUMMY\", \"rmse\": 12706.694262667083}, {\"model\": \"DUMMY\", \"rmse\": 8770.744163137864}, {\"model\": \"LR\", \"rmse\": 10379.346378583716}, {\"model\": \"LR\", \"rmse\": 5934.271614878021}, {\"model\": \"LR\", \"rmse\": 6498.538828106907}, {\"model\": \"LR\", \"rmse\": 8501.927487145158}, {\"model\": \"LR\", \"rmse\": 8985.5561249925}, {\"model\": \"RIDGE\", \"rmse\": 10241.86103434039}, {\"model\": \"RIDGE\", \"rmse\": 5335.880604020452}, {\"model\": \"RIDGE\", \"rmse\": 5801.367016604223}, {\"model\": \"RIDGE\", \"rmse\": 8847.203139166693}, {\"model\": \"RIDGE\", \"rmse\": 8146.711293794758}, {\"model\": \"LASSO\", \"rmse\": 10344.689954123161}, {\"model\": \"LASSO\", \"rmse\": 5891.92791607391}, {\"model\": \"LASSO\", \"rmse\": 6409.573731795758}, {\"model\": \"LASSO\", \"rmse\": 8466.74634863466}, {\"model\": \"LASSO\", \"rmse\": 8873.887275969557}, {\"model\": \"EN\", \"rmse\": 11550.26184718517}, {\"model\": \"EN\", \"rmse\": 4883.047769208598}, {\"model\": \"EN\", \"rmse\": 6604.000449449033}, {\"model\": \"EN\", \"rmse\": 11521.114996650944}, {\"model\": \"EN\", \"rmse\": 7806.423833365239}, {\"model\": \"KNN\", \"rmse\": 11126.695653141313}, {\"model\": \"KNN\", \"rmse\": 3961.631643244099}, {\"model\": \"KNN\", \"rmse\": 5362.013893647829}, {\"model\": \"KNN\", \"rmse\": 11128.611861619871}, {\"model\": \"KNN\", \"rmse\": 7880.187849120028}, {\"model\": \"DT\", \"rmse\": 4138.861041588923}, {\"model\": \"DT\", \"rmse\": 3276.091868223655}, {\"model\": \"DT\", \"rmse\": 1633.0186940918682}, {\"model\": \"DT\", \"rmse\": 3721.9072523141276}, {\"model\": \"DT\", \"rmse\": 1336.3731207136284}, {\"model\": \"SVR\", \"rmse\": 13064.981990773787}, {\"model\": \"SVR\", \"rmse\": 6350.376664870609}, {\"model\": \"SVR\", \"rmse\": 8203.20157169273}, {\"model\": \"SVR\", \"rmse\": 12987.834698647412}, {\"model\": \"SVR\", \"rmse\": 8877.241314712097}, {\"model\": \"RFR\", \"rmse\": 4997.933439440077}, {\"model\": \"RFR\", \"rmse\": 961.75593920653}, {\"model\": \"RFR\", \"rmse\": 1392.7575451853518}, {\"model\": \"RFR\", \"rmse\": 4652.132868531295}, {\"model\": \"RFR\", \"rmse\": 1424.8970287606073}, {\"model\": \"ETR\", \"rmse\": 4631.214806556581}, {\"model\": \"ETR\", \"rmse\": 1897.187384847547}, {\"model\": \"ETR\", \"rmse\": 1865.2085915245382}, {\"model\": \"ETR\", \"rmse\": 4181.771043726651}, {\"model\": \"ETR\", \"rmse\": 818.1917986938275}, {\"model\": \"ABR\", \"rmse\": 3514.3660190775704}, {\"model\": \"ABR\", \"rmse\": 1546.9948906707134}, {\"model\": \"ABR\", \"rmse\": 1436.5253891567236}, {\"model\": \"ABR\", \"rmse\": 4541.599459293128}, {\"model\": \"ABR\", \"rmse\": 1885.8951603847793}, {\"model\": \"GBR\", \"rmse\": 3421.5926341745494}, {\"model\": \"GBR\", \"rmse\": 613.2713476450871}, {\"model\": \"GBR\", \"rmse\": 1329.1677528434395}, {\"model\": \"GBR\", \"rmse\": 4176.49429950222}, {\"model\": \"GBR\", \"rmse\": 1527.0425781820638}], \"data-57e2c4bf959c6419fa1d70aa24739c88\": [{\"model\": \"DUMMY\", \"rmse\": 916.4380151999005}, {\"model\": \"DUMMY\", \"rmse\": 1297.4962393795124}, {\"model\": \"DUMMY\", \"rmse\": 1863.7191067462393}, {\"model\": \"DUMMY\", \"rmse\": 2074.94830401245}, {\"model\": \"DUMMY\", \"rmse\": 673.9992753708216}, {\"model\": \"LR\", \"rmse\": 851.7295320984496}, {\"model\": \"LR\", \"rmse\": 697.1023115245534}, {\"model\": \"LR\", \"rmse\": 1029.7481891573577}, {\"model\": \"LR\", \"rmse\": 1285.6544549896598}, {\"model\": \"LR\", \"rmse\": 965.1912766863843}, {\"model\": \"RIDGE\", \"rmse\": 806.945290384358}, {\"model\": \"RIDGE\", \"rmse\": 696.1279963356035}, {\"model\": \"RIDGE\", \"rmse\": 1110.0735606303908}, {\"model\": \"RIDGE\", \"rmse\": 1304.6897828619365}, {\"model\": \"RIDGE\", \"rmse\": 826.0082242917819}, {\"model\": \"LASSO\", \"rmse\": 846.6519477639168}, {\"model\": \"LASSO\", \"rmse\": 703.9004439750512}, {\"model\": \"LASSO\", \"rmse\": 1026.1021157790715}, {\"model\": \"LASSO\", \"rmse\": 1287.0866794908968}, {\"model\": \"LASSO\", \"rmse\": 967.3649933791634}, {\"model\": \"EN\", \"rmse\": 769.2574881950084}, {\"model\": \"EN\", \"rmse\": 1148.3620392862513}, {\"model\": \"EN\", \"rmse\": 1736.9655351821166}, {\"model\": \"EN\", \"rmse\": 1953.409867781314}, {\"model\": \"EN\", \"rmse\": 589.253136201552}, {\"model\": \"KNN\", \"rmse\": 683.5353794563072}, {\"model\": \"KNN\", \"rmse\": 724.724119849697}, {\"model\": \"KNN\", \"rmse\": 1487.0559213317201}, {\"model\": \"KNN\", \"rmse\": 1676.6385511706649}, {\"model\": \"KNN\", \"rmse\": 537.9079065537111}, {\"model\": \"DT\", \"rmse\": 606.735491782453}, {\"model\": \"DT\", \"rmse\": 953.1950605306763}, {\"model\": \"DT\", \"rmse\": 975.8177318136327}, {\"model\": \"DT\", \"rmse\": 933.7274647673753}, {\"model\": \"DT\", \"rmse\": 482.7221343153681}, {\"model\": \"SVR\", \"rmse\": 942.978668375283}, {\"model\": \"SVR\", \"rmse\": 1324.0802853392192}, {\"model\": \"SVR\", \"rmse\": 1892.9308112606163}, {\"model\": \"SVR\", \"rmse\": 2094.162719398632}, {\"model\": \"SVR\", \"rmse\": 677.6542815388824}, {\"model\": \"RFR\", \"rmse\": 486.9674536658118}, {\"model\": \"RFR\", \"rmse\": 237.85680089172567}, {\"model\": \"RFR\", \"rmse\": 905.1341924389483}, {\"model\": \"RFR\", \"rmse\": 905.1486825063686}, {\"model\": \"RFR\", \"rmse\": 595.960338095516}, {\"model\": \"ETR\", \"rmse\": 498.8744736111104}, {\"model\": \"ETR\", \"rmse\": 362.93725509395153}, {\"model\": \"ETR\", \"rmse\": 639.4040313385336}, {\"model\": \"ETR\", \"rmse\": 1116.0064495459583}, {\"model\": \"ETR\", \"rmse\": 617.8455719885219}, {\"model\": \"ABR\", \"rmse\": 537.2595245280686}, {\"model\": \"ABR\", \"rmse\": 470.52089849449175}, {\"model\": \"ABR\", \"rmse\": 860.6989596478658}, {\"model\": \"ABR\", \"rmse\": 794.9402395524972}, {\"model\": \"ABR\", \"rmse\": 464.4103789159201}, {\"model\": \"GBR\", \"rmse\": 546.280600228323}, {\"model\": \"GBR\", \"rmse\": 409.2048801281103}, {\"model\": \"GBR\", \"rmse\": 1043.7233006784088}, {\"model\": \"GBR\", \"rmse\": 910.0751397411331}, {\"model\": \"GBR\", \"rmse\": 538.1533986998616}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chart3 = (rev_chart3 | ear_chart3).properties(\n",
    "    title=alt.TitleParams('Full Feature Space', anchor='middle'))\n",
    "full_chart3.configure_view(stroke=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9379792a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-2f717c092ca5416b9d766f1e5c0fa74f.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-2f717c092ca5416b9d766f1e5c0fa74f.vega-embed details,\n",
       "  #altair-viz-2f717c092ca5416b9d766f1e5c0fa74f.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-2f717c092ca5416b9d766f1e5c0fa74f\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-2f717c092ca5416b9d766f1e5c0fa74f\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-2f717c092ca5416b9d766f1e5c0fa74f\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300, \"stroke\": null}}, \"vconcat\": [{\"hconcat\": [{\"data\": {\"name\": \"data-058aacd56957f7f7fa47760f195e2d9f\"}, \"mark\": {\"type\": \"boxplot\", \"median\": {\"color\": \"black\", \"strokeWidth\": 3}, \"opacity\": 0.5, \"size\": 33}, \"encoding\": {\"color\": {\"field\": \"model\", \"legend\": null, \"type\": \"nominal\"}, \"x\": {\"axis\": {\"grid\": false, \"labelAngle\": 0}, \"field\": \"model\", \"sort\": [\"DUMMY\", \"LR\", \"RIDGE\", \"LASSO\", \"EN\", \"KNN\", \"DT\", \"SVR\", \"RFR\", \"ETR\", \"ABR\", \"GBR\"], \"title\": \"Regression Model\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false}, \"field\": \"rmse\", \"title\": \"RMSE (millions of $)\", \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Revenue\", \"width\": 480}, {\"data\": {\"name\": \"data-07a6fbe5e7ba0dab4464ea7888219fd8\"}, \"mark\": {\"type\": \"boxplot\", \"median\": {\"color\": \"black\", \"strokeWidth\": 3}, \"opacity\": 0.5, \"size\": 33}, \"encoding\": {\"color\": {\"field\": \"model\", \"legend\": null, \"type\": \"nominal\"}, \"x\": {\"axis\": {\"grid\": false, \"labelAngle\": 0}, \"field\": \"model\", \"sort\": [\"DUMMY\", \"LR\", \"RIDGE\", \"LASSO\", \"EN\", \"KNN\", \"DT\", \"SVR\", \"RFR\", \"ETR\", \"ABR\", \"GBR\"], \"title\": \"Regression Model\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false}, \"field\": \"rmse\", \"title\": \"RMSE (millions of $)\", \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Net Income\", \"width\": 480}], \"title\": {\"text\": \"Raw Fundamental Feature Space\", \"anchor\": \"middle\"}}, {\"hconcat\": [{\"data\": {\"name\": \"data-49bd409fa04e18edd5766f5b3d0bb945\"}, \"mark\": {\"type\": \"boxplot\", \"median\": {\"color\": \"black\", \"strokeWidth\": 3}, \"opacity\": 0.5, \"size\": 33}, \"encoding\": {\"color\": {\"field\": \"model\", \"legend\": null, \"type\": \"nominal\"}, \"x\": {\"axis\": {\"grid\": false, \"labelAngle\": 0}, \"field\": \"model\", \"sort\": [\"DUMMY\", \"LR\", \"RIDGE\", \"LASSO\", \"EN\", \"KNN\", \"DT\", \"SVR\", \"RFR\", \"ETR\", \"ABR\", \"GBR\"], \"title\": \"Regression Model\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false}, \"field\": \"rmse\", \"title\": \"RMSE (millions of $)\", \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Revenue\", \"width\": 480}, {\"data\": {\"name\": \"data-4aeb8efa1eb8e28597b63c2697cbfa21\"}, \"mark\": {\"type\": \"boxplot\", \"median\": {\"color\": \"black\", \"strokeWidth\": 3}, \"opacity\": 0.5, \"size\": 33}, \"encoding\": {\"color\": {\"field\": \"model\", \"legend\": null, \"type\": \"nominal\"}, \"x\": {\"axis\": {\"grid\": false, \"labelAngle\": 0}, \"field\": \"model\", \"sort\": [\"DUMMY\", \"LR\", \"RIDGE\", \"LASSO\", \"EN\", \"KNN\", \"DT\", \"SVR\", \"RFR\", \"ETR\", \"ABR\", \"GBR\"], \"title\": \"Regression Model\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false}, \"field\": \"rmse\", \"title\": \"RMSE (millions of $)\", \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Net Income\", \"width\": 480}], \"title\": {\"text\": \"Engineered Feature Space\", \"anchor\": \"middle\"}}, {\"hconcat\": [{\"data\": {\"name\": \"data-220082242f2738b52bacfbc9e2374d61\"}, \"mark\": {\"type\": \"boxplot\", \"median\": {\"color\": \"black\", \"strokeWidth\": 3}, \"opacity\": 0.5, \"size\": 33}, \"encoding\": {\"color\": {\"field\": \"model\", \"legend\": null, \"type\": \"nominal\"}, \"x\": {\"axis\": {\"grid\": false, \"labelAngle\": 0}, \"field\": \"model\", \"sort\": [\"DUMMY\", \"LR\", \"RIDGE\", \"LASSO\", \"EN\", \"KNN\", \"DT\", \"SVR\", \"RFR\", \"ETR\", \"ABR\", \"GBR\"], \"title\": \"Regression Model\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false}, \"field\": \"rmse\", \"title\": \"RMSE (millions of $)\", \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Revenue\", \"width\": 480}, {\"data\": {\"name\": \"data-57e2c4bf959c6419fa1d70aa24739c88\"}, \"mark\": {\"type\": \"boxplot\", \"median\": {\"color\": \"black\", \"strokeWidth\": 3}, \"opacity\": 0.5, \"size\": 33}, \"encoding\": {\"color\": {\"field\": \"model\", \"legend\": null, \"type\": \"nominal\"}, \"x\": {\"axis\": {\"grid\": false, \"labelAngle\": 0}, \"field\": \"model\", \"sort\": [\"DUMMY\", \"LR\", \"RIDGE\", \"LASSO\", \"EN\", \"KNN\", \"DT\", \"SVR\", \"RFR\", \"ETR\", \"ABR\", \"GBR\"], \"title\": \"Regression Model\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false}, \"field\": \"rmse\", \"title\": \"RMSE (millions of $)\", \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Net Income\", \"width\": 480}], \"title\": {\"text\": \"Full Feature Space\", \"anchor\": \"middle\"}}], \"title\": {\"text\": \"RMSE Comparing Feature Space and Predictor Variables using 5-Fold Cross Validation\", \"anchor\": \"middle\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-058aacd56957f7f7fa47760f195e2d9f\": [{\"model\": \"DUMMY\", \"rmse\": 12787.60384183147}, {\"model\": \"DUMMY\", \"rmse\": 6077.478958107764}, {\"model\": \"DUMMY\", \"rmse\": 7852.07307076927}, {\"model\": \"DUMMY\", \"rmse\": 12706.694262667083}, {\"model\": \"DUMMY\", \"rmse\": 8770.744163137864}, {\"model\": \"LR\", \"rmse\": 11355.244175449294}, {\"model\": \"LR\", \"rmse\": 4843.698240742818}, {\"model\": \"LR\", \"rmse\": 4746.260074401192}, {\"model\": \"LR\", \"rmse\": 9099.8954617875}, {\"model\": \"LR\", \"rmse\": 8859.028835134302}, {\"model\": \"RIDGE\", \"rmse\": 11310.160882304941}, {\"model\": \"RIDGE\", \"rmse\": 4561.502592910213}, {\"model\": \"RIDGE\", \"rmse\": 4691.500565012342}, {\"model\": \"RIDGE\", \"rmse\": 9425.136571499303}, {\"model\": \"RIDGE\", \"rmse\": 8564.440647735426}, {\"model\": \"LASSO\", \"rmse\": 11354.542742466796}, {\"model\": \"LASSO\", \"rmse\": 4840.810830617964}, {\"model\": \"LASSO\", \"rmse\": 4748.711572330515}, {\"model\": \"LASSO\", \"rmse\": 9100.212569045512}, {\"model\": \"LASSO\", \"rmse\": 8862.579615222843}, {\"model\": \"EN\", \"rmse\": 11728.848054050703}, {\"model\": \"EN\", \"rmse\": 4930.574309789623}, {\"model\": \"EN\", \"rmse\": 6660.48595326503}, {\"model\": \"EN\", \"rmse\": 11670.319714505778}, {\"model\": \"EN\", \"rmse\": 7904.668544544995}, {\"model\": \"KNN\", \"rmse\": 10344.103325761858}, {\"model\": \"KNN\", \"rmse\": 4666.785083766035}, {\"model\": \"KNN\", \"rmse\": 5203.307812284396}, {\"model\": \"KNN\", \"rmse\": 9184.546031811093}, {\"model\": \"KNN\", \"rmse\": 7192.966630923298}, {\"model\": \"DT\", \"rmse\": 3442.5725727871763}, {\"model\": \"DT\", \"rmse\": 2099.8397682337395}, {\"model\": \"DT\", \"rmse\": 1514.9480829684665}, {\"model\": \"DT\", \"rmse\": 4523.157379843845}, {\"model\": \"DT\", \"rmse\": 1192.7627636802752}, {\"model\": \"SVR\", \"rmse\": 13064.981961507088}, {\"model\": \"SVR\", \"rmse\": 6350.376610679709}, {\"model\": \"SVR\", \"rmse\": 8203.20153213008}, {\"model\": \"SVR\", \"rmse\": 12987.834673320374}, {\"model\": \"SVR\", \"rmse\": 8877.241280271483}, {\"model\": \"RFR\", \"rmse\": 5034.853535247595}, {\"model\": \"RFR\", \"rmse\": 765.1755786638716}, {\"model\": \"RFR\", \"rmse\": 1198.034300229026}, {\"model\": \"RFR\", \"rmse\": 3695.0272904038634}, {\"model\": \"RFR\", \"rmse\": 1320.5024398500013}, {\"model\": \"ETR\", \"rmse\": 5328.985866089118}, {\"model\": \"ETR\", \"rmse\": 1654.795012531189}, {\"model\": \"ETR\", \"rmse\": 1156.1716062078572}, {\"model\": \"ETR\", \"rmse\": 3989.853685747003}, {\"model\": \"ETR\", \"rmse\": 1174.1676716764725}, {\"model\": \"ABR\", \"rmse\": 3447.056525800058}, {\"model\": \"ABR\", \"rmse\": 1524.5725002123786}, {\"model\": \"ABR\", \"rmse\": 1542.6090198914508}, {\"model\": \"ABR\", \"rmse\": 4739.4042402350005}, {\"model\": \"ABR\", \"rmse\": 1763.7546246177628}, {\"model\": \"GBR\", \"rmse\": 3637.3105605484657}, {\"model\": \"GBR\", \"rmse\": 765.6660514241199}, {\"model\": \"GBR\", \"rmse\": 823.7959870061819}, {\"model\": \"GBR\", \"rmse\": 2372.331550533908}, {\"model\": \"GBR\", \"rmse\": 1290.3854757102624}], \"data-07a6fbe5e7ba0dab4464ea7888219fd8\": [{\"model\": \"DUMMY\", \"rmse\": 916.4380151999005}, {\"model\": \"DUMMY\", \"rmse\": 1297.4962393795124}, {\"model\": \"DUMMY\", \"rmse\": 1863.7191067462393}, {\"model\": \"DUMMY\", \"rmse\": 2074.94830401245}, {\"model\": \"DUMMY\", \"rmse\": 673.9992753708216}, {\"model\": \"LR\", \"rmse\": 796.7626980780601}, {\"model\": \"LR\", \"rmse\": 581.0150231266622}, {\"model\": \"LR\", \"rmse\": 847.7553129652302}, {\"model\": \"LR\", \"rmse\": 1275.0223287356837}, {\"model\": \"LR\", \"rmse\": 886.1385806197364}, {\"model\": \"RIDGE\", \"rmse\": 776.4587576959545}, {\"model\": \"RIDGE\", \"rmse\": 598.8951447126885}, {\"model\": \"RIDGE\", \"rmse\": 943.6883385059049}, {\"model\": \"RIDGE\", \"rmse\": 1289.2577478294531}, {\"model\": \"RIDGE\", \"rmse\": 798.8174166166182}, {\"model\": \"LASSO\", \"rmse\": 796.1087070070273}, {\"model\": \"LASSO\", \"rmse\": 582.6247258521635}, {\"model\": \"LASSO\", \"rmse\": 847.096016580892}, {\"model\": \"LASSO\", \"rmse\": 1275.5322740564786}, {\"model\": \"LASSO\", \"rmse\": 887.017288341566}, {\"model\": \"EN\", \"rmse\": 772.5670604123734}, {\"model\": \"EN\", \"rmse\": 1160.4334943309698}, {\"model\": \"EN\", \"rmse\": 1737.1698960506958}, {\"model\": \"EN\", \"rmse\": 1973.308301750769}, {\"model\": \"EN\", \"rmse\": 585.9266051988706}, {\"model\": \"KNN\", \"rmse\": 631.362916578877}, {\"model\": \"KNN\", \"rmse\": 601.6645451286819}, {\"model\": \"KNN\", \"rmse\": 947.3450745740643}, {\"model\": \"KNN\", \"rmse\": 1201.338928517507}, {\"model\": \"KNN\", \"rmse\": 724.5177907387927}, {\"model\": \"DT\", \"rmse\": 619.3558286651252}, {\"model\": \"DT\", \"rmse\": 600.8533356489216}, {\"model\": \"DT\", \"rmse\": 1679.4388311858206}, {\"model\": \"DT\", \"rmse\": 777.4977667985128}, {\"model\": \"DT\", \"rmse\": 526.0439593747362}, {\"model\": \"SVR\", \"rmse\": 942.9786208529837}, {\"model\": \"SVR\", \"rmse\": 1324.0802644239404}, {\"model\": \"SVR\", \"rmse\": 1892.930776854629}, {\"model\": \"SVR\", \"rmse\": 2094.162699493562}, {\"model\": \"SVR\", \"rmse\": 677.6542377844422}, {\"model\": \"RFR\", \"rmse\": 482.1128662167995}, {\"model\": \"RFR\", \"rmse\": 239.19310880916515}, {\"model\": \"RFR\", \"rmse\": 725.9397242206543}, {\"model\": \"RFR\", \"rmse\": 808.0119375017164}, {\"model\": \"RFR\", \"rmse\": 559.4228583704901}, {\"model\": \"ETR\", \"rmse\": 511.10039213846096}, {\"model\": \"ETR\", \"rmse\": 397.53413285671843}, {\"model\": \"ETR\", \"rmse\": 805.8292282414602}, {\"model\": \"ETR\", \"rmse\": 1000.87416839134}, {\"model\": \"ETR\", \"rmse\": 535.7602952884865}, {\"model\": \"ABR\", \"rmse\": 576.6602525351349}, {\"model\": \"ABR\", \"rmse\": 342.1062360337267}, {\"model\": \"ABR\", \"rmse\": 614.7321631860124}, {\"model\": \"ABR\", \"rmse\": 721.9425625905993}, {\"model\": \"ABR\", \"rmse\": 794.5295624339956}, {\"model\": \"GBR\", \"rmse\": 549.6703085175062}, {\"model\": \"GBR\", \"rmse\": 281.1320123238651}, {\"model\": \"GBR\", \"rmse\": 900.3975187009728}, {\"model\": \"GBR\", \"rmse\": 790.4602149329355}, {\"model\": \"GBR\", \"rmse\": 456.68602136525067}], \"data-49bd409fa04e18edd5766f5b3d0bb945\": [{\"model\": \"DUMMY\", \"rmse\": 12787.60384183147}, {\"model\": \"DUMMY\", \"rmse\": 6077.478958107764}, {\"model\": \"DUMMY\", \"rmse\": 7852.07307076927}, {\"model\": \"DUMMY\", \"rmse\": 12706.694262667083}, {\"model\": \"DUMMY\", \"rmse\": 8770.744163137864}, {\"model\": \"LR\", \"rmse\": 10821.891380559671}, {\"model\": \"LR\", \"rmse\": 6427.184889094979}, {\"model\": \"LR\", \"rmse\": 6046.859739325045}, {\"model\": \"LR\", \"rmse\": 8812.492501213797}, {\"model\": \"LR\", \"rmse\": 8917.227889193897}, {\"model\": \"RIDGE\", \"rmse\": 10820.955413729984}, {\"model\": \"RIDGE\", \"rmse\": 5936.887561742372}, {\"model\": \"RIDGE\", \"rmse\": 5785.344723687073}, {\"model\": \"RIDGE\", \"rmse\": 9256.2043542556}, {\"model\": \"RIDGE\", \"rmse\": 8505.789743541158}, {\"model\": \"LASSO\", \"rmse\": 10821.65681942802}, {\"model\": \"LASSO\", \"rmse\": 6427.186397231974}, {\"model\": \"LASSO\", \"rmse\": 6046.726455227086}, {\"model\": \"LASSO\", \"rmse\": 8812.508451571439}, {\"model\": \"LASSO\", \"rmse\": 8916.413894495263}, {\"model\": \"EN\", \"rmse\": 11989.728150365947}, {\"model\": \"EN\", \"rmse\": 5165.325650915977}, {\"model\": \"EN\", \"rmse\": 7101.304523144149}, {\"model\": \"EN\", \"rmse\": 11989.36222314085}, {\"model\": \"EN\", \"rmse\": 8010.502772093782}, {\"model\": \"KNN\", \"rmse\": 12036.691598811534}, {\"model\": \"KNN\", \"rmse\": 5031.590520746698}, {\"model\": \"KNN\", \"rmse\": 7199.425704946406}, {\"model\": \"KNN\", \"rmse\": 11905.477074839888}, {\"model\": \"KNN\", \"rmse\": 8580.738187163706}, {\"model\": \"DT\", \"rmse\": 6415.996329186189}, {\"model\": \"DT\", \"rmse\": 9297.738212332197}, {\"model\": \"DT\", \"rmse\": 5421.7622488290845}, {\"model\": \"DT\", \"rmse\": 5579.190814179891}, {\"model\": \"DT\", \"rmse\": 5329.52359019969}, {\"model\": \"SVR\", \"rmse\": 13064.982004694677}, {\"model\": \"SVR\", \"rmse\": 6350.3766936187285}, {\"model\": \"SVR\", \"rmse\": 8203.201594301494}, {\"model\": \"SVR\", \"rmse\": 12987.834713710039}, {\"model\": \"SVR\", \"rmse\": 8877.241333903963}, {\"model\": \"RFR\", \"rmse\": 7541.237000043439}, {\"model\": \"RFR\", \"rmse\": 7234.706233008463}, {\"model\": \"RFR\", \"rmse\": 4420.903935099489}, {\"model\": \"RFR\", \"rmse\": 7326.15477388617}, {\"model\": \"RFR\", \"rmse\": 5027.118553227127}, {\"model\": \"ETR\", \"rmse\": 8054.652508797339}, {\"model\": \"ETR\", \"rmse\": 4029.5397136890138}, {\"model\": \"ETR\", \"rmse\": 3100.5778241193266}, {\"model\": \"ETR\", \"rmse\": 7120.315184880896}, {\"model\": \"ETR\", \"rmse\": 6211.995423287581}, {\"model\": \"ABR\", \"rmse\": 9404.777681797255}, {\"model\": \"ABR\", \"rmse\": 9332.454744318451}, {\"model\": \"ABR\", \"rmse\": 5865.407508944504}, {\"model\": \"ABR\", \"rmse\": 10491.24174251723}, {\"model\": \"ABR\", \"rmse\": 8171.270953458604}, {\"model\": \"GBR\", \"rmse\": 5599.495318039817}, {\"model\": \"GBR\", \"rmse\": 6834.119780516619}, {\"model\": \"GBR\", \"rmse\": 4116.763136159413}, {\"model\": \"GBR\", \"rmse\": 7143.510341321735}, {\"model\": \"GBR\", \"rmse\": 3709.297196494301}], \"data-4aeb8efa1eb8e28597b63c2697cbfa21\": [{\"model\": \"DUMMY\", \"rmse\": 916.4380151999005}, {\"model\": \"DUMMY\", \"rmse\": 1297.4962393795124}, {\"model\": \"DUMMY\", \"rmse\": 1863.7191067462393}, {\"model\": \"DUMMY\", \"rmse\": 2074.94830401245}, {\"model\": \"DUMMY\", \"rmse\": 673.9992753708216}, {\"model\": \"LR\", \"rmse\": 817.4849373142287}, {\"model\": \"LR\", \"rmse\": 682.959700120298}, {\"model\": \"LR\", \"rmse\": 978.5491712302647}, {\"model\": \"LR\", \"rmse\": 1302.6223267539153}, {\"model\": \"LR\", \"rmse\": 921.136941267385}, {\"model\": \"RIDGE\", \"rmse\": 786.4594157357989}, {\"model\": \"RIDGE\", \"rmse\": 697.2312986611292}, {\"model\": \"RIDGE\", \"rmse\": 1094.270405634486}, {\"model\": \"RIDGE\", \"rmse\": 1323.19436526431}, {\"model\": \"RIDGE\", \"rmse\": 817.7290011681536}, {\"model\": \"LASSO\", \"rmse\": 817.4578656658457}, {\"model\": \"LASSO\", \"rmse\": 682.9693529550854}, {\"model\": \"LASSO\", \"rmse\": 978.5189195043238}, {\"model\": \"LASSO\", \"rmse\": 1302.6166438788928}, {\"model\": \"LASSO\", \"rmse\": 921.0741900266224}, {\"model\": \"EN\", \"rmse\": 798.5217175821591}, {\"model\": \"EN\", \"rmse\": 1187.5932961328192}, {\"model\": \"EN\", \"rmse\": 1786.9790329210903}, {\"model\": \"EN\", \"rmse\": 1986.754055785419}, {\"model\": \"EN\", \"rmse\": 595.2096141092587}, {\"model\": \"KNN\", \"rmse\": 799.3160766437555}, {\"model\": \"KNN\", \"rmse\": 778.601419211135}, {\"model\": \"KNN\", \"rmse\": 1763.4395102049252}, {\"model\": \"KNN\", \"rmse\": 1771.9853656057553}, {\"model\": \"KNN\", \"rmse\": 571.3361450528296}, {\"model\": \"DT\", \"rmse\": 656.0800395618402}, {\"model\": \"DT\", \"rmse\": 787.7058480408089}, {\"model\": \"DT\", \"rmse\": 940.7303016900796}, {\"model\": \"DT\", \"rmse\": 1389.3593522827368}, {\"model\": \"DT\", \"rmse\": 887.599962612554}, {\"model\": \"SVR\", \"rmse\": 942.9786937381182}, {\"model\": \"SVR\", \"rmse\": 1324.080295578571}, {\"model\": \"SVR\", \"rmse\": 1892.9308275842213}, {\"model\": \"SVR\", \"rmse\": 2094.1627315185833}, {\"model\": \"SVR\", \"rmse\": 677.6543053115021}, {\"model\": \"RFR\", \"rmse\": 619.1305492222881}, {\"model\": \"RFR\", \"rmse\": 307.44498681399824}, {\"model\": \"RFR\", \"rmse\": 739.0028198733388}, {\"model\": \"RFR\", \"rmse\": 1144.759007386523}, {\"model\": \"RFR\", \"rmse\": 445.1219449326818}, {\"model\": \"ETR\", \"rmse\": 553.3610304253714}, {\"model\": \"ETR\", \"rmse\": 387.79813781129667}, {\"model\": \"ETR\", \"rmse\": 699.2560595831644}, {\"model\": \"ETR\", \"rmse\": 1194.9300926963115}, {\"model\": \"ETR\", \"rmse\": 741.7047453195752}, {\"model\": \"ABR\", \"rmse\": 698.9025777189274}, {\"model\": \"ABR\", \"rmse\": 558.7300163984949}, {\"model\": \"ABR\", \"rmse\": 875.0030095923129}, {\"model\": \"ABR\", \"rmse\": 912.213888881783}, {\"model\": \"ABR\", \"rmse\": 333.31568610264213}, {\"model\": \"GBR\", \"rmse\": 666.5138825313824}, {\"model\": \"GBR\", \"rmse\": 377.11631592411214}, {\"model\": \"GBR\", \"rmse\": 798.8438295103458}, {\"model\": \"GBR\", \"rmse\": 1235.6668580287078}, {\"model\": \"GBR\", \"rmse\": 475.68252500143495}], \"data-220082242f2738b52bacfbc9e2374d61\": [{\"model\": \"DUMMY\", \"rmse\": 12787.60384183147}, {\"model\": \"DUMMY\", \"rmse\": 6077.478958107764}, {\"model\": \"DUMMY\", \"rmse\": 7852.07307076927}, {\"model\": \"DUMMY\", \"rmse\": 12706.694262667083}, {\"model\": \"DUMMY\", \"rmse\": 8770.744163137864}, {\"model\": \"LR\", \"rmse\": 10379.346378583716}, {\"model\": \"LR\", \"rmse\": 5934.271614878021}, {\"model\": \"LR\", \"rmse\": 6498.538828106907}, {\"model\": \"LR\", \"rmse\": 8501.927487145158}, {\"model\": \"LR\", \"rmse\": 8985.5561249925}, {\"model\": \"RIDGE\", \"rmse\": 10241.86103434039}, {\"model\": \"RIDGE\", \"rmse\": 5335.880604020452}, {\"model\": \"RIDGE\", \"rmse\": 5801.367016604223}, {\"model\": \"RIDGE\", \"rmse\": 8847.203139166693}, {\"model\": \"RIDGE\", \"rmse\": 8146.711293794758}, {\"model\": \"LASSO\", \"rmse\": 10344.689954123161}, {\"model\": \"LASSO\", \"rmse\": 5891.92791607391}, {\"model\": \"LASSO\", \"rmse\": 6409.573731795758}, {\"model\": \"LASSO\", \"rmse\": 8466.74634863466}, {\"model\": \"LASSO\", \"rmse\": 8873.887275969557}, {\"model\": \"EN\", \"rmse\": 11550.26184718517}, {\"model\": \"EN\", \"rmse\": 4883.047769208598}, {\"model\": \"EN\", \"rmse\": 6604.000449449033}, {\"model\": \"EN\", \"rmse\": 11521.114996650944}, {\"model\": \"EN\", \"rmse\": 7806.423833365239}, {\"model\": \"KNN\", \"rmse\": 11126.695653141313}, {\"model\": \"KNN\", \"rmse\": 3961.631643244099}, {\"model\": \"KNN\", \"rmse\": 5362.013893647829}, {\"model\": \"KNN\", \"rmse\": 11128.611861619871}, {\"model\": \"KNN\", \"rmse\": 7880.187849120028}, {\"model\": \"DT\", \"rmse\": 4138.861041588923}, {\"model\": \"DT\", \"rmse\": 3276.091868223655}, {\"model\": \"DT\", \"rmse\": 1633.0186940918682}, {\"model\": \"DT\", \"rmse\": 3721.9072523141276}, {\"model\": \"DT\", \"rmse\": 1336.3731207136284}, {\"model\": \"SVR\", \"rmse\": 13064.981990773787}, {\"model\": \"SVR\", \"rmse\": 6350.376664870609}, {\"model\": \"SVR\", \"rmse\": 8203.20157169273}, {\"model\": \"SVR\", \"rmse\": 12987.834698647412}, {\"model\": \"SVR\", \"rmse\": 8877.241314712097}, {\"model\": \"RFR\", \"rmse\": 4997.933439440077}, {\"model\": \"RFR\", \"rmse\": 961.75593920653}, {\"model\": \"RFR\", \"rmse\": 1392.7575451853518}, {\"model\": \"RFR\", \"rmse\": 4652.132868531295}, {\"model\": \"RFR\", \"rmse\": 1424.8970287606073}, {\"model\": \"ETR\", \"rmse\": 4631.214806556581}, {\"model\": \"ETR\", \"rmse\": 1897.187384847547}, {\"model\": \"ETR\", \"rmse\": 1865.2085915245382}, {\"model\": \"ETR\", \"rmse\": 4181.771043726651}, {\"model\": \"ETR\", \"rmse\": 818.1917986938275}, {\"model\": \"ABR\", \"rmse\": 3514.3660190775704}, {\"model\": \"ABR\", \"rmse\": 1546.9948906707134}, {\"model\": \"ABR\", \"rmse\": 1436.5253891567236}, {\"model\": \"ABR\", \"rmse\": 4541.599459293128}, {\"model\": \"ABR\", \"rmse\": 1885.8951603847793}, {\"model\": \"GBR\", \"rmse\": 3421.5926341745494}, {\"model\": \"GBR\", \"rmse\": 613.2713476450871}, {\"model\": \"GBR\", \"rmse\": 1329.1677528434395}, {\"model\": \"GBR\", \"rmse\": 4176.49429950222}, {\"model\": \"GBR\", \"rmse\": 1527.0425781820638}], \"data-57e2c4bf959c6419fa1d70aa24739c88\": [{\"model\": \"DUMMY\", \"rmse\": 916.4380151999005}, {\"model\": \"DUMMY\", \"rmse\": 1297.4962393795124}, {\"model\": \"DUMMY\", \"rmse\": 1863.7191067462393}, {\"model\": \"DUMMY\", \"rmse\": 2074.94830401245}, {\"model\": \"DUMMY\", \"rmse\": 673.9992753708216}, {\"model\": \"LR\", \"rmse\": 851.7295320984496}, {\"model\": \"LR\", \"rmse\": 697.1023115245534}, {\"model\": \"LR\", \"rmse\": 1029.7481891573577}, {\"model\": \"LR\", \"rmse\": 1285.6544549896598}, {\"model\": \"LR\", \"rmse\": 965.1912766863843}, {\"model\": \"RIDGE\", \"rmse\": 806.945290384358}, {\"model\": \"RIDGE\", \"rmse\": 696.1279963356035}, {\"model\": \"RIDGE\", \"rmse\": 1110.0735606303908}, {\"model\": \"RIDGE\", \"rmse\": 1304.6897828619365}, {\"model\": \"RIDGE\", \"rmse\": 826.0082242917819}, {\"model\": \"LASSO\", \"rmse\": 846.6519477639168}, {\"model\": \"LASSO\", \"rmse\": 703.9004439750512}, {\"model\": \"LASSO\", \"rmse\": 1026.1021157790715}, {\"model\": \"LASSO\", \"rmse\": 1287.0866794908968}, {\"model\": \"LASSO\", \"rmse\": 967.3649933791634}, {\"model\": \"EN\", \"rmse\": 769.2574881950084}, {\"model\": \"EN\", \"rmse\": 1148.3620392862513}, {\"model\": \"EN\", \"rmse\": 1736.9655351821166}, {\"model\": \"EN\", \"rmse\": 1953.409867781314}, {\"model\": \"EN\", \"rmse\": 589.253136201552}, {\"model\": \"KNN\", \"rmse\": 683.5353794563072}, {\"model\": \"KNN\", \"rmse\": 724.724119849697}, {\"model\": \"KNN\", \"rmse\": 1487.0559213317201}, {\"model\": \"KNN\", \"rmse\": 1676.6385511706649}, {\"model\": \"KNN\", \"rmse\": 537.9079065537111}, {\"model\": \"DT\", \"rmse\": 606.735491782453}, {\"model\": \"DT\", \"rmse\": 953.1950605306763}, {\"model\": \"DT\", \"rmse\": 975.8177318136327}, {\"model\": \"DT\", \"rmse\": 933.7274647673753}, {\"model\": \"DT\", \"rmse\": 482.7221343153681}, {\"model\": \"SVR\", \"rmse\": 942.978668375283}, {\"model\": \"SVR\", \"rmse\": 1324.0802853392192}, {\"model\": \"SVR\", \"rmse\": 1892.9308112606163}, {\"model\": \"SVR\", \"rmse\": 2094.162719398632}, {\"model\": \"SVR\", \"rmse\": 677.6542815388824}, {\"model\": \"RFR\", \"rmse\": 486.9674536658118}, {\"model\": \"RFR\", \"rmse\": 237.85680089172567}, {\"model\": \"RFR\", \"rmse\": 905.1341924389483}, {\"model\": \"RFR\", \"rmse\": 905.1486825063686}, {\"model\": \"RFR\", \"rmse\": 595.960338095516}, {\"model\": \"ETR\", \"rmse\": 498.8744736111104}, {\"model\": \"ETR\", \"rmse\": 362.93725509395153}, {\"model\": \"ETR\", \"rmse\": 639.4040313385336}, {\"model\": \"ETR\", \"rmse\": 1116.0064495459583}, {\"model\": \"ETR\", \"rmse\": 617.8455719885219}, {\"model\": \"ABR\", \"rmse\": 537.2595245280686}, {\"model\": \"ABR\", \"rmse\": 470.52089849449175}, {\"model\": \"ABR\", \"rmse\": 860.6989596478658}, {\"model\": \"ABR\", \"rmse\": 794.9402395524972}, {\"model\": \"ABR\", \"rmse\": 464.4103789159201}, {\"model\": \"GBR\", \"rmse\": 546.280600228323}, {\"model\": \"GBR\", \"rmse\": 409.2048801281103}, {\"model\": \"GBR\", \"rmse\": 1043.7233006784088}, {\"model\": \"GBR\", \"rmse\": 910.0751397411331}, {\"model\": \"GBR\", \"rmse\": 538.1533986998616}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(full_chart & full_chart2 & full_chart3).configure_view(stroke=None).properties(\n",
    "    title=alt.TitleParams('RMSE Comparing Feature Space and Predictor Variables using 5-Fold Cross Validation', anchor='middle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eab9be4",
   "metadata": {},
   "source": [
    "## PCA Only Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8b30911a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 618, in fit\n    X, y = validate_data(\n           ~~~~~~~~~~~~~^\n        self,\n        ^^^^^\n    ...<5 lines>...\n        force_writeable=True,\n        ^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n    X = check_array(\n        X,\n    ...<12 lines>...\n        input_name=\"X\",\n    )\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1105, in check_array\n    _assert_all_finite(\n    ~~~~~~~~~~~~~~~~~~^\n        array,\n        ^^^^^^\n    ...<2 lines>...\n        allow_nan=ensure_all_finite == \"allow-nan\",\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 120, in _assert_all_finite\n    _assert_all_finite_element_wise(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        X,\n        ^^\n    ...<4 lines>...\n        input_name=input_name,\n        ^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 169, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[80]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[32m     37\u001b[39m     pipe = Pipeline([(\u001b[33m'\u001b[39m\u001b[33mprep\u001b[39m\u001b[33m'\u001b[39m, preproc), (\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m, model)])\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     rmse_rev = -\u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_pca\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my1_rev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m     rmse_ear = -cross_val_score(pipe, X_pca, y2_ear, cv=cv, scoring=scorer, n_jobs=-\u001b[32m1\u001b[39m)\n\u001b[32m     40\u001b[39m     names.append(name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:677\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    674\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    675\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:419\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    398\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m    399\u001b[39m results = parallel(\n\u001b[32m    400\u001b[39m     delayed(_fit_and_score)(\n\u001b[32m    401\u001b[39m         clone(estimator),\n\u001b[32m   (...)\u001b[39m\u001b[32m    416\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[32m    417\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    423\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[32m    424\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:505\u001b[39m, in \u001b[36m_warn_or_raise_about_fit_failures\u001b[39m\u001b[34m(results, error_score)\u001b[39m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits == num_fits:\n\u001b[32m    499\u001b[39m     all_fits_failed_message = (\n\u001b[32m    500\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    501\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    502\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou can try to debug the error by setting error_score=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    503\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    508\u001b[39m     some_fits_failed_message = (\n\u001b[32m    509\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    510\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe score on these train-test partitions for these parameters\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    514\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 618, in fit\n    X, y = validate_data(\n           ~~~~~~~~~~~~~^\n        self,\n        ^^^^^\n    ...<5 lines>...\n        force_writeable=True,\n        ^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n    X = check_array(\n        X,\n    ...<12 lines>...\n        input_name=\"X\",\n    )\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1105, in check_array\n    _assert_all_finite(\n    ~~~~~~~~~~~~~~~~~~^\n        array,\n        ^^^^^^\n    ...<2 lines>...\n        allow_nan=ensure_all_finite == \"allow-nan\",\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 120, in _assert_all_finite\n    _assert_all_finite_element_wise(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        X,\n        ^^\n    ...<4 lines>...\n        input_name=input_name,\n        ^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 169, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    }
   ],
   "source": [
    "# Lets attempt this first with the raw data\n",
    "X_pca = pca_data.copy()\n",
    "# columns\n",
    "#cat_cols = ['Sector', 'Exchange', 'Market Cap'] \n",
    "num_cols = X_pca.columns\n",
    "\n",
    "# models (set seeds where applicable)\n",
    "models = [\n",
    "    ('DUMMY', DummyRegressor(strategy='mean')),\n",
    "    ('LR', LinearRegression()),\n",
    "    ('RIDGE', Ridge()),\n",
    "    ('LASSO', Lasso()),\n",
    "    ('EN', ElasticNet()),\n",
    "    ('KNN', KNeighborsRegressor()),\n",
    "    ('DT', DecisionTreeRegressor(random_state=random_state)),\n",
    "    ('SVR', SVR()),\n",
    "    ('RFR', RandomForestRegressor(random_state=random_state)),\n",
    "    ('ETR', ExtraTreesRegressor(random_state=random_state)),\n",
    "    ('ABR', AdaBoostRegressor(random_state=random_state)),\n",
    "    ('GBR', GradientBoostingRegressor(random_state=random_state)),\n",
    "]\n",
    "\n",
    "# preprocessing\n",
    "preproc = ColumnTransformer([\n",
    "    ('num', Pipeline([\n",
    "        ('scale', scaler)\n",
    "    ]), num_cols),\n",
    "    \n",
    "])\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle = True, random_state=random_state)\n",
    "scorer = 'neg_root_mean_squared_error'  # RMSE as negative; flip sign after\n",
    "\n",
    "names, kfold_results_rev, kfold_results_ear = [], [], []\n",
    "\n",
    "for name, model in models:\n",
    "    pipe = Pipeline([('prep', preproc), ('model', model)])\n",
    "    rmse_rev = -cross_val_score(pipe, X_pca, y1_rev, cv=cv, scoring=scorer, n_jobs=-1)\n",
    "    rmse_ear = -cross_val_score(pipe, X_pca, y2_ear, cv=cv, scoring=scorer, n_jobs=-1)\n",
    "    names.append(name)\n",
    "    kfold_results_rev.append(rmse_rev)\n",
    "    kfold_results_ear.append(rmse_ear)\n",
    "\n",
    "# optional: summary\n",
    "summary = pd.DataFrame({\n",
    "    'model': names,\n",
    "    'rev_rmse_mean': [r.mean() for r in kfold_results_rev],\n",
    "    'rev_rmse_std':  [r.std()  for r in kfold_results_rev],\n",
    "    'ear_rmse_mean': [r.mean() for r in kfold_results_ear],\n",
    "    'ear_rmse_std':  [r.std()  for r in kfold_results_ear],\n",
    "}).sort_values('rev_rmse_mean')\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ba0841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a better looking chart in altair\n",
    "df_rev = pd.DataFrame({\n",
    "    \"model\": np.concatenate([[n]*len(v) for n, v in zip(names, kfold_results_rev)]),\n",
    "    \"rmse\":  np.concatenate(kfold_results_rev)\n",
    "})\n",
    "\n",
    "df_rev['rmse'] = df_rev['rmse']/1_000_000\n",
    "\n",
    "rev_chart4 = alt.Chart(df_rev).mark_boxplot(size=33, opacity=0.5, median={'color': 'black', 'strokeWidth': 3}).encode(\n",
    "    x=alt.X('model:N', sort=names, title='Regression Model', axis = alt.Axis(labelAngle = 0, grid = False)),\n",
    "    y=alt.Y('rmse:Q', title='RMSE (millions of $)', axis = alt.Axis(grid = False)),\n",
    "    color = alt.Color('model:N', legend=None)\n",
    ").properties(\n",
    "    width=40*len(names), height=300,\n",
    "    title='Revenue'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3600c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a better looking chart in altair\n",
    "df_ear = pd.DataFrame({\n",
    "    \"model\": np.concatenate([[n]*len(v) for n, v in zip(names, kfold_results_ear)]),\n",
    "    \"rmse\":  np.concatenate(kfold_results_ear)\n",
    "})\n",
    "\n",
    "df_ear['rmse'] = df_ear['rmse']/1_000_000\n",
    "\n",
    "ear_chart4 = alt.Chart(df_ear).mark_boxplot(size=33, opacity=0.5, median={'color': 'black', 'strokeWidth': 3}).encode(\n",
    "    x=alt.X('model:N', sort=names, title='Regression Model', axis = alt.Axis(labelAngle = 0, grid = False)),\n",
    "    y=alt.Y('rmse:Q', title='RMSE (millions of $)', axis = alt.Axis(grid = False)),\n",
    "    color = alt.Color('model:N', legend=None)\n",
    ").properties(\n",
    "    width=40*len(names), height=300,\n",
    "    title='Net Income'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814fc8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-9e7ac55f018e47e4a92c17cf9dec2391.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-9e7ac55f018e47e4a92c17cf9dec2391.vega-embed details,\n",
       "  #altair-viz-9e7ac55f018e47e4a92c17cf9dec2391.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-9e7ac55f018e47e4a92c17cf9dec2391\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-9e7ac55f018e47e4a92c17cf9dec2391\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-9e7ac55f018e47e4a92c17cf9dec2391\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300, \"stroke\": null}}, \"hconcat\": [{\"data\": {\"name\": \"data-828819fa62ecb64ce8813fd799f2e353\"}, \"mark\": {\"type\": \"boxplot\", \"median\": {\"color\": \"black\", \"strokeWidth\": 3}, \"opacity\": 0.5, \"size\": 33}, \"encoding\": {\"color\": {\"field\": \"model\", \"legend\": null, \"type\": \"nominal\"}, \"x\": {\"axis\": {\"grid\": false, \"labelAngle\": 0}, \"field\": \"model\", \"sort\": [\"DUMMY\", \"LR\", \"RIDGE\", \"LASSO\", \"EN\", \"KNN\", \"DT\", \"SVR\", \"RFR\", \"ETR\", \"ABR\", \"GBR\"], \"title\": \"Regression Model\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false}, \"field\": \"rmse\", \"title\": \"RMSE (millions of $)\", \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Revenue\", \"width\": 480}, {\"data\": {\"name\": \"data-e8780a50e5a2c4e66b40e1ee710d50d1\"}, \"mark\": {\"type\": \"boxplot\", \"median\": {\"color\": \"black\", \"strokeWidth\": 3}, \"opacity\": 0.5, \"size\": 33}, \"encoding\": {\"color\": {\"field\": \"model\", \"legend\": null, \"type\": \"nominal\"}, \"x\": {\"axis\": {\"grid\": false, \"labelAngle\": 0}, \"field\": \"model\", \"sort\": [\"DUMMY\", \"LR\", \"RIDGE\", \"LASSO\", \"EN\", \"KNN\", \"DT\", \"SVR\", \"RFR\", \"ETR\", \"ABR\", \"GBR\"], \"title\": \"Regression Model\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false}, \"field\": \"rmse\", \"title\": \"RMSE (millions of $)\", \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Net Income\", \"width\": 480}], \"title\": {\"text\": \"Full Feature Space\", \"anchor\": \"middle\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-828819fa62ecb64ce8813fd799f2e353\": [{\"model\": \"DUMMY\", \"rmse\": 9172.182458946496}, {\"model\": \"DUMMY\", \"rmse\": 9235.333130188488}, {\"model\": \"DUMMY\", \"rmse\": 7629.322474862113}, {\"model\": \"DUMMY\", \"rmse\": 8373.809157067491}, {\"model\": \"DUMMY\", \"rmse\": 16357.43752848085}, {\"model\": \"LR\", \"rmse\": 13425.039720432202}, {\"model\": \"LR\", \"rmse\": 12855.678512209253}, {\"model\": \"LR\", \"rmse\": 11193.07979840082}, {\"model\": \"LR\", \"rmse\": 12667.03778503444}, {\"model\": \"LR\", \"rmse\": 17540.630960807153}, {\"model\": \"RIDGE\", \"rmse\": 11404.889334498605}, {\"model\": \"RIDGE\", \"rmse\": 11298.684123622295}, {\"model\": \"RIDGE\", \"rmse\": 9579.375063608239}, {\"model\": \"RIDGE\", \"rmse\": 10368.241513457235}, {\"model\": \"RIDGE\", \"rmse\": 16796.1788041127}, {\"model\": \"LASSO\", \"rmse\": 13125.288409718361}, {\"model\": \"LASSO\", \"rmse\": 12564.440391960703}, {\"model\": \"LASSO\", \"rmse\": 11040.404712316456}, {\"model\": \"LASSO\", \"rmse\": 12605.226877248877}, {\"model\": \"LASSO\", \"rmse\": 17238.764708658626}, {\"model\": \"EN\", \"rmse\": 9249.19016994264}, {\"model\": \"EN\", \"rmse\": 9374.79140487634}, {\"model\": \"EN\", \"rmse\": 7735.923160709681}, {\"model\": \"EN\", \"rmse\": 8477.154325612713}, {\"model\": \"EN\", \"rmse\": 16371.036444944528}, {\"model\": \"KNN\", \"rmse\": 10090.634030813353}, {\"model\": \"KNN\", \"rmse\": 9778.32695209603}, {\"model\": \"KNN\", \"rmse\": 8523.2169184439}, {\"model\": \"KNN\", \"rmse\": 8852.40451719099}, {\"model\": \"KNN\", \"rmse\": 16990.031689311123}, {\"model\": \"DT\", \"rmse\": 15187.745457555624}, {\"model\": \"DT\", \"rmse\": 19101.496931514892}, {\"model\": \"DT\", \"rmse\": 12949.854219107521}, {\"model\": \"DT\", \"rmse\": 17311.829888690103}, {\"model\": \"DT\", \"rmse\": 18956.47943710935}, {\"model\": \"SVR\", \"rmse\": 9518.40930798736}, {\"model\": \"SVR\", \"rmse\": 9605.282891742094}, {\"model\": \"SVR\", \"rmse\": 7728.557005905879}, {\"model\": \"SVR\", \"rmse\": 8638.995473976685}, {\"model\": \"SVR\", \"rmse\": 16680.12603439242}, {\"model\": \"RFR\", \"rmse\": 11401.172986300262}, {\"model\": \"RFR\", \"rmse\": 14546.153058519432}, {\"model\": \"RFR\", \"rmse\": 9449.083075010765}, {\"model\": \"RFR\", \"rmse\": 10671.055375454078}, {\"model\": \"RFR\", \"rmse\": 16920.839475409302}, {\"model\": \"ETR\", \"rmse\": 11201.739646465661}, {\"model\": \"ETR\", \"rmse\": 9837.851180221915}, {\"model\": \"ETR\", \"rmse\": 9269.739011838887}, {\"model\": \"ETR\", \"rmse\": 10049.32835070686}, {\"model\": \"ETR\", \"rmse\": 16544.810603080547}, {\"model\": \"ABR\", \"rmse\": 11775.98863828318}, {\"model\": \"ABR\", \"rmse\": 11769.37184871938}, {\"model\": \"ABR\", \"rmse\": 10403.572154125492}, {\"model\": \"ABR\", \"rmse\": 11924.521299687067}, {\"model\": \"ABR\", \"rmse\": 16710.84018964162}, {\"model\": \"GBR\", \"rmse\": 12211.383222204728}, {\"model\": \"GBR\", \"rmse\": 17140.799587411093}, {\"model\": \"GBR\", \"rmse\": 10702.525463533637}, {\"model\": \"GBR\", \"rmse\": 11586.70890306967}, {\"model\": \"GBR\", \"rmse\": 17456.400394993707}], \"data-e8780a50e5a2c4e66b40e1ee710d50d1\": [{\"model\": \"DUMMY\", \"rmse\": 2100.543872995704}, {\"model\": \"DUMMY\", \"rmse\": 854.4184001299118}, {\"model\": \"DUMMY\", \"rmse\": 1588.3033086697783}, {\"model\": \"DUMMY\", \"rmse\": 1233.0495717469257}, {\"model\": \"DUMMY\", \"rmse\": 1923.265283017755}, {\"model\": \"LR\", \"rmse\": 2342.239151886989}, {\"model\": \"LR\", \"rmse\": 1471.813144328102}, {\"model\": \"LR\", \"rmse\": 1982.524941727904}, {\"model\": \"LR\", \"rmse\": 1686.231094604352}, {\"model\": \"LR\", \"rmse\": 2100.0787128868083}, {\"model\": \"RIDGE\", \"rmse\": 2235.5643533177927}, {\"model\": \"RIDGE\", \"rmse\": 1189.0611549344467}, {\"model\": \"RIDGE\", \"rmse\": 1803.6014042952409}, {\"model\": \"RIDGE\", \"rmse\": 1456.5878495299537}, {\"model\": \"RIDGE\", \"rmse\": 2040.7109315883076}, {\"model\": \"LASSO\", \"rmse\": 2333.900734023027}, {\"model\": \"LASSO\", \"rmse\": 1402.6759463485862}, {\"model\": \"LASSO\", \"rmse\": 1949.486969591134}, {\"model\": \"LASSO\", \"rmse\": 1674.0092135975697}, {\"model\": \"LASSO\", \"rmse\": 2095.0705897594203}, {\"model\": \"EN\", \"rmse\": 2110.523381000528}, {\"model\": \"EN\", \"rmse\": 884.3216963882899}, {\"model\": \"EN\", \"rmse\": 1611.9222965883946}, {\"model\": \"EN\", \"rmse\": 1256.8510679464198}, {\"model\": \"EN\", \"rmse\": 1927.3209133875926}, {\"model\": \"KNN\", \"rmse\": 2189.238204835877}, {\"model\": \"KNN\", \"rmse\": 982.4113866660072}, {\"model\": \"KNN\", \"rmse\": 1854.2191793101983}, {\"model\": \"KNN\", \"rmse\": 1525.3172554422354}, {\"model\": \"KNN\", \"rmse\": 1992.8694916310014}, {\"model\": \"DT\", \"rmse\": 2715.2817613466154}, {\"model\": \"DT\", \"rmse\": 1773.1847110917818}, {\"model\": \"DT\", \"rmse\": 2586.151712080463}, {\"model\": \"DT\", \"rmse\": 3507.6951827465728}, {\"model\": \"DT\", \"rmse\": 2159.381511712357}, {\"model\": \"SVR\", \"rmse\": 2133.473716588823}, {\"model\": \"SVR\", \"rmse\": 900.8660951953599}, {\"model\": \"SVR\", \"rmse\": 1583.9373865988175}, {\"model\": \"SVR\", \"rmse\": 1243.8118670997824}, {\"model\": \"SVR\", \"rmse\": 1961.8672385181849}, {\"model\": \"RFR\", \"rmse\": 2264.8205424308794}, {\"model\": \"RFR\", \"rmse\": 1215.7606230411461}, {\"model\": \"RFR\", \"rmse\": 1950.4467457951737}, {\"model\": \"RFR\", \"rmse\": 2066.7283692153555}, {\"model\": \"RFR\", \"rmse\": 1971.8164847318587}, {\"model\": \"ETR\", \"rmse\": 2206.576743769093}, {\"model\": \"ETR\", \"rmse\": 1011.0023468580094}, {\"model\": \"ETR\", \"rmse\": 1791.3426020631455}, {\"model\": \"ETR\", \"rmse\": 1652.9339617865585}, {\"model\": \"ETR\", \"rmse\": 1973.2363919660356}, {\"model\": \"ABR\", \"rmse\": 2194.021063655013}, {\"model\": \"ABR\", \"rmse\": 955.7659893212447}, {\"model\": \"ABR\", \"rmse\": 1784.8955351370541}, {\"model\": \"ABR\", \"rmse\": 2038.8582238280069}, {\"model\": \"ABR\", \"rmse\": 1937.7603931184822}, {\"model\": \"GBR\", \"rmse\": 2269.796497476645}, {\"model\": \"GBR\", \"rmse\": 1406.6561987931664}, {\"model\": \"GBR\", \"rmse\": 1856.0908067047267}, {\"model\": \"GBR\", \"rmse\": 2243.1653821020955}, {\"model\": \"GBR\", \"rmse\": 1958.7305164178904}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chart4 = (rev_chart4 | ear_chart4).properties(\n",
    "    title=alt.TitleParams('Full Feature Space', anchor='middle'))\n",
    "full_chart3.configure_view(stroke=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "milestoneII",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
