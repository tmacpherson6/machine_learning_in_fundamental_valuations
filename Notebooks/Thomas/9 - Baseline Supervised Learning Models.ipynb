{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f2d2185",
   "metadata": {},
   "source": [
    "# Supervised Learning Models  \n",
    "The goal of this notebook is to create a machine learning pipeline that test multiple base forms (no hyper parameter tuning) of supervised machine learning techniques. This will allow us to determine the best baseline model to then tune in order to maximize performance. We want to set this up in a form that allows us to apply it to many different subsets of our feature space to see what works best and reduce model complexity while maintaining forecasting of out-of-sample data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018f1012",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "There are going to be a lot of different baseline models that we need to import here. The goal will be to produce a pipeline that runs the dataset through all of these models and outputs a box-whisker plot showing the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4282acdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Sci-Kit Learn Processing and Evaluating\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, QuantileTransformer\n",
    "\n",
    "\n",
    "# Supervised Learning Models  \n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso  \n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor  \n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "from sklearn.svm import SVR  \n",
    "from sklearn.ensemble import RandomForestRegressor  \n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import altair as alt\n",
    "\n",
    "# Let's set our Random State here as well\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a12134b",
   "metadata": {},
   "source": [
    "## Load Data Files\n",
    "Now we need to load both the X_data files and the y_data files for comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f28340",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '../../datasets/'\n",
    "X_train_file = 'X_train_filled_KPIs_QoQ_PCA.csv'\n",
    "y_train_file = 'y_train.csv'\n",
    "X = pd.read_csv(root_path+X_train_file)\n",
    "y = pd.read_csv(root_path+y_train_file)\n",
    "print(X.shape, y.shape)\n",
    "print(X.tail(),y.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6851fb74",
   "metadata": {},
   "source": [
    "Let's put in a small section where we can filter out the Mega and Nano caps before changing the y-variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3a3896",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X['Market Cap'].unique())\n",
    "print(X.shape)\n",
    "X = X[(X['Market Cap'] != 'Mega-Cap') & (X['Market Cap'] != 'Micro-Cap')]\n",
    "print(X.shape)\n",
    "print(X['Market Cap'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aea7a58",
   "metadata": {},
   "source": [
    "Alright, the first thing that I notice is that we have different sizes of files. That means we dropped rows in our X split but didn't drop them in our y. So let's address this first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d21ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_train = set(X['Ticker'])\n",
    "y = y[y['Ticker'].isin(in_train)].copy()\n",
    "print(len(in_train))\n",
    "print(y.shape)\n",
    "#print(X.tail(),y.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246251c0",
   "metadata": {},
   "source": [
    "### Set up our dependent variables (y1 and y2)\n",
    "Now, Let's get our two different y variables that we want to compare to. y1 will be total Revenue, y2 will be net income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f430f0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pull out the data we want to predict\n",
    "y1_rev = y['Revenue_2025Q2']\n",
    "y2_ear = y['NetIncome_2025Q2']\n",
    "y3_rev_rat = (y['Revenue_2025Q2'] - X['Revenue_2025Q1'])/X['Revenue_2025Q1']\n",
    "print(y1_rev.shape,y2_ear.shape, y3_rev_rat.shape)\n",
    "print(y1_rev.isna().sum())\n",
    "print(y2_ear.isna().sum())\n",
    "print(y3_rev_rat.isna().sum())\n",
    "print(y3_rev_rat[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d2a575",
   "metadata": {},
   "source": [
    "So, it turns out that we have a lot of missing values that we are trying to predict here. So we obviously need to remove them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f18c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[['Ticker','Revenue_2025Q2','NetIncome_2025Q2']]\n",
    "print(y.shape)\n",
    "y.dropna(inplace=True)\n",
    "print(y.shape)\n",
    "in_dependent = set(y['Ticker'])\n",
    "X = X[X['Ticker'].isin(in_dependent)].copy()\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257b5f00",
   "metadata": {},
   "source": [
    "Now, we can reassing the y1_rev and the y2_ear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bab48fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_rev = y['Revenue_2025Q2']\n",
    "y2_ear = y['NetIncome_2025Q2']\n",
    "y3_rev_rat = (y['Revenue_2025Q2'] - X['Revenue_2025Q1'])/X['Revenue_2025Q1']\n",
    "y4_margin =y['NetIncome_2025Q2']/y['Revenue_2025Q2']\n",
    "print(y1_rev.isna().sum())\n",
    "print(y2_ear.isna().sum())\n",
    "print(y3_rev_rat.isna().sum())\n",
    "print(y4_margin.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2951ae",
   "metadata": {},
   "source": [
    "Great, now similar to our unsupervised notebook. We need to do a little data cleaning and manipulation on our X here so that we have useable X and y data. Let's start by dropping the unique columns that will not help us in identifying trends (Ticker, Name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82883dd3",
   "metadata": {},
   "source": [
    "## Dataset Separation\n",
    "Alright, I think one of the first things we should do is identify three different datasets that we want to work with.  \n",
    "1. Full Dataset (minus columns like Ticker)  \n",
    "2. Raw Data Dataset (What would it look like if we just used the raw financial data) \n",
    "4. KPIs and PCA Dataset (Engineered data and data reduction dataset; this may end up being 2) \n",
    "3. Engineered Dataset (Do we get better structure when we look at just the engineered features)\n",
    "\n",
    "We can easily just split these into subdatasets if we pull out the relevant columns. So let's look at all of the columns first so that we can start creating the proper datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8e189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset = X.copy()\n",
    "columns = complete_dataset.columns.tolist()\n",
    "for column in sorted(columns):\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fc654c",
   "metadata": {},
   "source": [
    "Alright, let's start by identifying which columns to drop because they are unnecessary for the unsupervised learning part. This should be relatively few columns.\n",
    "- Ticker\n",
    "- Name  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8288eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset = complete_dataset.drop(columns=['Ticker','Name'])\n",
    "print(complete_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c33ce7d",
   "metadata": {},
   "source": [
    "Great, now, we can loop through all of the columns and we will pull out all of the feature engineered data if it contains 'KPI', 'QoQ', or 'Rate' in the title. We can then investigate these columns to make sure they make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951429f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_columns = []\n",
    "engineered_columns = []\n",
    "pca_columns = []\n",
    "revenue_columns = []\n",
    "for column in complete_dataset.columns:\n",
    "    if ('KPI' not in column) and ('QoQ' not in column) and ('Rate' not in column) and ('PCA' not in column) and ('Cluster' not in column):\n",
    "        raw_columns.append(column)\n",
    "    else:\n",
    "        engineered_columns.append(column)\n",
    "for column in complete_dataset.columns:\n",
    "    if ('PCA' not in column) and ('Cluster' not in column):\n",
    "        continue\n",
    "    else:\n",
    "        pca_columns.append(column)\n",
    "for column in complete_dataset.columns:\n",
    "    if ('Revenue' in column) and ('CostOf' not in column):\n",
    "        revenue_columns.append(column)\n",
    "print(f'Raw Columns: {len(raw_columns)}')\n",
    "print(f'Engineered Columns: {len(engineered_columns)}')\n",
    "print(f'PCA Columns {len(pca_columns)}')\n",
    "print(f'Revenue Columns {len(revenue_columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b894fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in engineered_columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e580b7f2",
   "metadata": {},
   "source": [
    "Now, there are going to be some of the raw columns that we want to add back to the engineered columns as they can be very important components to the company, so let's list these here.\n",
    "- Sector  \n",
    "- Exchange\n",
    "- Location  \n",
    "- Market Cap\n",
    "- Market Value\n",
    "\n",
    "So let's append those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30639f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_back = ['Sector','Exchange','Location','Market Value','Market Cap']\n",
    "engineered_columns = engineered_columns + add_back\n",
    "print(f'Engineered Columns after adding back important raw columns: {len(engineered_columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c098971",
   "metadata": {},
   "source": [
    "Alright, now we can build out all of our feature dataframes to test them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a507d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = complete_dataset[raw_columns]\n",
    "eng_data = complete_dataset[engineered_columns]\n",
    "tot_data = complete_dataset.copy()\n",
    "#kpi_data = place holder for the KPI data\n",
    "pca_data = complete_dataset[pca_columns]\n",
    "rev_data = complete_dataset[revenue_columns + add_back]\n",
    "\n",
    "print(f'Full Dataset Shape: {tot_data.shape}')\n",
    "print(f'Raw Data Shape: {raw_data.shape}')\n",
    "print(f'Engineered Data Shape: {eng_data.shape}')\n",
    "#print(f'KPI Data shape: {kpi_data.shape}')\n",
    "print(f'PCA reduced Data Shape: {pca_data.shape}')\n",
    "print(f'Rev reduced Data Shape: {rev_data.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78784126",
   "metadata": {},
   "source": [
    "## Fundamental Data\n",
    "Now that we have all of our data setup, we need to work on the preprocessing steps in order to have machine readable information being fed into our supervised model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd416dde",
   "metadata": {},
   "source": [
    "### Scaler Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b2e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set our scaler here\n",
    "scaler = QuantileTransformer()\n",
    "#scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b46e62",
   "metadata": {},
   "source": [
    "## Aside\n",
    "I wanted to see whether only using the revenue data was better at predicting the revenue than the full dataset so I came back up to the top of my notebook to run this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45084058",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets see how we do with just the rev data.\n",
    "#X_rev = rev_data.copy()\n",
    "## columns\n",
    "#cat_cols = ['Sector', 'Exchange', 'Market Cap'] \n",
    "#num_cols = [c for c in X_rev.columns if c not in cat_cols]\n",
    "#\n",
    "## models (set seeds where applicable)\n",
    "#models = [\n",
    "#    ('DUMMY', DummyRegressor(strategy='median')),\n",
    "#    ('LR', LinearRegression()),\n",
    "#    ('RIDGE', Ridge()),\n",
    "#    ('LASSO', Lasso()),\n",
    "#    ('EN', ElasticNet()),\n",
    "#    ('KNN', KNeighborsRegressor()),\n",
    "#    ('DT', DecisionTreeRegressor(random_state=random_state)),\n",
    "#    ('SVR', SVR()),\n",
    "#    ('RFR', RandomForestRegressor(random_state=random_state)),\n",
    "#    ('ETR', ExtraTreesRegressor(random_state=random_state)),\n",
    "#    ('ABR', AdaBoostRegressor(random_state=random_state)),\n",
    "#    ('GBR', GradientBoostingRegressor(random_state=random_state)),\n",
    "#    ('MLP', MLPRegressor(random_state=random_state))\n",
    "#]\n",
    "#\n",
    "## preprocessing\n",
    "#preproc = ColumnTransformer([\n",
    "#    ('num', Pipeline([\n",
    "#        ('scale', scaler)\n",
    "#    ]), num_cols),\n",
    "#    ('cat', Pipeline([\n",
    "#        ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "#    ]), cat_cols),\n",
    "#])\n",
    "#\n",
    "#cv = KFold(n_splits=5, shuffle = True, random_state=random_state)\n",
    "#scorer = 'neg_root_mean_squared_error'  # RMSE as negative; flip sign after\n",
    "#\n",
    "#names, kfold_results_rev, kfold_results_ear, kfold_results_rat = [], [], [], []\n",
    "#\n",
    "#for name, model in models:\n",
    "#    pipe = Pipeline([('prep', preproc), ('model', model)])\n",
    "#    rmse_rev = -cross_val_score(pipe, X_rev, y1_rev, cv=cv, scoring=scorer, n_jobs=-1)\n",
    "#    rmse_ear = -cross_val_score(pipe, X_rev, y2_ear, cv=cv, scoring=scorer, n_jobs=-1)\n",
    "#    \n",
    "#    names.append(name)\n",
    "#    kfold_results_rev.append(rmse_rev)\n",
    "#    kfold_results_ear.append(rmse_ear)\n",
    "#    \n",
    "#\n",
    "## optional: summary\n",
    "#summary = pd.DataFrame({\n",
    "#    'model': names,\n",
    "#    'rev_rmse_mean': [r.mean() for r in kfold_results_rev],\n",
    "#    'rev_rmse_std':  [r.std()  for r in kfold_results_rev],\n",
    "#    'ear_rmse_mean': [r.mean() for r in kfold_results_ear],\n",
    "#    'ear_rmse_std':  [r.std()  for r in kfold_results_ear],\n",
    "#}).sort_values('rev_rmse_mean')\n",
    "#summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0f7f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's try a better looking chart in altair\n",
    "#df_rev = pd.DataFrame({\n",
    "#    \"model\": np.concatenate([[n]*len(v) for n, v in zip(names, kfold_results_rev)]),\n",
    "#    \"rmse\":  np.concatenate(kfold_results_rev)\n",
    "#})\n",
    "#\n",
    "#df_rev['rmse'] = df_rev['rmse']/1_000_000\n",
    "#\n",
    "#rev_chart = alt.Chart(df_rev).mark_boxplot(size=33, opacity=0.5, median={'color': 'black', 'strokeWidth': 3}).encode(\n",
    "#    x=alt.X('model:N', sort=names, title='Regression Model', axis = alt.Axis(labelAngle = 0, grid = False)),\n",
    "#    y=alt.Y('rmse:Q', title='RMSE (millions of $)', axis = alt.Axis(grid = False)),\n",
    "#    color = alt.Color('model:N', legend=None)\n",
    "#).properties(\n",
    "#    width=40*len(names), height=300,\n",
    "#    title='Revenue'\n",
    "#)\n",
    "#\n",
    "#rev_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e991494",
   "metadata": {},
   "source": [
    "## Continue with original notebook\n",
    "Here we will resume to our original order of testing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87746896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets attempt this first with the raw data\n",
    "X_raw = raw_data.copy()\n",
    "# columns\n",
    "cat_cols = ['Sector', 'Exchange', 'Market Cap'] \n",
    "num_cols = [c for c in X_raw.columns if c not in cat_cols]\n",
    "\n",
    "# models (set seeds where applicable)\n",
    "models = [\n",
    "    ('DUMMY', DummyRegressor(strategy='median')),\n",
    "    ('LR', LinearRegression()),\n",
    "    ('RIDGE', Ridge()),\n",
    "    ('LASSO', Lasso()),\n",
    "    ('EN', ElasticNet()),\n",
    "    ('KNN', KNeighborsRegressor()),\n",
    "    ('DT', DecisionTreeRegressor(random_state=random_state)),\n",
    "    ('SVR', SVR()),\n",
    "    ('RFR', RandomForestRegressor(random_state=random_state)),\n",
    "    ('ETR', ExtraTreesRegressor(random_state=random_state)),\n",
    "    ('ABR', AdaBoostRegressor(random_state=random_state)),\n",
    "    ('GBR', GradientBoostingRegressor(random_state=random_state)),\n",
    "    ('MLP', MLPRegressor(random_state=random_state))\n",
    "]\n",
    "\n",
    "# preprocessing\n",
    "preproc = ColumnTransformer([\n",
    "    ('num', Pipeline([\n",
    "        ('scale', scaler)\n",
    "    ]), num_cols),\n",
    "    ('cat', Pipeline([\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]), cat_cols),\n",
    "])\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle = True, random_state=random_state)\n",
    "scorer = 'neg_root_mean_squared_error'  # RMSE as negative; flip sign after\n",
    "\n",
    "names, kfold_results_rev, kfold_results_ear, kfold_results_rat, kfold_results_marg= [], [], [], [], []\n",
    "\n",
    "for name, model in models:\n",
    "    pipe = Pipeline([('prep', preproc), ('model', model)])\n",
    "    rmse_rev = -cross_val_score(pipe, X_raw, y1_rev, cv=cv, scoring=scorer, n_jobs=-1)\n",
    "    rmse_ear = -cross_val_score(pipe, X_raw, y2_ear, cv=cv, scoring=scorer, n_jobs=-1)\n",
    "    \n",
    "    rmse_marg = -cross_val_score(pipe, X_raw, y4_margin, cv=cv, scoring=scorer, n_jobs=-1)\n",
    "    names.append(name)\n",
    "    kfold_results_rev.append(rmse_rev)\n",
    "    kfold_results_ear.append(rmse_ear)\n",
    "    \n",
    "    kfold_results_marg.append(rmse_marg)\n",
    "\n",
    "# optional: summary\n",
    "summary = pd.DataFrame({\n",
    "    'model': names,\n",
    "    'rev_rmse_mean': [r.mean() for r in kfold_results_rev],\n",
    "    'rev_rmse_std':  [r.std()  for r in kfold_results_rev],\n",
    "    'ear_rmse_mean': [r.mean() for r in kfold_results_ear],\n",
    "    'ear_rmse_std':  [r.std()  for r in kfold_results_ear],\n",
    "}).sort_values('rev_rmse_mean')\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19903c6",
   "metadata": {},
   "source": [
    "Alright, that should hopefully run through all of our models and give us an output that we can plot the box and whisker plots. Let's just use a simple plot first to see if it worked then we can build a nicer one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e243fe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison Predicting Revenue using Raw Financial Data: \\n5-fold Cross Validation')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(kfold_results_rev)\n",
    "ax.set_xticklabels(names)\n",
    "fig.set_size_inches(15,8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00d1f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a better looking chart in altair\n",
    "df_rev = pd.DataFrame({\n",
    "    \"model\": np.concatenate([[n]*len(v) for n, v in zip(names, kfold_results_rev)]),\n",
    "    \"rmse\":  np.concatenate(kfold_results_rev)\n",
    "})\n",
    "\n",
    "df_rev['rmse'] = df_rev['rmse']/1_000_000\n",
    "\n",
    "rev_chart = alt.Chart(df_rev).mark_boxplot(size=33, opacity=0.5, median={'color': 'black', 'strokeWidth': 3}).encode(\n",
    "    x=alt.X('model:N', sort=names, title='Regression Model', axis = alt.Axis(labelAngle = 0, grid = False)),\n",
    "    y=alt.Y('rmse:Q', title='RMSE (millions of $)', axis = alt.Axis(grid = False)),\n",
    "    color = alt.Color('model:N', legend=None)\n",
    ").properties(\n",
    "    width=40*len(names), height=300,\n",
    "    title='Revenue'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c32e06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a better looking chart in altair\n",
    "df_ear = pd.DataFrame({\n",
    "    \"model\": np.concatenate([[n]*len(v) for n, v in zip(names, kfold_results_ear)]),\n",
    "    \"rmse\":  np.concatenate(kfold_results_ear)\n",
    "})\n",
    "\n",
    "df_ear['rmse'] = df_ear['rmse']/1_000_000\n",
    "\n",
    "ear_chart = alt.Chart(df_ear).mark_boxplot(size=33, opacity=0.5, median={'color': 'black', 'strokeWidth': 3}).encode(\n",
    "    x=alt.X('model:N', sort=names, title='Regression Model', axis = alt.Axis(labelAngle = 0, grid = False)),\n",
    "    y=alt.Y('rmse:Q', title='RMSE (millions of $)', axis = alt.Axis(grid = False)),\n",
    "    color = alt.Color('model:N', legend=None)\n",
    ").properties(\n",
    "    width=40*len(names), height=300,\n",
    "    title='Net Income'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7da660c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's try a better looking chart in altair\n",
    "#df_rat = pd.DataFrame({\n",
    "#    \"model\": np.concatenate([[n]*len(v) for n, v in zip(names, kfold_results_rat)]),\n",
    "#    \"rmse\":  np.concatenate(kfold_results_rat)\n",
    "#})\n",
    "#\n",
    "#df_rat['rmse'] = df_rat['rmse']\n",
    "#\n",
    "#rat_chart = alt.Chart(df_rat).mark_boxplot(size=33, opacity=0.5, median={'color': 'black', 'strokeWidth': 3}).encode(\n",
    "#    x=alt.X('model:N', sort=names, title='Regression Model', axis = alt.Axis(labelAngle = 0, grid = False)),\n",
    "#    y=alt.Y('rmse:Q', title='RMSE (% Change of Revenue)', axis = alt.Axis(grid = False)),\n",
    "#    color = alt.Color('model:N', legend=None)\n",
    "#).properties(\n",
    "#    width=40*len(names), height=300,\n",
    "#    title='QoQ Change in Revenue'\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d29165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's try a better looking chart in altair\n",
    "#df_marg = pd.DataFrame({\n",
    "#    \"model\": np.concatenate([[n]*len(v) for n, v in zip(names, kfold_results_marg)]),\n",
    "#    \"rmse\":  np.concatenate(kfold_results_marg)\n",
    "#})\n",
    "#\n",
    "#df_rat['rmse'] = df_rat['rmse']\n",
    "#\n",
    "#marg_chart = alt.Chart(df_marg).mark_boxplot(size=33, opacity=0.5, median={'color': 'black', 'strokeWidth': 3}).encode(\n",
    "#    x=alt.X('model:N', sort=names, title='Regression Model', axis = alt.Axis(labelAngle = 0, grid = False)),\n",
    "#    y=alt.Y('rmse:Q', title='RMSE (% Change of Revenue)', axis = alt.Axis(grid = False)),\n",
    "#    color = alt.Color('model:N', legend=None)\n",
    "#).properties(\n",
    "#    width=40*len(names), height=300,\n",
    "#    title='Margin'\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5211391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chart = (rev_chart | ear_chart ).properties(\n",
    "    title=alt.TitleParams('Raw Fundamental Feature Space', anchor='middle'))\n",
    "full_chart.configure_view(stroke=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90727086",
   "metadata": {},
   "source": [
    "## Engineered Only Data\n",
    "Now that we have seen the performance of the fundamentals. Let's look at the engineered data by itself. I have a feeling this will struggle to predict the absolute revenue value because it's not included in the orginal but I may be wrong. Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ebe972",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     40\u001b[39m pipe = Pipeline([(\u001b[33m'\u001b[39m\u001b[33mprep\u001b[39m\u001b[33m'\u001b[39m, preproc), (\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m, model)])\n\u001b[32m     41\u001b[39m rmse_rev = -cross_val_score(pipe, X_eng, y1_rev, cv=cv, scoring=scorer, n_jobs=-\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m rmse_ear = -\u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_eng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my2_ear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m rmse_marg = -cross_val_score(pipe, X_eng, y4_margin, cv=cv, scoring=scorer, n_jobs=-\u001b[32m1\u001b[39m)\n\u001b[32m     45\u001b[39m names.append(name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:677\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    674\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    675\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:399\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    396\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m    398\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m results = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    419\u001b[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[32m    421\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    423\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmacp\\anaconda3\\envs\\milestoneII\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Lets attempt this first with the raw data\n",
    "X_eng = eng_data.copy()\n",
    "# columns\n",
    "cat_cols = ['Sector', 'Exchange', 'Market Cap'] \n",
    "num_cols = [c for c in X_eng.columns if c not in cat_cols]\n",
    "\n",
    "# models (set seeds where applicable)\n",
    "models = [\n",
    "    ('DUMMY', DummyRegressor(strategy='median')),\n",
    "    ('LR', LinearRegression()),\n",
    "    ('RIDGE', Ridge()),\n",
    "    ('LASSO', Lasso()),\n",
    "    ('EN', ElasticNet()),\n",
    "    ('KNN', KNeighborsRegressor()),\n",
    "    ('DT', DecisionTreeRegressor(random_state=random_state)),\n",
    "    ('SVR', SVR()),\n",
    "    ('RFR', RandomForestRegressor(random_state=random_state)),\n",
    "    ('ETR', ExtraTreesRegressor(random_state=random_state)),\n",
    "    ('ABR', AdaBoostRegressor(random_state=random_state)),\n",
    "    ('GBR', GradientBoostingRegressor(random_state=random_state)),\n",
    "    ('MLP', MLPRegressor(random_state=random_state))\n",
    "]\n",
    "\n",
    "# preprocessing\n",
    "preproc = ColumnTransformer([\n",
    "    ('num', Pipeline([\n",
    "        ('scale', scaler)\n",
    "    ]), num_cols),\n",
    "    ('cat', Pipeline([\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]), cat_cols),\n",
    "])\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle = True, random_state=random_state)\n",
    "scorer = 'neg_root_mean_squared_error'  # RMSE as negative; flip sign after\n",
    "\n",
    "names, kfold_results_rev, kfold_results_ear, kfold_results_rat, kfold_results_marg= [], [], [], [], []\n",
    "\n",
    "for name, model in models:\n",
    "    pipe = Pipeline([('prep', preproc), ('model', model)])\n",
    "    rmse_rev = -cross_val_score(pipe, X_eng, y1_rev, cv=cv, scoring=scorer, n_jobs=-1)\n",
    "    rmse_ear = -cross_val_score(pipe, X_eng, y2_ear, cv=cv, scoring=scorer, n_jobs=-1)\n",
    "    \n",
    "    rmse_marg = -cross_val_score(pipe, X_eng, y4_margin, cv=cv, scoring=scorer, n_jobs=-1)\n",
    "    names.append(name)\n",
    "    kfold_results_rev.append(rmse_rev)\n",
    "    kfold_results_ear.append(rmse_ear)\n",
    "    \n",
    "    kfold_results_marg.append(rmse_marg)\n",
    "\n",
    "# optional: summary\n",
    "summary = pd.DataFrame({\n",
    "    'model': names,\n",
    "    'rev_rmse_mean': [r.mean() for r in kfold_results_rev],\n",
    "    'rev_rmse_std':  [r.std()  for r in kfold_results_rev],\n",
    "    'ear_rmse_mean': [r.mean() for r in kfold_results_ear],\n",
    "    'ear_rmse_std':  [r.std()  for r in kfold_results_ear],\n",
    "    \n",
    "}).sort_values('rev_rmse_mean')\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7137bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a better looking chart in altair\n",
    "df_rev = pd.DataFrame({\n",
    "    \"model\": np.concatenate([[n]*len(v) for n, v in zip(names, kfold_results_rev)]),\n",
    "    \"rmse\":  np.concatenate(kfold_results_rev)\n",
    "})\n",
    "\n",
    "df_rev['rmse'] = df_rev['rmse']/1_000_000\n",
    "\n",
    "rev_chart2 = alt.Chart(df_rev).mark_boxplot(size=33, opacity=0.5, median={'color': 'black', 'strokeWidth': 3}).encode(\n",
    "    x=alt.X('model:N', sort=names, title='Regression Model', axis = alt.Axis(labelAngle = 0, grid = False)),\n",
    "    y=alt.Y('rmse:Q', title='RMSE (millions of $)', axis = alt.Axis(grid = False)),\n",
    "    color = alt.Color('model:N', legend=None)\n",
    ").properties(\n",
    "    width=40*len(names), height=300,\n",
    "    title='Revenue'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3520be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a better looking chart in altair\n",
    "df_ear = pd.DataFrame({\n",
    "    \"model\": np.concatenate([[n]*len(v) for n, v in zip(names, kfold_results_ear)]),\n",
    "    \"rmse\":  np.concatenate(kfold_results_ear)\n",
    "})\n",
    "\n",
    "df_ear['rmse'] = df_ear['rmse']/1_000_000\n",
    "\n",
    "ear_chart2 = alt.Chart(df_ear).mark_boxplot(size=33, opacity=0.5, median={'color': 'black', 'strokeWidth': 3}).encode(\n",
    "    x=alt.X('model:N', sort=names, title='Regression Model', axis = alt.Axis(labelAngle = 0, grid = False)),\n",
    "    y=alt.Y('rmse:Q', title='RMSE (millions of $)', axis = alt.Axis(grid = False)),\n",
    "    color = alt.Color('model:N', legend=None)\n",
    ").properties(\n",
    "    width=40*len(names), height=300,\n",
    "    title='Net Income'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b81b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's try a better looking chart in altair\n",
    "#df_rat = pd.DataFrame({\n",
    "#    \"model\": np.concatenate([[n]*len(v) for n, v in zip(names, kfold_results_rat)]),\n",
    "#    \"rmse\":  np.concatenate(kfold_results_rat)\n",
    "#})\n",
    "#\n",
    "#df_rat['rmse'] = df_rat['rmse']\n",
    "#\n",
    "#rat_chart2 = alt.Chart(df_rat).mark_boxplot(size=33, opacity=0.5, median={'color': 'black', 'strokeWidth': 3}).encode(\n",
    "#    x=alt.X('model:N', sort=names, title='Regression Model', axis = alt.Axis(labelAngle = 0, grid = False)),\n",
    "#    y=alt.Y('rmse:Q', title='RMSE (% Change of Revenue)', axis = alt.Axis(grid = False)),\n",
    "#    color = alt.Color('model:N', legend=None)\n",
    "#).properties(\n",
    "#    width=40*len(names), height=300,\n",
    "#    title='QoQ Change in Revenue'\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a28de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's try a better looking chart in altair\n",
    "#df_marg = pd.DataFrame({\n",
    "#    \"model\": np.concatenate([[n]*len(v) for n, v in zip(names, kfold_results_marg)]),\n",
    "#    \"rmse\":  np.concatenate(kfold_results_marg)\n",
    "#})\n",
    "#\n",
    "#df_marg['rmse'] = df_rat['rmse']\n",
    "#\n",
    "#marg_chart2 = alt.Chart(df_marg).mark_boxplot(size=33, opacity=0.5, median={'color': 'black', 'strokeWidth': 3}).encode(\n",
    "#    x=alt.X('model:N', sort=names, title='Regression Model', axis = alt.Axis(labelAngle = 0, grid = False)),\n",
    "#    y=alt.Y('rmse:Q', title='RMSE (% Change of Revenue)', axis = alt.Axis(grid = False)),\n",
    "#    color = alt.Color('model:N', legend=None)\n",
    "#).properties(\n",
    "#    width=40*len(names), height=300,\n",
    "#    title='Margin'\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869fb916",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chart2 = (rev_chart2 | ear_chart2 ).properties(\n",
    "    title=alt.TitleParams('Raw Fundamental Feature Space', anchor='middle'))\n",
    "full_chart2.configure_view(stroke=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e568df9",
   "metadata": {},
   "source": [
    "## Full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f7b848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets attempt this first with the raw data\n",
    "X_tot = tot_data.copy()\n",
    "# columns\n",
    "cat_cols = ['Sector', 'Exchange', 'Market Cap'] \n",
    "num_cols = [c for c in X_tot.columns if c not in cat_cols]\n",
    "\n",
    "# models (set seeds where applicable)\n",
    "models = [\n",
    "    ('DUMMY', DummyRegressor(strategy='median')),\n",
    "    ('LR', LinearRegression()),\n",
    "    ('RIDGE', Ridge()),\n",
    "    ('LASSO', Lasso()),\n",
    "    ('EN', ElasticNet()),\n",
    "    ('KNN', KNeighborsRegressor()),\n",
    "    ('DT', DecisionTreeRegressor(random_state=random_state)),\n",
    "    ('SVR', SVR()),\n",
    "    ('RFR', RandomForestRegressor(random_state=random_state)),\n",
    "    ('ETR', ExtraTreesRegressor(random_state=random_state)),\n",
    "    ('ABR', AdaBoostRegressor(random_state=random_state)),\n",
    "    ('GBR', GradientBoostingRegressor(random_state=random_state)),\n",
    "    ('MLP', MLPRegressor(random_state=random_state))\n",
    "]\n",
    "# preprocessing\n",
    "preproc = ColumnTransformer([\n",
    "    ('num', Pipeline([\n",
    "        ('scale', scaler)\n",
    "    ]), num_cols),\n",
    "    ('cat', Pipeline([\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]), cat_cols),\n",
    "])\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle = True, random_state=random_state)\n",
    "scorer = 'neg_root_mean_squared_error'\n",
    "\n",
    "names, kfold_results_rev, kfold_results_ear, kfold_results_rat = [], [], [], []\n",
    "kfold_mae,kfold_r2,kfold_results_marg = [],[],[]\n",
    "\n",
    "for name, model in models:\n",
    "    pipe = Pipeline([('prep', preproc), ('model', model)])\n",
    "    rmse_rev = -cross_val_score(pipe, X_tot, y1_rev, cv=cv, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "    mae_rev = -cross_val_score(pipe, X_tot, y1_rev, cv=cv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "    r2_rev = cross_val_score(pipe, X_tot, y1_rev, cv=cv, scoring='r2', n_jobs=-1)\n",
    "    rmse_ear = -cross_val_score(pipe, X_tot, y2_ear, cv=cv, scoring=scorer, n_jobs=-1)\n",
    "\n",
    "    rmse_marg = -cross_val_score(pipe, X_tot, y4_margin, cv=cv, scoring=scorer, n_jobs=-1)\n",
    "    names.append(name)\n",
    "    kfold_results_rev.append(rmse_rev)\n",
    "    kfold_mae.append(mae_rev)\n",
    "    kfold_r2.append(r2_rev)\n",
    "    kfold_results_ear.append(rmse_ear)\n",
    "    \n",
    "    kfold_results_marg.append(rmse_marg)\n",
    "\n",
    "# optional: summary\n",
    "summary = pd.DataFrame({\n",
    "    'model': names,\n",
    "    'RMSE mean': [r.mean() for r in kfold_results_rev],\n",
    "    'RMSE std':  [r.std()  for r in kfold_results_rev],\n",
    "    'MAE mean': [r.mean() for r in kfold_mae],\n",
    "    'MAE std':  [r.std()  for r in kfold_mae],\n",
    "    'r2 mean': [r.mean() for r in kfold_r2],\n",
    "    'r2 std': [r.std() for r in kfold_r2],\n",
    "})\n",
    "summary.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e496c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame({\n",
    "    'model': names,\n",
    "    'RMSE mean': [str(int(r.mean()/1_000_000))+'M' for r in kfold_results_rev],\n",
    "    'RMSE std':  [str(int(r.std()/1_000_000))+'M'  for r in kfold_results_rev],\n",
    "    'MAE mean': [str(int(r.mean()/1_000_000))+'M' for r in kfold_mae],\n",
    "    'MAE std':  [str(int(r.std()/1_000_000))+'M'  for r in kfold_mae],\n",
    "    'r2 mean': [np.round(r.mean(),3) for r in kfold_r2],\n",
    "    'r2 std': [np.round(r.std(),3) for r in kfold_r2],\n",
    "})\n",
    "summary.set_index('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d91bac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a better looking chart in altair\n",
    "df_rev = pd.DataFrame({\n",
    "    \"model\": np.concatenate([[n]*len(v) for n, v in zip(names, kfold_results_rev)]),\n",
    "    \"rmse\":  np.concatenate(kfold_results_rev)\n",
    "})\n",
    "\n",
    "df_rev['rmse'] = df_rev['rmse']/1_000_000\n",
    "\n",
    "rev_chart3 = alt.Chart(df_rev).mark_boxplot(size=33, opacity=0.5, median={'color': 'black', 'strokeWidth': 3}).encode(\n",
    "    x=alt.X('model:N', sort=names, title='Regression Model', axis = alt.Axis(labelAngle = 0, grid = False)),\n",
    "    y=alt.Y('rmse:Q', title='RMSE (millions of $)', axis = alt.Axis(grid = False)),\n",
    "    color = alt.Color('model:N', legend=None)\n",
    ").properties(\n",
    "    width=40*len(names), height=300,\n",
    "    title='Revenue'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb429220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a better looking chart in altair\n",
    "df_ear = pd.DataFrame({\n",
    "    \"model\": np.concatenate([[n]*len(v) for n, v in zip(names, kfold_results_ear)]),\n",
    "    \"rmse\":  np.concatenate(kfold_results_ear)\n",
    "})\n",
    "\n",
    "df_ear['rmse'] = df_ear['rmse']/1_000_000\n",
    "\n",
    "ear_chart3 = alt.Chart(df_ear).mark_boxplot(size=33, opacity=0.5, median={'color': 'black', 'strokeWidth': 3}).encode(\n",
    "    x=alt.X('model:N', sort=names, title='Regression Model', axis = alt.Axis(labelAngle = 0, grid = False)),\n",
    "    y=alt.Y('rmse:Q', title='RMSE (millions of $)', axis = alt.Axis(grid = False)),\n",
    "    color = alt.Color('model:N', legend=None)\n",
    ").properties(\n",
    "    width=40*len(names), height=300,\n",
    "    title='Net Income'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f589e652",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's try a better looking chart in altair\n",
    "#df_rat = pd.DataFrame({\n",
    "#    \"model\": np.concatenate([[n]*len(v) for n, v in zip(names, kfold_results_rat)]),\n",
    "#    \"rmse\":  np.concatenate(kfold_results_rat)\n",
    "#})\n",
    "#\n",
    "#df_rat['rmse'] = df_rat['rmse']\n",
    "#\n",
    "#rat_chart3 = alt.Chart(df_rat).mark_boxplot(size=33, opacity=0.5, median={'color': 'black', 'strokeWidth': 3}).encode(\n",
    "#    x=alt.X('model:N', sort=names, title='Regression Model', axis = alt.Axis(labelAngle = 0, grid = False)),\n",
    "#    y=alt.Y('rmse:Q', title='RMSE (% Change of Revenue)', axis = alt.Axis(grid = False)),\n",
    "#    color = alt.Color('model:N', legend=None)\n",
    "#).properties(\n",
    "#    width=40*len(names), height=300,\n",
    "#    title='QoQ Change in Revenue'\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b055265",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's try a better looking chart in altair\n",
    "#df_marg = pd.DataFrame({\n",
    "#    \"model\": np.concatenate([[n]*len(v) for n, v in zip(names, kfold_results_marg)]),\n",
    "#    \"rmse\":  np.concatenate(kfold_results_marg)\n",
    "#})\n",
    "#\n",
    "#df_rat['rmse'] = df_rat['rmse']\n",
    "#\n",
    "#marg_chart3 = alt.Chart(df_marg).mark_boxplot(size=33, opacity=0.5, median={'color': 'black', 'strokeWidth': 3}).encode(\n",
    "#    x=alt.X('model:N', sort=names, title='Regression Model', axis = alt.Axis(labelAngle = 0, grid = False)),\n",
    "#    y=alt.Y('rmse:Q', title='RMSE (% Change of Revenue)', axis = alt.Axis(grid = False)),\n",
    "#    color = alt.Color('model:N', legend=None)\n",
    "#).properties(\n",
    "#    width=40*len(names), height=300,\n",
    "#    title='Margin'\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ee982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chart3 = (rev_chart3 | ear_chart3 ).properties(\n",
    "    title=alt.TitleParams('Regression Model Evaluation using Root Mean Squared Error: 5-fold Cross-Validation', fontSize = 20, anchor='middle'))\n",
    "full_chart3.configure_view(stroke=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9379792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(full_chart & full_chart2 & full_chart3).configure_view(stroke=None).properties(\n",
    "    title=alt.TitleParams('RMSE Comparing Feature Space and Predictor Variables Without Mega- and Micro-Cap using 5-Fold Cross Validation', anchor='middle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eab9be4",
   "metadata": {},
   "source": [
    "## PCA Only Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b30911a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets attempt this first with the raw data\n",
    "X_pca = pca_data.copy()\n",
    "# columns\n",
    "#cat_cols = ['Sector', 'Exchange', 'Market Cap'] \n",
    "num_cols = X_pca.columns\n",
    "\n",
    "# models (set seeds where applicable)\n",
    "models = [\n",
    "    ('DUMMY', DummyRegressor(strategy='mean')),\n",
    "    ('LR', LinearRegression()),\n",
    "    ('RIDGE', Ridge()),\n",
    "    ('LASSO', Lasso()),\n",
    "    ('EN', ElasticNet()),\n",
    "    ('KNN', KNeighborsRegressor()),\n",
    "    ('DT', DecisionTreeRegressor(random_state=random_state)),\n",
    "    ('SVR', SVR()),\n",
    "    ('RFR', RandomForestRegressor(random_state=random_state)),\n",
    "    ('ETR', ExtraTreesRegressor(random_state=random_state)),\n",
    "    ('ABR', AdaBoostRegressor(random_state=random_state)),\n",
    "    ('GBR', GradientBoostingRegressor(random_state=random_state)),\n",
    "]\n",
    "\n",
    "# preprocessing\n",
    "preproc = ColumnTransformer([\n",
    "    ('num', Pipeline([\n",
    "        ('scale', scaler)\n",
    "    ]), num_cols),\n",
    "    \n",
    "])\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle = True, random_state=random_state)\n",
    "scorer = 'neg_root_mean_squared_error'  # RMSE as negative; flip sign after\n",
    "\n",
    "names, kfold_results_rev, kfold_results_ear = [], [], []\n",
    "\n",
    "for name, model in models:\n",
    "    pipe = Pipeline([('prep', preproc), ('model', model)])\n",
    "    rmse_rev = -cross_val_score(pipe, X_pca, y1_rev, cv=cv, scoring=scorer, n_jobs=-1)\n",
    "    rmse_ear = -cross_val_score(pipe, X_pca, y2_ear, cv=cv, scoring=scorer, n_jobs=-1)\n",
    "    names.append(name)\n",
    "    kfold_results_rev.append(rmse_rev)\n",
    "    kfold_results_ear.append(rmse_ear)\n",
    "\n",
    "# optional: summary\n",
    "summary = pd.DataFrame({\n",
    "    'model': names,\n",
    "    'rev_rmse_mean': [r.mean() for r in kfold_results_rev],\n",
    "    'rev_rmse_std':  [r.std()  for r in kfold_results_rev],\n",
    "    'ear_rmse_mean': [r.mean() for r in kfold_results_ear],\n",
    "    'ear_rmse_std':  [r.std()  for r in kfold_results_ear],\n",
    "}).sort_values('rev_rmse_mean')\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ba0841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a better looking chart in altair\n",
    "df_rev = pd.DataFrame({\n",
    "    \"model\": np.concatenate([[n]*len(v) for n, v in zip(names, kfold_results_rev)]),\n",
    "    \"rmse\":  np.concatenate(kfold_results_rev)\n",
    "})\n",
    "\n",
    "df_rev['rmse'] = df_rev['rmse']/1_000_000\n",
    "\n",
    "rev_chart4 = alt.Chart(df_rev).mark_boxplot(size=33, opacity=0.5, median={'color': 'black', 'strokeWidth': 3}).encode(\n",
    "    x=alt.X('model:N', sort=names, title='Regression Model', axis = alt.Axis(labelAngle = 0, grid = False)),\n",
    "    y=alt.Y('rmse:Q', title='RMSE (millions of $)', axis = alt.Axis(grid = False)),\n",
    "    color = alt.Color('model:N', legend=None)\n",
    ").properties(\n",
    "    width=40*len(names), height=300,\n",
    "    title='Revenue'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3600c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a better looking chart in altair\n",
    "df_ear = pd.DataFrame({\n",
    "    \"model\": np.concatenate([[n]*len(v) for n, v in zip(names, kfold_results_ear)]),\n",
    "    \"rmse\":  np.concatenate(kfold_results_ear)\n",
    "})\n",
    "\n",
    "df_ear['rmse'] = df_ear['rmse']/1_000_000\n",
    "\n",
    "ear_chart4 = alt.Chart(df_ear).mark_boxplot(size=33, opacity=0.5, median={'color': 'black', 'strokeWidth': 3}).encode(\n",
    "    x=alt.X('model:N', sort=names, title='Regression Model', axis = alt.Axis(labelAngle = 0, grid = False)),\n",
    "    y=alt.Y('rmse:Q', title='RMSE (millions of $)', axis = alt.Axis(grid = False)),\n",
    "    color = alt.Color('model:N', legend=None)\n",
    ").properties(\n",
    "    width=40*len(names), height=300,\n",
    "    title='Net Income'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814fc8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chart4 = (rev_chart4 | ear_chart4).properties(\n",
    "    title=alt.TitleParams('Full Feature Space', anchor='middle'))\n",
    "full_chart4.configure_view(stroke=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "milestoneII",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
